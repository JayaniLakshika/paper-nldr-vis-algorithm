---
title: "Looking at Non-Linear Dimension Reductions as Models in the Data Space"
format: 
    jasa-pdf:
        keep-tex: true
    jasa-html: default
author:
  - name: Jayani P.G. Lakshika
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-6265-6481
    email: jayani.piyadigamage@monash.edu
    url: https://jayanilakshika.netlify.app/
  - name: Dianne Cook
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-3813-7155
    email: dicook@monash.edu 
    url: http://www.dicook.org/
  - name: Paul Harrison
    affiliations:
      - name: Monash University
        department: MGBP, BDInstitute
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-3980-268X
    email: 	paul.harrison@monash.edu
    url: 
  - name: Michael Lydeamore
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0001-6515-827X
    email: michael.lydeamore@monash.edu
    url: 
  - name: Thiyanga S. Talagala
    affiliations:
      - name: University of Sri Jayewardenepura
        department: Statistics
        address: Gangodawila
        city: Nugegoda 
        country: Sri Lanka
        postal-code: 10100
    orcid: 0000-0002-0656-9789
    email: ttalagala@sjp.ac.lk 
    url: https://thiyanga.netlify.app/
tbl-cap-location: bottom
abstract: |
  Nonlinear dimension reduction (NLDR) techniques such as tSNE, and UMAP provide a low-dimensional representation of high-dimensional (high-D) data using non-linear transformation. The methods and parameter choices can create wildly different representations, making it difficult to decide which is best, or whether any or all are accurate or misleading. NLDR often exaggerates random patterns, sometimes due to the samples observed. But NLDR views have an important role in data analysis because, if done well, they provide a concise visual (and conceptual) summary of high-D distributions. To help evaluate the NLDR we have developed an algorithm to show the 2D NLDR model in the high-D space, viewed with a tour. One can see if the model fits everywhere or better in some subspaces, or completely mismatches the data. It is used to evaluate which 2D layout is the best representation of the high-D distribution and see how different methods may have similar summaries or quirks.
  
keywords: [high-dimensional data, dimension reduction, triangulation, hexagonal binning, low-dimensional manifold, manifold learning, tour, data vizualization]
keywords-formatted: [high-dimensional data, dimension reduction, triangulation, hexagonal binning, low-dimensional manifold, manifold learning, tour, data vizualization]

bibliography: bibliography.bib  
---

```{r include=FALSE}
# Set up chunk for for knitr
knitr::opts_chunk$set(
  fig.width = 5,
  fig.height = 5,
  fig.align = "center",
  out.width = "100%",
  code.line.numbers = FALSE,
  fig.retina = 4,
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  dev.args = list(pointsize = 11)
)
```

```{r}
#| label: load-libraries
#| warning: false
#| echo: false
library(quollr)
library(dplyr)
# remotes::install_github("jlmelville/snedata")
library(snedata)
library(ggflowchart)
library(purrr) ## map function
library(gridExtra) ## for grid.arrange
library(rsample)
library(DT)
library(ggbeeswarm)
library(ggplot2)
library(readr)
library(tidyr)

library(Rtsne)
library(uwot)
library(phateR)
library(patchwork)
library(langevitour)
library(colorspace)
library(kableExtra)
library(grid)
```

```{r}
#| label: plot-theme
theme_set(theme_linedraw() +
   theme(
     aspect.ratio = 1,
     plot.background = element_rect(fill = 'transparent', colour = NA),
     plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
     panel.background = element_rect(fill = 'transparent', 
                                     colour = NA),
     panel.grid.major = element_blank(), 
     panel.grid.minor = element_blank(), 
     axis.title.x = element_blank(), axis.title.y = element_blank(),
     axis.text.x = element_blank(), axis.ticks.x = element_blank(),
     axis.text.y = element_blank(), axis.ticks.y = element_blank(),
     legend.background = element_rect(fill = 'transparent', 
                                      colour = NA),
     legend.key = element_rect(fill = 'transparent', 
                               colour = NA),
     legend.position = "none", 
     legend.title = element_text(size=5), 
     legend.text = element_text(size=4),
     legend.key.height = unit(0.25, 'cm'),
     legend.key.width = unit(0.25, 'cm')
   )
)
interior_annotation <- function(label) {
  annotation_custom(grid::textGrob(label = label,
      x = unit(0.92, "npc"), y = unit(0.92, "npc"),
      gp = grid::gpar(cex = 1, col="grey70")))
}
```

```{r}
#| label: code-setup
set.seed(20240110)
source("nldr_code.R", local = TRUE)
```

<!-- 
Check-list before submission
* Is it all American spelling
* Spelling checked generally
* Code all runs given fresh workspace
* Code has a readme, explaining how the paper results are reproduced
-->

## Introduction

Non-linear dimension reduction (NLDR) is popular for making a convenient low-dimensional representation of high-dimensional data. Recently developed methods include t-distributed stochastic neighbor embedding (tSNE) [@Laurens2008], uniform manifold approximation and projection (UMAP) [@Leland2018], potential of heat-diffusion for affinity-based trajectory embedding (PHATE) algorithm [@article03], large-scale dimensionality reduction Using triplets (TriMAP) [@article02], and pairwise controlled manifold approximation (PaCMAP) [@Yingfan2021]. However, the representation generated can vary dramatically from method to method, and with different choices of parameters or random seeds made using the same method (@fig-NLDR-variety). The dilemma for the analyst is then, **which representation to use**. The choice might result in different procedures used in the downstream analysis, or different inferential conclusions. The research described here provides new visual tools to aid with this decision. 

<!-- - What's the problem:

  Non-linear dimension reduction being used to summarise high-dimensional data.

  - Summary of literature

  Relevant high-d vis, NLDR history
-->

```{r}
# label: read-pbmc-nldr
# Read a variety of different NLDR representations of PBMC
# and plot them on same aspect ratio
clr_choice <- "#0077A3"
umap_pbmc <- read_rds("data/pbmc3k/pbmc_umap_30_min_dist_0.3.rds")

nldr1 <- umap_pbmc |>
  ggplot(aes(x = UMAP1,
             y = UMAP2)) +
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("a")

umap_pbmc <- read_rds("data/pbmc3k/pbmc_umap_5_min_dist_0.01.rds")

nldr2 <- umap_pbmc |>
  ggplot(aes(x = UMAP1,
             y = UMAP2))+
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("b")

umap_pbmc <- read_rds("data/pbmc3k/pbmc_umap_15_min_dist_0.99.rds")
nldr3 <- umap_pbmc |>
  ggplot(aes(x = UMAP1,
             y = UMAP2))+
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("c")

tsne_pbmc <- read_rds("data/pbmc3k/pbmc_tsne_5.rds")

nldr4 <- tsne_pbmc |>
  ggplot(aes(x = tSNE1,
             y = tSNE2))+
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("d")

tsne_pbmc <- read_rds("data/pbmc3k/pbmc_tsne_51.rds")

nldr5 <- tsne_pbmc |>
  ggplot(aes(x = tSNE1,
             y = tSNE2))+
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("e")

phate_pbmc <- read_rds("data/pbmc3k/pbmc_phate_5.rds")
nldr6 <- phate_pbmc |>
  ggplot(aes(x = PHATE1,
             y = PHATE2))+
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("f")

trimap_pbmc <- read_rds("data/pbmc3k/pbmc_trimap_12_4_3.rds")
nldr7 <- trimap_pbmc |>
  ggplot(aes(x = TriMAP1,
             y = TriMAP2))+
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("g")

pacmap_pbmc <- read_rds("data/pbmc3k/pbmc_pacmap_30_random_0.9_5.rds")
nldr8 <- pacmap_pbmc |>
  ggplot(aes(x = PaCMAP1,
             y = PaCMAP2))+
  geom_point(alpha=0.1, size=1, colour=clr_choice) +
  interior_annotation("h")
```


```{r}
#| label: fig-NLDR-variety
#| echo: false
#| fig-cap: "Six different NLDR representations of the same data. Different techniques and different parameter choices are used. Researchers may have seen any of these in their analysis of this data, depending on their choice of method, or typical parameter choice. Would they make different decisions downstream in the analysis depending on which version seen? Which is the most accurate representation of the structure in high dimensions?"
#| fig-width: 8
#| fig-height: 4
#| out-width: 100%
# 2D layouts from different NLDR techniques and different hyperparameter choices applied for the PBMC3k dataset: (a) UMAP (n_neighbors = 30, min_dist = 0.3), (b) UMAP (n_neighbors = 5, min_dist = 0.01), (c) UMAP (n_neighbors = 15, min_dist = 0.99), (d) UMAP (n_neighbors = 15, min_dist = 0.03), (e) UMAP (n_neighbors = 84, min_dist = 0.99), (f) tSNE (perplexity = 5), (g) tSNE (perplexity = 51), (h) tSNE (perplexity = 92), (i) PHATE (knn = 2), (j) PHATE (knn = 5), (k) PHATE (knn = 10), (l) TriMAP (n_inliers = 12, n_outliers = 4, n_random = 3), (m) TriMAP (n_inliers = 30, n_outliers = 4, n_random = 10), (n) TriMAP (n_inliers = 5, n_outliers = 2, n_random = 2), (p) PaCMAP (n_neighbors = 10, init = pca, MN_ratio = 0.5, FP_ratio = 2), (q) PaCMAP (n_neighbors = 30, init = random, MN_ratio = 0.9, FP_ratio = 5), (r) PaCMAP (n_neighbors = 5, init = pca, MN_ratio = 0.1, FP_ratio = 1), and (s) PaCMAP (n_neighbors = 30, init = random, MN_ratio = 0.1, FP_ratio = 1). Is there a best representation of the original data or are they all providing  equivalent information?
nldr1 + nldr2 + nldr3 + nldr4 +
  nldr5 + nldr6 + nldr7 + nldr8 +
  plot_layout(ncol = 4)
```

The paper is organised as follows. @sec-background provides a summary of the literature on NLDR, and high-dimensional data visualization methods. @sec-method contains the details of the new methodology, including simulated data examples. Two applications illustrating the use of the new methodology for bioinformatics and image classification are in @sec-applications. Limitations and future directions are provided in @sec-discussion.

## Background {#sec-background}

## Method {#sec-method}

  - Create a representation of the model
  - Algorithm in 2D
      - Parameters
      - Tuning
  - Showing model in high-d
  - What is learned about simulated examples

## Applications {#sec-applications}

### pbmc
     - NLDR view used to illustrate clusters
     - Use our method to assess is it a reasonable representation
     - Demonstrate that it is not
     - Illustrate how to use out method to get a better representation
     
### digits: 1
     - NLDR is used to illustrate different ways 1's are drawn
     - Use our method to assess is it a reasonable representation
     - Demonstrate that it is, except for the anomalies 
     
## Discussion {#sec-discussion}

  - Summarise contributions
  - Explain where it is expected or not expected to work, eg higher dimensional relationships
  - Diagnostic app to explore differences in distances
  - What might be useful enhancements

  
## References {.unnumbered}
  
::: {#refs}
:::
      
{{< pagebreak >}}
    
