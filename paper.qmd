---
title: "Visualising How Non-linear Dimension Reduction Warps Your Data"
format: 
    jasa-pdf:
        keep-tex: true
    jasa-html: default
author:
  - name: Jayani P.G. Lakshika
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-6265-6481
    email: jayani.piyadigamage@monash.edu
    url: https://jayanilakshika.netlify.app/
  - name: Dianne Cook
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-3813-7155
    email: dicook@monash.edu 
    url: http://www.dicook.org/
  - name: Paul Harrison
    affiliations:
      - name: Monash University
        department: MGBP, BDInstitute
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-3980-268X
    email: 	paul.harrison@monash.edu
    url: 
  - name: Michael Lydeamore
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0001-6515-827X
    email: michael.lydeamore@monash.edu
    url: 
  - name: Thiyanga S. Talagala
    affiliations:
      - name: University of Sri Jayewardenepura
        department: Statistics
        address: Gangodawila
        city: Nugegoda 
        country: Sri Lanka
        postal-code: 10100
    orcid: 0000-0002-0656-9789
    email: ttalagala@sjp.ac.lk 
    url: https://thiyanga.netlify.app/
tbl-cap-location: bottom
abstract: |
  Non-Linear Dimension Reduction (NLDR) techniques have emerged as powerful tools to visualize high-dimensional data. However, their complexity and parameter choices may lead to distrustful or misleading results. To address this challenge, we propose a novel approach that combines the tour technique with a low-dimensional manifold generated using NLDR techniques, hexagonal binning, and triangulation. This integration enables a clear examination of the low-dimensional representation in the original high-dimensional space. Our approach not only preserves the advantages of both tours and NLDR but also offers a more intuitive perception of complex data structures and facilitates accurate data transformation assessments. The method and example data sets are available in the **quollr** R package.
  
keywords: [high-dimensional data, dimension reduction, triangulation, hexagonal binning, low-dimensional manifold, manifold learning, tour, data vizualization]
keywords-formatted: [high-dimensional data, dimension reduction, triangulation, hexagonal binning, low-dimensional manifold, manifold learning, tour, data vizualization]

bibliography: bibliography.bib  
---
  
```{r}
#| warning: false
#| echo: false
library(quollr)
library(dplyr)
# remotes::install_github("jlmelville/snedata")
library(snedata)
library(ggflowchart)
library(purrr) ## map function
library(gridExtra) ## for grid.arrange
library(rsample)
library(DT)
library(ggbeeswarm)
library(ggplot2)
library(readr)
library(tidyr)

library(Rtsne)
library(umap)
library(phateR)
library(patchwork)
library(langevitour)
library(colorspace)
library(kableExtra)
library(grid)
set.seed(20240110)

source("nldr_code.R", local = TRUE)
```

```{=html}
<!-- 
  Notes
* Use American spelling
-->
```

## Introduction {#sec-intro}

High-dimensional (high-D) data is prevalent across various fields, such as ecology and bioinformatics [@Guo2023], due to advancements in data collection technologies [@Johnstone2009; @ayesha2020overview]. However, visualization of high-D data introduces significant challenges, because the complexity of visualizing data beyond two dimensions [@Jia2022]. In recent years, interactive and dynamic graphics systems like **liminal** [@article21] —which employs interactive tools like brushing and linking [@article58]—and software tools such as **XGobi**, **GGobi** [@article60], **tourr**  [@article61], **detourr** [@article22], and **langevitour**  [@article09], involving dynamic methods like tours [@Asimov1985], have played a key role in visualizing high-D data (data-vis).

To create low-dimensional representations (typically in 2D) (m-vis) [@article59] of high-D data, it is common to apply dimension reduction (DR) techniques. Approaches for DR involve linear methods such as principal component analysis (PCA) [@Karl1901], non-linear methods such as multi-dimensional scaling (MDS) [@Torgerson1967]. In the past decade, many new non-linear dimension reduction (NLDR) techniques have emerged, such as t-distributed stochastic neighbor embedding (tSNE) [@Laurens2008] and uniform manifold approximation and projection (UMAP) [@Leland2018]. NLDR techniques are the 2D models of high-D data in our context.  

It is important to visualize various non-linear dimensionality reduction (NLDR) techniques for the same high-D data in order to understand and find the best representation. After doing so, the 2D models may differ considerably from each other and may also deviate from the original data structure in high-dimensional space. Therefore, visualizing the 2D model in high-D space (m-in-ds) is more useful to answer different types of questions:

- Is there a best 2D representation of high-D data or are they all providing  equivalent information? Is there a best parameter choice to fit the 2D model? How does the model change when it's parameters change?

- How well the does the 2D models capture the data structure? Is the model fitting able to capture different data structure like non-linear, clustering?

If we cannot easily ask and answer these questions, our ability to understand the models is limited. To find the best 2D model and parameter choices, a better understanding of the underlying science is important.

Also, the importance of m-vis along with data-vis has been recognized and incorporated into interactive software, **liminal** [@article21]. But the 2D model and high-D visualize side by side and interactive like brushing and linking connect the data in the two panels. To address this challenge, we propose a novel approach by combining the tour technique with a low-dimensional manifold. This manifold is created through the synergistic use of NLDR techniques, hexagonal binning, and triangulation. This integration facilitates a more understanding of the data structure, how well (or how poorly) NLDR techniques perform.

The outline of this paper is as follows. The @sec-background provides an detailed overview of dimension reduction methods, and tours. Building upon this foundation, the @sec-methods delves into the proposed algorithm, its implementation details, how to tune the model, model summaries, and a synthetic example to illustrate the functionality of the algorithm. Subsequently, @sec-applications showcases applications of the algorithm on different data sets, particularly in single-cell RNA-seq data. These applications reveal insights into the performance and trustworthiness of NLDR algorithms. We analyze the results to identify situations where NLDR techniques may lead to misleading interpretations. Finally, @sec-conclusions concludes by summarizing the findings and emphasizing the significance of the proposed approach in tackling the challenges of high-dimensional data visualization.

<!--UMAP with different param choices-->

```{r}
#| warning: false
#| echo: false

UMAP_data_7 <- read_rds(file = "data/s_curve/s_curve_umap_7.rds")

#(n-neighbors: 50)
plot_list1_umap <- plot_UMAP_2D(UMAP_data_7) + #ggtitle("(b)") +
  geom_point(alpha=0.5, size = 0.5, colour = "#8dd3c7", fill = "#8dd3c7") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

UMAP_data_15 <- read_rds(file = "data/s_curve/s_curve_umap_15.rds")

#(n-neighbors: 50)
plot_list2_umap <- plot_UMAP_2D(UMAP_data_15) + #ggtitle("(b)") + 
  geom_point(alpha=0.5, size = 0.5, colour = "#a65628", fill = "#a65628") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

UMAP_data_32 <- read_rds(file = "data/s_curve/s_curve_umap_32.rds")

#(n-neighbors: 50)
plot_list3_umap <- plot_UMAP_2D(UMAP_data_32) + #ggtitle("(b)") +
  geom_point(alpha=0.5, size = 0.5, color = "#f781bf", fill = "#f781bf") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'c', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

UMAP_data <- read_rds(file = "data/s_curve/s_curve_umap.rds")

#(n-neighbors: 50)
plot_list4_umap <- plot_UMAP_2D(UMAP_data) + #ggtitle("(b)") +
  geom_point(alpha=0.5, size = 0.5, colour = "#999999", fill = "#999999") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'd', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```


```{r}
#| echo: false
#| fig-cap: "2D layouts from UMAP applied for the S-curve data: (a) UMAP (n_neighbors = 7), (b) UMAP (n_neighbors = 15), (c) UMAP (n_neighbors = 32), (d) UMAP (n_neighbors = 50). Is there a best hyperparameter choice in representing UMAP or are they all providing  equivalent information?"
#| label: fig-nldervisUMAP
#| out-width: 100%

plot_list1_umap + plot_list2_umap + plot_list3_umap + plot_list4_umap +
  plot_layout(ncol=4)
```



<!--High-dimensional (high-D) data is widespread in many fields including ecology and bioinformatics [@Guo2023], in part because of new data collection technologies [@Johnstone2009; @ayesha2020overview]. Working with high-dimensional data poses considerable challenges due to the difficulty in visualizing beyond two dimensions [@Jia2022]. High-dimensional data also presents difficulties for model fitting [@Johnstone2009], both computationally and interpretation, each of which benefits from visualization.

To create visual representations of high-dimensional data, it is common to apply dimension reduction techniques. 

However, projecting high-dimensional data has limitations, such as information loss and potential distortion of essential structures and patterns [@Jia2022, @article53]. The choice of technique and parameters further impacts the accuracy of the visualization, necessitating careful consideration for meaningful interpretation (see @fig-nldervis).

Interactive and dynamic graphics systems have also been developed over the years to enable visualizing high dimensions. One method, called a tour [@Asimov1985], shows a sequence of linear projections is shown as a movie, allowing exploration without warping the space [@lee2021review]. Interactive tools like **XGobi** and **GGobi** have been successful in incorporating tours for exploring high-dimensional data [@article60]. The R package **tourr** [@article61] further enhances tour visualization within R, although it may face limitations in frame rate and interactive features compared to **GGobi**.

To overcome these limitations, the R package **detourr** [@article22] has been developed, leveraging a Javascript widget via htmlwidgets [@Ramnath2023] to achieve higher frame rates and enhanced interactivity. Additionally, the R package **langevitour** [@article09] utilizes Langevin Dynamics to generate a continuous path of projections, eliminating the need for interpolation between projections for animation. The tour technique has proven valuable in exploring statistical model fits [@article58] and factorial experimental designs [@article59]. Augmenting the results of non-linear dimensional reduction methods with the tour, as demonstrated in the **liminal** R package [@article21], further enhances data exploration.

The earlier approaches for DR involve linear methods such as PCA [@Karl1901]. PCA aims to maintain the second-order statistics of the data by projecting the points into the low dimensional space that preserves the maximum amount of variance among all such projections. As a result, PCA has been shown to be effective in preserving the global structure of the data (Silva & Tenenbaum, 2003).
The global structure includes the overall shape of the dataset, placement of the clusters, and the existence of potential outliers. Unlike PCA, much of the focus of the more recent non-linear methods, including t-SNE (Maaten & Hinton,2008), LargeVis (Tang et al., 2016), and UMAP (McInnes et al., 2018) has been on preserving the local neighborhood structure of each individual point. Mainly,  


While tours [@Asimov1985] preserve space without warping [@lee2021review], they require integrating multiple low-dimensional views mentally to perceive high-dimensional structures. To address this challenge, we propose a novel approach by combining the tour technique with a low-dimensional manifold. This manifold is created through the synergistic use of Non-Linear Dimension Reduction (NLDR) techniques, hexagonal binning, and triangulation. By merging these techniques, our approach offers a comprehensive and efficient means to visualize and explore high-dimensional data while retaining the advantages of both tours and NLDR. This integration facilitates a more intuitive perception of complex data structures and empowers analysts with a robust tool for assessing the accuracy of data transformations. The implementation of our approach is available as an R package called **quollr**.

The outline of this paper is as follows. The @sec-background provides an detailed overview of dimension reduction methods, triangulation, and tours. Building upon this foundation, the @sec-methods delves into the proposed algorithm, **quollr**, and its implementation details. In @sec-prediction, discusses the effectiveness of the learned low-dimensional manifold in accurately representing the complex high-dimensional data. Following that, @sec-simpleex presents simple examples from simulations to illustrate the functionality of the algorithm. Subsequently, @sec-applications showcases real-world applications of **quollr** on different data sets, particularly in single-cell RNA-seq data. These applications reveal insights into the performance and trustworthiness of NLDR algorithms. We analyze the results to identify situations where NLDR techniques may lead to misleading interpretations. Finally, @sec-conclusions concludes by summarizing the findings and emphasizing the significance of the proposed approach in tackling the challenges of high-dimensional data visualization. -->

## Background {#sec-background}

### Dimension Reduction

Consider the high-D data a rectangular matrix $X_{n \times p}$, where $X_{n \times p} = \begin{bmatrix} \textbf{x}_{1} & \textbf{x}_{2} & \cdots & \textbf{x}_{n}\\ \end{bmatrix}^\top$, with $n$ observations in $p$ dimensions. The objective is to discover a low-dimensional projection $Y_{n \times d} = \begin{bmatrix} \textbf{y}_{1} & \textbf{y}_{2} & \cdots & \textbf{y}_{n}\\ \end{bmatrix}^\top$, represented as an $n$ × $d$ matrix, where $d \ll p$. The reduction process seeks to remove noise from the original data set while retaining essential information.

There are two main categories of dimension reduction techniques: linear and non-linear methods. Linear techniques involve a linear transformation of the data, with one popular example being PCA. PCA performs an eigen-decomposition of the sample covariance matrix to obtain orthogonal principal components that capture the variance of the data [@Karl1901].

In contrast, NLDR techniques generate the low-dimensional representation $Y$ from the high-dimensional data $X$, often using pre-processing techniques like $k$-nearest neighbors graph or kernel transformations. Multidimensional Scaling (MDS) is a class of NLDR methods that aims to construct an embedding $Y$ in a low-dimensional space, approximating the pair-wise distances in $X$ [@Torgerson1967]. Variants of MDS include non-metric scaling [@article62] and Isomap, which estimate geodesic distances to create the low-dimensional representation [@article63]. Other approaches based on diffusion processes, like diffusion maps [@article64] and the PHATE (Potential of Heat-diffusion for Affinity-based Trajectory Embedding) algorithm [@article03], also fall under NLDR methods.

<!--Their focus is on capturing complex structures that may not be easily represented in the original space, making a straightforward reverse mapping challenging.

One specific technique we focus on is Pairwise Controlled Manifold Approximation (PaCMAP). Similar considerations apply to related methods like tSNE [@Laurens2008], UMAP [@Leland2018], and TrMAP [@article02].

However, linear methods may not fully capture complex non-linear relationships present in the data.-->

#### Non-linear dimension reduction techniques

NLDR techniques are crucial for analyzing and displaying high-dimensional data, where linear approaches may not adequately capture complexities in relationships between variables [@Johnstone2009]. One of the challenges with NLDR techniques is the selection and tuning of appropriate hyperparameters [@liao2023]. This process involves finding the suitable combination of hyperparameters that enhances the performance of the NLDR technique, considering the characteristics of the dataset and the specific goals of the analysis.

<!--This process requires a delicate balance to optimize the performance of NLDR techniques, taking into account the intricacies of the dataset and the specific goals of the analysis.-->

Additionally, another challenge is lack of reverse mapping. Techniques like PCA and auto-encoders [@article65] provide a way to map back from the low-dimensional space to the high-D space, facilitating data reconstruction. However, some NLDR methods, such as tSNE, don't have a specific way to reconstruct the original data from the low-dimensional space.

In this article, mainly focus on five NLDR techniques. They are tSNE, UMAP, PHATE, TriMAP [@article02], and Pairwise Controlled Manifold Approximation (PaCMAP) [@article01]. 

Among these, tSNE [@Laurens2008] stands out for its ability to preserve pairwise distances. By minimizing the divergence between probability distributions in both high and low-dimensional spaces, tSNE effectively uncovers intricate structures and patterns within the data. Its application is widespread, particularly in tasks requiring the visualization of clusters and local relationships. However, achieving effective results requires careful consideration of hyperparameters, such as perplexity.

UMAP [@Leland2018] is a useful technique for simplifying data while maintaining both local and overall structures. It builds a fuzzy topological view by considering nearby data points and then optimizes a simplified version to match that view. UMAP is known for working well with different scales of relationships in data and is efficient in handling large datasets. However, it's important to choose parameters like neighbors and minimum distance carefully, as they can affect the results.

Furthermore, PHATE [@article03] is great for understanding how things develop, especially in single-cell genomics. It uses a heat diffusion process to capture relationships between data points, like points along a trajectory. While PHATE is excellent for revealing these developmental structures, it requires careful tuning of its parameters because of its specialized focus.

Additionally, TriMAP [@article02] takes a special approach by creating a triangulated graph representation of the data. This method is good at understanding both local and global structures by treating the data as a network of triangles. TriMAP is powerful in capturing complicated structures, but it's important to choose parameters carefully, like deciding how many neighbors to consider.

PaCMAP [@article01] is different because it adds supervised learning to make a 2D representation while keeping the relationships between pairs of points. It builds a graph using distances between pairs and then makes the 2D representation better using a customizable loss function. What's special about PaCMAP is that it can use class labels or extra information to guide how it makes the 2D representation. This gives users a way to change how PaCMAP works to fit their needs better.



<!--Among these techniques, tSNE stands out for its emphasis on preserving pairwise distances. By minimizing the divergence between probability distributions in both the high and low-dimensional spaces, t-SNE effectively reveals intricate structures and patterns within the data. Its application is widespread in tasks requiring the visualization of clusters and local relationships, though it does require careful consideration of the perplexity parameter for optimal results.

UMAP is another powerful non-linear technique that strikes a balance between preserving local and global structures. Constructing a fuzzy topological representation using a weighted k-nearest neighbors graph, UMAP optimizes the low-dimensional embedding to resemble this representation. Known for its efficiency and scalability, UMAP is versatile across various scales of relationships in the data, although parameter sensitivity, particularly concerning the choice of neighbors, must be taken into account.

For trajectory data, PHATE provides specialized capabilities. It models the affinity between data points, simulating a heat diffusion process to capture developmental processes, particularly in single-cell genomics. While PHATE excels in revealing trajectory structures and offering insights into cellular development, it necessitates careful parameter tuning due to its specialized nature.

TriMAP adopts a unique approach by approximating the data manifold through the construction of a triangulated graph representation. This technique efficiently captures both global and local structures by representing the data as a network of triangles. TriMAP's strength lies in its ability to efficiently capture complex structures, albeit with sensitivity to parameter choices, including the number of neighbors.

In contrast, PaCMAP introduces supervised learning to create a low-dimensional representation while preserving pair-wise relationships. Constructing a graph based on pair-wise distances, PaCMAP optimizes an embedding using a customizable loss function. Particularly notable is PaCMAP's flexibility in incorporating class labels or additional information to guide the embedding process, offering users a means to customize its behavior and performance.-->


```{r}
#| warning: false
#| echo: false

data <- read_rds("data/s_curve/s_curve.rds")
```

```{r}
#| warning: false
#| echo: false

training_data <- read_rds("data/s_curve/s_curve_training.rds")
test_data <- read_rds("data/s_curve/s_curve_test.rds")
```

```{r}
#| warning: false
#| echo: false

tSNE_data <- read_rds("data/s_curve/s_curve_tsne_27.rds")

plot_list1 <- plot_tSNE_2D(tSNE_data) +  
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

UMAP_data <- read_rds(file = "data/s_curve/s_curve_umap.rds")

#(n-neighbors: 50)
plot_list2 <- plot_UMAP_2D(UMAP_data) + 
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```


```{r}
#| warning: false
#| echo: false

#(knn: 5)
# PHATE_data <- Fit_PHATE(training_data, knn = 5, with_seed = 20240110)
# write_csv(PHATE_data, paste0(here::here(), "/data/phate_data_s_curve.csv"))

PHATE_data <- read_rds(file = "data/s_curve/s_curve_phate.rds")

plot_list3 <- plot_PHATE_2D(PHATE_data) + 
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'c', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

```

```{r}
#| warning: false
#| echo: false

# tem_dir <- tempdir()
# 
# Fit_TriMAP_data(training_data, tem_dir)
# 
# path <- file.path(tem_dir, "df_2_without_class.csv")
# path2 <- file.path(tem_dir, "dataset_3_TriMAP_values.csv")
# 
# Fit_TriMAP(as.integer(2), as.integer(5), as.integer(4), as.integer(3), path, path2)
# 
# TriMAP_data <- read_csv(path2)
# write_csv(TriMAP_data, paste0(here::here(), "/data/trimap_data_s_curve.csv"))

TriMAP_data <- read_rds(file = "data/s_curve/s_curve_trimap.rds")

#(n-inliers: 5, \n n-outliers: 4, n-random: 3)
plot_list4 <- plot_TriMAP_2D(TriMAP_data) + 
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'd', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

```


```{r}
#| warning: false
#| echo: false

# tem_dir <- tempdir()
# 
# Fit_PacMAP_data(training_data, tem_dir)
# 
# path <- file.path(tem_dir, "df_2_without_class.csv")
# path2 <- file.path(tem_dir, "dataset_3_PaCMAP_values.csv")
# 
# Fit_PaCMAP(as.integer(2), as.integer(10), "random", 0.9, as.integer(2), path, path2)
# 
# PacMAP_data <- read_csv(path2)
# write_csv(PacMAP_data, paste0(here::here(), "/data/pacmap_data_s_curve.csv"))

PaCMAP_data <- read_rds(file = "data/s_curve/s_curve_pacmap.rds")

#(knn: 10, init: random, \n MN-ratio: 0.9, FP-ratio: 2)
plot_list5 <- plot_PaCMAP_2D(PaCMAP_data) +  
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'e', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

```

```{r}
#| echo: false
#| fig-cap: "2D layouts from different NLDR techniques applied the same data: (a) tSNE (perplexity = 27), (b) UMAP (n_neighbors = 50), (c) PHATE (knn = 5), (d) TriMAP (n_inliers = 5, n_outliers = 4, n_random = 3), and (e) PaCMAP (n_neighbors = 10, init = random, MN_ratio = 0.9, FP_ratio = 2). Is there a best representation of the original data or are they all providing  equivalent information?"
#| label: fig-nldervis
#| out-width: 100%

plot_list1 + plot_list2 + plot_list3 + plot_list4 + plot_list5 +
  plot_layout(ncol=5)
```


### Linear overviews using tours

A tour is a powerful visualization technique used to explore the shape and global structure of high-dimensional data by generating a sequence of projections, typically into two dimensions. There are two main types of tours: the grand tour [@Asimov1985] and the guided tour [@article29]. A grand tour involves randomly selecting new orthonormal bases, enabling users to understand the structure by exploring the subspace of d-dimensional projections [@Asimov1985]. In contrast, a guided tour can be employed to generate a sequence of 'interesting' projections based on an index function [@article29].

The process begins with the data matrix $X$. It generates a sequence of $p$ × $d$ orthonormal projection matrices (bases) $P_t$, usually $d$ is one or two dimensions. For each pair of orthonormal bases $P_t$ and $P_{t+1}$, a geodesic path is interpolated to create smooth animation between projections. The resulting tour continuously visualizes the projected data $Y_t$ = $XP_t$ as it interpolates between successive bases.

Furthermore, software like **langevitour** can visualize both types of tours, providing flexibility for exploring high-dimensional data with various objectives. In our context, use grand tour along with the model to observe how effectively the model captures the underlying structure of the data.

<!--While both tours can be used to visualize data, examples often focus on using the grand tour to observe global structures. However, software like **langevitour** can visualize both types of tours, providing flexibility for exploring high-dimensional data with various objectives. --> 

## Methodology {#sec-methods}

In this paper, we introduce a novel method to determine the most effective NLDR technique and the best hyperparameter choice that provides the most useful representation of high-D data. Our approach involves dividing the high-D dataset into two parts: a training set for constructing the model and a test set for generating predictive values and residuals. Our algorithm takes a 2D embedding data as the input and generate a tour that displays the high-D wireframe to overlay the data. The flow chart of the proposed algorithm is shown in @fig-meth. The algorithm consists of two main phases: (1) generating the model in the 2D space and (2) lifting the model into high-D space. The main steps of the algorithm are described in detail in this section using UMAP 2D embedding of the S-curve dataset. This dataset has seven dimensions, including four noise dimensions that were added to the original 3D data. 

![The flow diagram shows the main steps of our algorithm. There are two basic phases, one to generate the model in the 2D space, and other to map the model into the high-D space.](figures/workflow.png){#fig-meth fig-align="center" width="100%" height="100%"}

### Preprocessing steps

To reduce computational complexity when applying NLDR techniques to high-D data and to reduce noise presence, PCA [@article67, @article68, @article69] is used as a preprocessing step. PCA involves identifying principal components that maximize variance. These components are then used as the high-D data for the algorithm.

### Constructing the 2D model {#sec-construct2d}

**Step 1: Scaling NLDR data**

First, we prepare the 2D embedding data to fit within the bounds required for regular hexagonal binning. To achieve this, we implement two key scaling steps. Scale the first 2D embedding component to range between $0$ and $1$, ensuring that all data points fall within this normalized interval. Secondly, we scale the second 2D embedding component to range between $0$ and $y_{max}$ (see @eq-equation3).

The calculation of $y_{max}$ involves several steps. First, the aspect ratio ($ar$) is computed by dividing the range of the second 2D embedding component ($r_2$) by the range of the first 2D embedding component ($r_1$) (see @eq-equation1). Then, the hexagon ratio ($hr$) is determined by dividing the height of the hexagon ($hb$) by its width ($wb$) (see @eq-equation2). Finally, $y_{max}$ is derived by taking the ceiling of $\frac{ar}{hr}$ and multiplying it by $hr$. This process ensures that $y_{max}$ is an integer multiple of $hr$, accommodating the grid layout of the hexagonal bins.

$$
 ar = \frac{r_2}{r_1}
$$ {#eq-equation1}

$$
 hr = \frac{hb}{wb}
$$ {#eq-equation2}

$$
 y_{max} = \left\lceil\frac{ar}{hr}\right\rceil * hr
$$ {#eq-equation3}

**Step 2: Hexagonating NLDR data**

Hexagonating NLDR data (see @fig-meth Step 2) involves partitioning the 2D embedding data into hexagonal bins, a technique commonly referred to as hexagonal binning [@Carr1987, @article66]. This method use a hexagonal grid to create a bivariate histogram that effectively visualizes the structure of high-D data. Hexagons, one of only three regular polygons capable of tessellating a plane [@Carr2013], offer unique advantages due to their symmetry of nearest neighbors and maximal number of sides for such tessellations [@Dan2023]. This geometric property makes hexagons more efficient in covering the plane compared to other regular tessellations and reduces visual bias when displaying data densities [@Dan2023]. In our algorithm, we aim to conduct regular hexagonal binning (**cite quollr paper**), involving the computation of hexagonal grid configurations, the generation of the grid, and the assignment of the 2D embedding to hexagons. 

<!--
**(a) Determine the number of bins along the x axis** ($b_1$)

**(b) Determine the number of bins along the y axis** ($b_2$)

**(c) Determine the total number of bins** ($b$)

**(d) Assign NLDR data to hexagons**--> 

**Step 3: Obtaining bin centroids or bin means**

In the previous step, the algorithm clusters the 2D embedding data into hexagons. Following this, in this step, the bin centroids or bin means (see @fig-meth Step 3) are obtained [@Carr2013].

The bin centroid ($C_k^{(2)}$) for a $k^{th}$ hexagon with hexagonal grid coordinates $(h^{k}x_{i}, h^{k}y_{i})$, where $i = 1 \dots 6$ can be defined as:

$$
C_k^{(2)} = (C_{ky_1}, C_{ky_2}) = \left(\frac{\sum_{i=1}^{6} h^{k}x_{i}}{6}, \frac{\sum_{i=1}^{6} h^{k}y_{i}}{6}\right).
$$ {#eq-equation4}

Also, the bin mean ($C_k^{(2)}$) is defined as the mean of the data points within the $k^{th}$ hexagon (see @eq-equation5). 

$$
C_k^{(2)} = (C_{ky_1}, C_{ky_2}) = \left(\frac{1}{n_k} \sum_{i=1}^{n_k} y_{1i}, \frac{1}{n_k} \sum_{i=1}^{n_k} y_{2i}\right),
$$ {#eq-equation5}

where $n_k$ is the number of data points within the hexagon, $y_{1i}$ and $y_{2i}$ are the $x$ and $y$ coordinates of the $i^{th}$ data point within the hexagon.

**Step 4: Triangulating bin centroids or bin means**

In this step, the algorithm proceeds to triangulate the hexagonal bin centroids or bin means (see @fig-meth Step 4). Triangulation is a fundamental process in computational geometry and computer graphics that involves dividing a set of points in a given space into interconnected triangles [@article30]. One common algorithm used for triangulation is Delaunay triangulation [@article26, @article54], where points are connected in a way that maximizes the minimum angles of the resulting triangles, leading to a more regular and well-conditioned triangulation. 

Delaunay triangulation can be defined as follows:

Let $C^{(2)} = \{C_1^{(2)}, C_2^{(2)}, ..., C_m^{(2)}\}$ be a set of $m$ bin centroids or bin means in the plane. Delaunay triangulation of $C^{(2)}$, denoted as $DT(C^{(2)})$, is a triangulation of the convex hull of $C^{(2)}$ such that the circumcircle of every triangle in the triangulation contains no other points from $C^{(2)}$.

Given that the hexagons are regular, the resulting triangles will mostly be equilateral.

<!--

**Step 1: Computing the hexagonal grid configuration**

The hexagonal grid, formed through hexagonal binning [@Carr1987, @article66], serves as a type of bivariate histogram employed to visualize the structure of high-D data. Hexagons, being one of only three regular polygons capable of tessellating a plane [@Carr2013], possess both symmetry of nearest neighbors and the maximum number of sides for a regular tessellation of the plane. This unique combination makes hexagons more efficient in covering the plane compared to other regular tessellations. Additionally, hexagons exhibit lower visual bias when displaying densities, setting them apart from other regular tessellations [@Dan2023]. In our algorithm, hexagonal binning is used as the initial step of constructing the 2D model and the total number of bins ($b$) is the crucial parameter that defines the granularity of the hexagonal grid. 

**(a) Determine the number of bins along the x axis** ($b_1$)

First, the number of bins along the x-axis ($b_1$) is computed using the relationship between the diameter ($h$) and the area ($A$) of regular hexagons (see @eq-equation3).

In the process of computing hexagonal bin configurations, the first step involves determining the number of bins along the x-axis. This begins with the initialization of parameters such as the hexagonal size ($s$) and the buffer along the x-axis. Subsequently, the range of the first 2D embedding component ($r_1$) is calculated to ensure comprehensive coverage of the data. This range is then adjusted by incorporating the buffer amount, effectively expanding the boundary to accommodate potential outliers or edge cases. The default buffer amount along the x-axis is $\sqrt{3} * s * 1.5$. Next, the horizontal spacing ($h$) between hexagons is computed based on the hexagon size. Finally, the number of bins along the x-axis is computed based on the adjusted range ($r_1 + buffer_{x}$) and the horizontal spacing ($h$).


$$
 h = \sqrt{3} * s
$$ {#eq-equation3}

$$
 b_1 = \frac{r_1 + buffer_{x}}{h}
$$ {#eq-equation4}

**(b) Determine the number of bins along the y-axis** ($b_2$)

Next, the number of bins along the y-axis is computed based on the number of bins along the x-axis ($b_1$) and the shape parameter ($s$) (see @eq-equation4) [@Carr2013].

$$
  v = 1.5 * s
$$ {#eq-equation5}

$$
 b_2 = \frac{r_2 + buffer_{y}}{v}
$$ {#eq-equation6}
   
**(c) Determine the total number of bins** ($b$)

The total number of bins is determined by multiplying the number of bins along the x-axis ($b_1$) with the number of bins along the y-axis ($b_2$) (see @eq-equation5).
  
$$
b = b_1 \times b_2
$${#eq-equation5}
-->                

### Lifting the model into high dimensions

#### Lifting the triangular mesh points into high dimensions

Consider $f: \mathbb{R}^p \rightarrow \mathbb{R}^2$ be a function that maps the high-D data ($X_{n \times p}$) to its NLDR equivalent ($Y_{n \times d}$). Then, let $g: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be a function that maps each 2D embedding point to its closest centroid ($C^{(2)}$). It follows that $f(g(x))$ maps the high-D points $x$ to the centroid in 2D ($C_k^{(2)}$). Also, define a function $v: \mathbb{R}^2 \rightarrow \mathbb{R}^p$ maps the 2D centroid ($C^{(2)}$) to the high-D mean of the points ($C^{(p)}$) in the hexagon.

The high-D mean of all the points in $k^{th}$ hexagon by

$$
C_k^{(p)} = (C_{kx_1}, ..., C_{kx_p}) = \left(\frac{1}{n_k} \sum_{i=1}^{n_k} x_{1i}, \frac{1}{n_k} \sum_{i=1}^{n_k} x_{2i}, \dots ,\frac{1}{n_k} \sum_{i=1}^{n_k} x_{pi}\right).
$${#eq-equation6}

Therefore,

$$
v(C_k^{(2)}) = C_k^{(p)}.
$${#eq-equation7}

Therefore, $f(g(x))$ gives the 2D centroid associated with high-D points $x$, and $v(C_k^{(2)})$ gives the high-D centroid associated with 2D point $C_k^{(2)}$. Thus, $v(f(g(x)))$ gives the high-D centroid ($C_k^{(p)}$) associated with the 2D embedding of the points $x$. 

#### Lifting the 2D triangular mesh into high dimensions

As described in Step 4 of @sec-construct2d, during the triangulation process in 2D space, vertices are identified to form edges. With the knowledge of the high-D mappings for the 2D hexagonal bins, the vertices connected in 2D are also connected in high-D (see video linked in @fig-wkhighD). 

```{r}
#| warning: false
#| echo: false
#| message: false

umap_s_curve_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = UMAP_data, 
                                    x = "UMAP1", y = "UMAP2"))) |>
  dplyr::rename(c("UMAP1" = "scaled_UMAP1", 
                  "UMAP2" = "scaled_UMAP2")) |>
  dplyr::mutate(ID = 1:NROW(UMAP_data))

```

```{r}
#| warning: false
#| echo: false
#| message: false

num_bins_x <- 5
num_bins_y <- 10
hex_size <- 0.19


hb_obj <- hex_binning(data = umap_s_curve_scaled, x = "UMAP1", 
                              y = "UMAP2", num_bins_x = num_bins_x, 
                              num_bins_y = num_bins_y, x_start = NA, y_start = NA, 
                              buffer_x = NA, buffer_y = NA, hex_size = hex_size, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)

UMAP_data_with_hb_id <- as.data.frame(do.call(cbind, hb_obj$data_hb_id))

model_object <- fit_highd_model( training_data = training_data, 
                                 nldr_df_with_id = umap_s_curve_scaled, 
                                 x = "UMAP1", y = "UMAP2", 
                                 num_bins_x = num_bins_x, 
                                 num_bins_y = num_bins_y, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "UMAP", 
                                 col_start_highd = "x")

df_bin_centroids <- model_object$df_bin_centroids
df_bin <- model_object$df_bin

## Triangulate bin centroids
tr1_object <- tri_bin_centroids(df_bin_centroids, x = "c_x", y = "c_y")
tr_from_to_df <- gen_edges(tri_object = tr1_object)

# Create the tibble with x and y coordinates
tr_df <- tibble::tibble(x = tr1_object$x, y = tr1_object$y)


## Compute 2D distances
distance <- cal_2d_dist(tr_coord_df = tr_from_to_df, 
                                start_x = "x_from", start_y = "y_from", 
                                end_x = "x_to", end_y = "y_to", 
                                select_vars = c("from", "to", "distance"))


## Map hb_id

df_bin_centroids_n <- df_bin_centroids |>
  select(hexID) |>
  mutate(ID = 1:NROW(df_bin_centroids))

tr_from_to_df_n <- left_join(tr_from_to_df, df_bin_centroids_n, by = c("from" = "ID")) |>
  rename("from_hb_id" = "hexID")

tr_from_to_df_n <- left_join(tr_from_to_df_n, df_bin_centroids_n, by = c("to" = "ID")) |>
  rename("to_hb_id" = "hexID")

hb_id_selected <- tr_from_to_df_n |>
  dplyr::filter((from == 1) & (to == 3)) 

# Filter and label small and long edges
distance_df_small_edges <- distance |>
  dplyr::filter((from != 1) | (to != 3)) |>
  dplyr::mutate(type = "small_edges")

distance_df_long_edges <- distance |>
  dplyr::filter((from == 1) & (to == 3)) |>
  dplyr::mutate(type = "long_edges")

# Combine small and long edges
distance_edges <- dplyr::bind_rows(distance_df_small_edges, distance_df_long_edges)

tr_from_to_df_coord_with_group <- inner_join(tr_from_to_df, distance_edges, by = c("from" = "from", "to" = "to"))

## To generate a data set with high-D and 2D training data
df_all <- dplyr::bind_cols(training_data |> dplyr::select(-ID), UMAP_data_with_hb_id)

UMAP_data_with_hb_id_selected <- UMAP_data_with_hb_id |> dplyr::filter(hb_id %in% c(hb_id_selected$from_hb_id, hb_id_selected$to_hb_id)) |>
  dplyr::mutate(select_point = if_else(hb_id == hb_id_selected$from_hb_id, "data1", "data2"))

UMAP_data_with_hb_id_selected_no <- UMAP_data_with_hb_id |> dplyr::filter(!(hb_id %in% c(hb_id_selected$from_hb_id, hb_id_selected$to_hb_id)))

bin_coord_1 <- tr_df |>
  dplyr::filter((x == hb_id_selected$x_from)) |>
  dplyr::filter((y == hb_id_selected$y_from))

# bin_coord_1 <- tr_df |>
#   head(1)


bin_coord_2 <- tr_df |>
  dplyr::filter((x == hb_id_selected$x_to)) |>
  dplyr::filter((y == hb_id_selected$y_to))

# bin_coord_2 <- tr_df |>
#   dplyr::filter(row_number() == 2)


bin_coord <- dplyr::bind_rows(bin_coord_1, bin_coord_2)

a1 <- ggplot(bin_coord, aes(x = x, y = y)) +
  geom_segment(
    aes(x = x_from, y = y_from, xend = x_to, yend = y_to, colour = type),
    data = tr_from_to_df_coord_with_group) +
  geom_point() +
  #coord_equal() +
  coord_cartesian(xlim =c(-0.5, 1.5), ylim = c(-0.5, 2.7)) +
  geom_point(data = UMAP_data_with_hb_id_selected, aes(x = UMAP1, y = UMAP2, colour = select_point), alpha = 0.5, size = 1) +
  scale_color_manual(values=c("#e6550d", "#000000", "#e31a1c", "#f6e8c3")) +
  geom_point(size = 3, colour = "#33a02c") + 
  #ggtitle("(b)") + 
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  #coord_equal() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) 


a2 <- ggplot(data = hex_grid, aes(x = x, y = y)) + 
  geom_polygon(color = "#deebf7", aes(group = hex_poly_id), fill = "#ffffff") +
  geom_segment(
    aes(x = x_from, y = y_from, xend = x_to, yend = y_to), colour = "#f6e8c3",
    data = tr_from_to_df_coord_with_group
  ) +
  geom_point(data = UMAP_data_with_hb_id_selected, aes(x = UMAP1, y = UMAP2, colour = select_point), size = 1, alpha = 0.5) +
  scale_color_manual(values=c("#e6550d", "#000000")) +
  geom_point(data = df_bin_centroids |> dplyr::filter(hexID %in% c(hb_id_selected$from_hb_id, hb_id_selected$to_hb_id)), aes(x = c_x, y = c_y), colour = "#33a02c", size = 3) +
  geom_point(data = UMAP_data_with_hb_id_selected_no, aes(x = UMAP1, y = UMAP2), colour = "#6a3d9a", size = 1, alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_equal() +
  theme_light() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) 


## Script to make coloring data points with a line

df1 <- df_all |> 
  dplyr::filter(hb_id == as.character(hb_id_selected$from_hb_id)) |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data1") ## original dataset

df2 <- df_all |> 
  dplyr::filter(hb_id == as.character(hb_id_selected$to_hb_id)) |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data2") ## original dataset

df3 <- df_all |> 
  dplyr::filter(!(hb_id %in% c(as.character(hb_id_selected$from_hb_id), as.character(hb_id_selected$to_hb_id)))) |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data") ## original dataset

df_b <- df_bin |> 
  dplyr::filter(hb_id %in% df_bin_centroids$hexID) |>
  dplyr::filter(hb_id %in% c(as.character(hb_id_selected$from_hb_id), as.character(hb_id_selected$to_hb_id))) |>
  dplyr::select(-hb_id) |>
  dplyr::mutate(type = "model") ## Data with summarized mean

df_exe <- dplyr::bind_rows(df_b, df1, df2, df3)

lg_high <- langevitour::langevitour(df_exe[1:(length(df_exe)-1)], group = df_exe$type, pointSize = append(rep(4, NROW(df_b)), rep(2, NROW(df1) + NROW(df2) + NROW(df3))), levelColors = c("#6a3d9a", "#e6550d", "#000000", "#33a02c"), lineFrom = 1, lineTo = 2, lineColors = "#e31a1c")

```

```{r}
#| warning: false
#| echo: false
#| label: fig-wkhighD
#| fig-cap: How the 2D model lift into high dimensions? (a) visualize the points and the hexagonal bin centroids related $7^{th}$ and $12^{th}$ hexagons, (b) visualization of the edge connected the $7^{th}$ and $12^{th}$ hexagons (colored in red) in the triangular mesh. A video of tour animation is available at <https://youtu.be/hxU91xNTJL0>.

a2 + a1 +
  plot_annotation(tag_levels = 'a') +
  plot_layout(ncol = 3) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```


<!--
```{r}
#| echo: false
#| eval: false

num_bins_x <- calculate_effective_x_bins(.data = UMAP_data, x = UMAP1,
                                         cell_area = 1)

shape_value <- calculate_effective_shape_value(.data = UMAP_data, 
                                               x = UMAP1, y = UMAP2)

## To extract bin centroids
hexbin_data_object <-extract_hexbin_centroids(nldr_df = UMAP_data, num_bins = num_bins_x, shape_val = shape_value)

df_bin_centroids <- hexbin_data_object$hexdf_data

# ##########
# 
# ## Data set with all possible centroids in the hexagonal grid
# 
# full_centroid_df <- generate_full_grid_centroids(df_bin_centroids)
# 
# ## To map hexID to hexbin centroids in the full grid
# 
# vec1 <- stats::setNames(rep("", 2), c("x", "y"))  ## Define column names
# 
# full_grid_with_hexbin_id <- dplyr::bind_rows(vec1)[0, ]
# full_grid_with_hexbin_id <- full_grid_with_hexbin_id |>
#   dplyr::mutate_if(is.character, as.numeric)
# 
# for(i in 1:length(sort(unique(full_centroid_df$y)))){
#   
#   ## Filter the data set with specific y value
#   specific_y_val_df <- full_centroid_df |>
#     dplyr::filter(y == sort(unique(full_centroid_df$y))[i])
#   
#   ordered_x_df <- specific_y_val_df |>
#     dplyr::arrange(x) 
#   
#   full_grid_with_hexbin_id <- dplyr::bind_rows(full_grid_with_hexbin_id, ordered_x_df)
#   
# }
# 
# 
# full_grid_with_hexbin_id <- full_grid_with_hexbin_id |>
#   dplyr::mutate(hexID = row_number())
# 
# full_grid_with_hexbin_id <- full_grid_with_hexbin_id |>
#   dplyr::rename("c_x" = "x",
#          "c_y" = "y") 
# 
# full_grid_with_hexbin_id <- dplyr::full_join(full_grid_with_hexbin_id, df_bin_centroids, by = c("hexID" = "hexID")) |>
#   dplyr::select(-c(x, y)) #|> 
#   #dplyr::mutate(counts = tidyr::replace_na(counts, 0))
# 
# full_grid_with_hexbin_id <- full_grid_with_hexbin_id |>
#     dplyr::mutate(std_counts = counts/max(counts, na.rm = TRUE))
# 
# ## Generate all coordinates of hexagons
# hex_grid <- full_hex_grid(full_centroid_df)
# 
# full_grid_with_polygon_id_df <- map_polygon_id(full_grid_with_hexbin_id, hex_grid)
# 
# full_grid_with_hexbin_id_rep <- full_grid_with_polygon_id_df |>
#   dplyr::slice(rep(1:n(), each = 6)) |>
#   dplyr::arrange(polygon_id)

hex_full_count_df <- read_rds("data/s_curve/s_curve_hex_11.rds") 

##########

min_std_cell_threshold <- 0.05

df_bin_centroids_all <- hexbin_data_object$hexdf_data ## All the centroids without removing low-density hexagons


df_bin_centroids <- df_bin_centroids |>
  dplyr::mutate(stand_cell_count = counts/max(counts)) |>
  dplyr::filter(stand_cell_count > min_std_cell_threshold)

UMAP_data_with_hb_id <- UMAP_data |> 
  dplyr::mutate(hb_id = hexbin_data_object$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all <- dplyr::bind_cols(training_data |> dplyr::select(-ID), UMAP_data_with_hb_id)

## Averaged on high-D
df_bin <- avg_highD_data(.data = df_all)

## Triangulate bin centroids
tr1_object <- triangulate_bin_centroids(df_bin_centroids, x, y)
tr_from_to_df <- generate_edge_info(triangular_object = tr1_object)

## Compute 2D distances
distance <- cal_2d_dist(.data = tr_from_to_df)

## To find the benchmark value
benchmark <- find_benchmark_value(.data = distance, distance_col = distance)


trimesh <- ggplot(df_bin_centroids, aes(x = x, y = y)) + 
  geom_segment(data = tr_from_to_df, aes(x = x_from, y = y_from, xend = x_to, yend = y_to)) +
  geom_point(size = 2, colour = "#33a02c") +
  coord_equal()

# ggplot(df_bin_centroids, aes(x = x, y = y)) + 
# geom_point(size = 1, colour = "#33a02c") + 
# geom_trimesh() + 
# coord_equal() 

trimesh <- trimesh +
  #ggtitle("(a)") + 
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) 
# theme(axis.text = element_text(size = 5),
#       axis.title = element_text(size = 7))

trimesh_gr <- colour_long_edges(.data = distance, benchmark_value = benchmark, 
                                triangular_object = tr1_object, distance_col = distance) 

trimesh_gr <- trimesh_gr + 
  geom_point(size = 2, colour = "#33a02c") + 
  #ggtitle("(b)") + 
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  #coord_equal() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) 

trimesh_removed <- remove_long_edges(.data = distance, benchmark_value = benchmark, 
                                     triangular_object = tr1_object, distance_col = distance)

trimesh_removed <- trimesh_removed + 
  geom_point(size = 2, colour = "#33a02c") + 
  #ggtitle("(b)") + 
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  #coord_equal() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) 



tour1 <- show_langevitour(df_all, df_bin, df_bin_centroids, benchmark_value = benchmark, distance = distance, distance_col = distance)
```

```{r}
#| echo: false
#| eval: false

## To plot the distribution of distance
plot_dist <- function(distance_df){
  distance_df$group <- "1"
  dist_plot <- ggplot(distance_df, aes(x = group, y = distance)) +
    geom_quasirandom()+
    ylim(0, max(unlist(distance_df$distance))+ 0.5) + coord_flip()
  return(dist_plot)
}
```

```{r}
#| echo: false
#| eval: false

distance_plot <- plot_dist(distance) +
  #ggtitle("(b)" ) + 
  ylab(expression(d^{(2)})) +
  theme(axis.text = element_text(size = 5),
        axis.title = element_text(size = 12))
```



```{r}
#| echo: false
#| warning: false
#| eval: false

data <- read_rds("data/s_curve/s_curve.rds")
training_data <- read_rds("data/s_curve/s_curve_training.rds")
UMAP_data <- read_rds(file = "data/s_curve/s_curve_umap.rds")

num_bins_x <- 2

shape_value <- calculate_effective_shape_value(.data = UMAP_data, 
                                               x = UMAP1, y = UMAP2)

## To extract bin centroids
hexbin_data_object <-extract_hexbin_centroids(nldr_df = UMAP_data, num_bins = num_bins_x, shape_val = shape_value)

df_bin_centroids <- hexbin_data_object$hexdf_data

# ## Data set with all possible centroids in the hexagonal grid
# 
# full_centroid_df <- generate_full_grid_centroids(df_bin_centroids)
# 
# ## Generate all coordinates of hexagons
# hex_grid <- full_hex_grid(full_centroid_df)
# 
# hex_full_count_df <- generate_full_grid_info(df_bin_centroids)
# 
# write_rds(hex_full_count_df, "data/s_curve/s_curve_hex_2.rds")

min_std_cell_threshold <- 0.05

df_bin_centroids_all <- hexbin_data_object$hexdf_data ## All the centroids without removing low-density hexagons


hex_full_count_df <- read_rds("data/s_curve/s_curve_hex_2.rds") 

df_bin_centroids <- df_bin_centroids |>
  dplyr::mutate(stand_cell_count = counts/max(counts)) |>
  dplyr::filter(stand_cell_count > min_std_cell_threshold)

UMAP_data_with_hb_id <- UMAP_data |> 
  dplyr::mutate(hb_id = hexbin_data_object$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all <- dplyr::bind_cols(training_data |> dplyr::select(-ID), UMAP_data_with_hb_id)

## Averaged on high-D
df_bin <- avg_highD_data(.data = df_all)

## Triangulate bin centroids
tr1_object <- triangulate_bin_centroids(df_bin_centroids, x, y)
tr_from_to_df <- generate_edge_info(triangular_object = tr1_object)

# Create the tibble with x and y coordinates
tr_df <- tibble::tibble(x = tr1_object$x, y = tr1_object$y)

## Compute 2D distances
distance <- cal_2d_dist(.data = tr_from_to_df)

## Map hb_id

df_bin_centroids_n <- df_bin_centroids |>
  select(hexID) |>
  mutate(ID = 1:NROW(df_bin_centroids))

tr_from_to_df_n <- left_join(tr_from_to_df, df_bin_centroids_n, by = c("from" = "ID")) |>
  rename("from_hb_id" = "hexID")

tr_from_to_df_n <- left_join(tr_from_to_df_n, df_bin_centroids_n, by = c("to" = "ID")) |>
  rename("to_hb_id" = "hexID")

hb_id_selected <- tr_from_to_df_n |>
  dplyr::filter((from == 2) & (to == 3)) 


# benchmark_value <- 19.4

# Filter and label small and long edges
distance_df_small_edges <- distance |>
  dplyr::filter((from != 2) | (to != 3)) |>
  dplyr::mutate(type = "small_edges")

distance_df_long_edges <- distance |>
  dplyr::filter((from == 2) & (to == 3)) |>
  dplyr::mutate(type = "long_edges")

# Combine small and long edges
distance_edges <- dplyr::bind_rows(distance_df_small_edges, distance_df_long_edges)

tr_from_to_df_coord_with_group <- inner_join(tr_from_to_df, distance_edges, by = c("from" = "from", "to" = "to"))

UMAP_data_with_hb_id_selected <- UMAP_data_with_hb_id |> dplyr::filter(hb_id %in% c(hb_id_selected$from_hb_id, hb_id_selected$to_hb_id)) |>
  dplyr::mutate(select_point = if_else(hb_id == hb_id_selected$from_hb_id, "data1", "data2"))

UMAP_data_with_hb_id_selected_no <- UMAP_data_with_hb_id |> dplyr::filter(!(hb_id %in% c(hb_id_selected$from_hb_id, hb_id_selected$to_hb_id)))

bin_coord_1 <- tr_df |>
  dplyr::filter((x == hb_id_selected$x_from)) |>
  dplyr::filter((y == hb_id_selected$y_from))

# bin_coord_1 <- tr_df |>
#   head(1)


bin_coord_2 <- tr_df |>
  dplyr::filter((x == hb_id_selected$x_to)) |>
  dplyr::filter((y == hb_id_selected$y_to))

# bin_coord_2 <- tr_df |>
#   dplyr::filter(row_number() == 2)
  

bin_coord <- dplyr::bind_rows(bin_coord_1, bin_coord_2)

a1 <- ggplot(bin_coord, aes(x = x, y = y)) +
  geom_segment(
    aes(x = x_from, y = y_from, xend = x_to, yend = y_to, colour = type),
    data = tr_from_to_df_coord_with_group) +
  geom_point() +
  coord_equal() +
  geom_point(data = UMAP_data_with_hb_id_selected, aes(x = UMAP1, y = UMAP2, colour = select_point), alpha = 0.5, size = 1) +
  scale_color_manual(values=c("#e6550d", "#000000", "#e31a1c", "#f6e8c3")) +
  geom_point(size = 3, colour = "#33a02c") + 
  #ggtitle("(b)") + 
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  #coord_equal() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) 


a2 <- ggplot(data = hex_full_count_df, aes(x = x, y = y)) + 
  geom_polygon(color = "#deebf7", aes(group = polygon_id), fill = "#ffffff") +
  geom_segment(
    aes(x = x_from, y = y_from, xend = x_to, yend = y_to), colour = "#f6e8c3",
    data = tr_from_to_df_coord_with_group
  ) +
  geom_point(data = UMAP_data_with_hb_id_selected, aes(x = UMAP1, y = UMAP2, colour = select_point), size = 1, alpha = 0.5) +
  scale_color_manual(values=c("#e6550d", "#000000")) +
  geom_point(data = df_bin_centroids_all |> dplyr::filter(hexID %in% c(hb_id_selected$from_hb_id, hb_id_selected$to_hb_id)), aes(x = x, y = y), colour = "#33a02c", size = 3) +
    geom_point(data = UMAP_data_with_hb_id_selected_no, aes(x = UMAP1, y = UMAP2), colour = "#6a3d9a", size = 1, alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_cartesian(xlim =c(-5, 8), ylim = c(-10, 10)) +
  theme_light() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) 


## Script to make coloring data points with a line

df1 <- df_all |> 
  dplyr::filter(hb_id == as.character(hb_id_selected$from_hb_id)) |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data1") ## original dataset

df2 <- df_all |> 
  dplyr::filter(hb_id == as.character(hb_id_selected$to_hb_id)) |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data2") ## original dataset

df3 <- df_all |> 
  dplyr::filter(!(hb_id %in% c(as.character(hb_id_selected$from_hb_id), as.character(hb_id_selected$to_hb_id)))) |>
  dplyr::select(tidyselect::starts_with("x")) |>
  dplyr::mutate(type = "data") ## original dataset

df_b <- df_bin |> 
  dplyr::filter(hb_id %in% df_bin_centroids$hexID) |>
  dplyr::filter(hb_id %in% c(as.character(hb_id_selected$from_hb_id), as.character(hb_id_selected$to_hb_id))) |>
  dplyr::select(-hb_id) |>
  dplyr::mutate(type = "model") ## Data with summarized mean

df_exe <- dplyr::bind_rows(df_b, df1, df2, df3)

lg_high <- langevitour::langevitour(df_exe[1:(length(df_exe)-1)], group = df_exe$type, pointSize = 3, levelColors = c("#6a3d9a", "#e6550d", "#000000", "#33a02c"), lineFrom = 1, lineTo = 2, lineColors = "#e31a1c")

```

```{r}
#| eval: false
#| warning: false
#| echo: false
#| label: fig-wkhighD1
#| fig-cap: How the 2D model lift into high dimensions? (a) visualize the points and the hexagonal bin centroids related 2nd and 15th hexagons, (b) visualization of the edge connected the 2nd and 15th hexagons (colored in red) in the triangular mesh. A video of tour animation is available at <https://youtu.be/ffWFVK1UTIc>.

a2 + a1 +
  plot_annotation(tag_levels = 'a') +
  plot_layout(ncol = 3) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```
-->

### Tuning the model

The performance and robustness of our model depend on four key parameters: (i) the total number of bins ($b$), (ii) a benchmark value used to remove low-density hexagons, (iii) a benchmark value used to remove long edges, and (iv) starting point of the hexagonal grid. However, there is no analytical formula to calculate an appropriate value for these parameters (the computation of default values can be find in *quollr* paper). The selection of these parameter values depends on the model performance computed by Mean Squared Error (MSE) (see @sec-goodfit).  

#### Total number of bins

The number of hexagonal bins in the hexagonal grid has a considerable impact on the construction of the 2D model. This is because it is the initial step in building the 2D model. The hexagonal grid with the chosen total number of bins must be able to capture the structure of the NLDR data. If the number of bins is too low, the model may not be able to capture the structure of the NLDR data effectively (see @fig-binsize (a)), while if there are too many bins, it may result in over-fitting the individual points of the NLDR data (see @fig-binsize (c)). Therefore, it is important to determine an appropriate number of bins to build an effective model.

```{r}
#| echo: false
#| message: false
#| warning: false

num_bins_x <- 3
num_bins_y <- 4
hex_size <- 0.62


hb_obj <- hex_binning(data = umap_s_curve_scaled, x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x, 
                      num_bins_y = num_bins_y, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj$centroids))
counts_df <- as.data.frame(do.call(cbind, hb_obj$std_cts))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj$hex_poly))

hex_full_count_df_loop1 <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

p1 <-  ggplot(data = hex_full_count_df_loop1, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
  geom_point(data = umap_s_curve_scaled, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  #coord_equal() +
  #coord_cartesian(xlim =c(-5, 7), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "a", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

```


```{r}
#| echo: false
#| message: false
#| warning: false

num_bins_x <- 6
num_bins_y <- 14
hex_size <- 0.13


hb_obj <- hex_binning(data = umap_s_curve_scaled, x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x, 
                      num_bins_y = num_bins_y, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj$centroids))
counts_df <- as.data.frame(do.call(cbind, hb_obj$std_cts))


## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj$hex_poly))

hex_full_count_df_loop2 <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

p2 <-  ggplot(data = hex_full_count_df_loop2, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
  geom_point(data = umap_s_curve_scaled, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  #coord_equal() +
  #coord_cartesian(xlim =c(-1, 2.7), ylim = c(-2, 12.2)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "b", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

```

```{r}
#| echo: false
#| message: false
#| warning: false

num_bins_x <- 12
num_bins_y <- 28
hex_size <- 0.06


hb_obj <- hex_binning(data = umap_s_curve_scaled, x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x, 
                      num_bins_y = num_bins_y, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj$centroids))
counts_df <- as.data.frame(do.call(cbind, hb_obj$std_cts))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj$hex_poly))

hex_full_count_df_loop3 <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

p3 <-  ggplot(data = hex_full_count_df_loop3, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
  geom_point(data = umap_s_curve_scaled, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  #coord_equal() +
  #coord_cartesian(xlim =c(-1, 2.7), ylim = c(-2, 12.2)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "c", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

```

```{r}
#| echo: false
#| label: fig-binsize
#| fig-pos: H
#| fig-cap: "Hexbin plots from different number of bins for the **UMAP** embeddings of **S-curve** training data: (a) b = 12 (3, 4), h = 0.62, (b) b = 84 (6, 14), h = 0.13, and (c) b = 336 (12, 28), h = 0.06. The hexbins are colored based on the density of points, with darker colors indicating higher point density and yellow color representing lower point density within each bin. What is the number of bins that would be effective in representing low-dimensional data?"

p1 + p2 + p3
``` 

$$
b = b_1 \times b_2
$${#eq-equation8}

Furthermore, the total number of bins is determined by the number of bins along the x-axis and y-axis (see @eq-equation8). To calculate the effective total number of bins, candidate values are selected based on the range between the minimum and approximate maximum number of bins along the x and y axes. The minimum number of bins along each axis is set to $1$, while the maximum number is estimated by taking the square root of the NLDR data point count. The analysis evaluates the MSE across varying total bin counts within this range, covering the minimum to maximum values along both axes.

The analysis focuses on exploring the effect of total number of bins on MSE. It considers MSE across different total number of bins, covering the range calculated from the minimum to maximum values along both x and y axes.

Typically, the MSE plot tends to have a steep slope at the beginning, indicating that a smaller number of bins causes a larger amount of error. Then, the slope gradually declines or levesl off, indicating that a higher number of bins generates a smaller error. This MSE plot is useful in determining the effective number of bins required to construct the 2D model. @fig-diagnosticpltScurve (b) has created a graph that shows how the Mean Squared Error (MSE) changes depending on the number of bins assigned in the hexagonal grid for UMAP applied to the S-curve dataset. As per the rule of thumb mentioned earlier, the effective number of bins is determined to be $84$, with $6$ bins along the x-axis and $14$ bins along the y-axis. Furthermore, @fig-modelScurve shows the 2D model constructed using UMAP with the selected total number of bins and how the model overlay on high-D data.


```{r}
#| warning: false
#| echo: false
#| message: false

## UMAP

hex_size_vec <- seq(0.06, 2, by = 0.01)

vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names

mse_df <- dplyr::bind_rows(vec)[0, ]
mse_df <- mse_df |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = umap_s_curve_scaled, 
            x = "UMAP1", y = "UMAP2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data, 
                                   nldr_df_with_id = umap_s_curve_scaled, 
                                   x = "UMAP1", y = "UMAP2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "UMAP", 
                                   col_start_highd = "x")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "UMAP")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "x")
  
  mse_df <- mse_df |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df <- dplyr::bind_rows(not_dupli_df, duplicate_df)
```

```{r}
#| warning: false
#| echo: false

## To draw with AIC
aic_plot <- ggplot(mse_df, aes(x = num_bins, y = aic
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 84, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("AIC") +
  xlab("total number of bins")
## Effective number of bins along x-axis

mse_plot <- ggplot(mse_df, aes(x = num_bins,
                                       y = mse
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 84, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from UMAP applied to training S-curve dataset. What is the effective number of bins in each NLDR technique to create a 2D model? The MSE plot have a steep slope at the beginning, indicating that a smaller number of bins causes a larger amount of error. Then, the slope gradually declines or level off, indicating that a higher number of bins generates a smaller error. Using the elbow method, when the total number of bins is set to $84$, the slope of the Mean Squared Error (MSE) plot experiences a sudden and noticeable change, resembling an elbow-like shape. This point indicates that adding less bins does not enough to capture the data structure."
#| label: fig-diagnosticpltScurve
##| out-width: 100%
#| fig-pos: H

aic_plot + mse_plot +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```

```{r msebinsnldr}
#| echo: false
#| message: false
#| warning: false

# num_bins_for_nldr_methods_df <- tibble::tibble(NLDR_technique = "tSNE", tot_bins = 72, aic = -21882.462)
# 
# num_bins_for_nldr_methods_df <- num_bins_for_nldr_methods_df |> 
#   tibble::add_row(NLDR_technique = "UMAP", tot_bins = 98, aic = -20013.266)
# 
# num_bins_for_nldr_methods_df <- num_bins_for_nldr_methods_df |> 
#   tibble::add_row(NLDR_technique = "PHATE", tot_bins = 90, aic = -15036.91)
# 
# num_bins_for_nldr_methods_df <- num_bins_for_nldr_methods_df |> 
#   tibble::add_row(NLDR_technique = "TriMAP", tot_bins = 154, aic = -23001.90)
# 
# num_bins_for_nldr_methods_df <- num_bins_for_nldr_methods_df |> 
#   tibble::add_row(NLDR_technique = "PaCMAP", tot_bins = 132, aic = -21330.059)
# 
# # knitr::kable(
# #   num_bins_for_nldr_methods_df,
# #   col.names = c('NLDR technique', 'total number of bins'), format = "latex", 
# #              caption = "Total number of bins suggested by rule of thumb for each NLDR technique applied to S-curve dataset."
# # ) |> 
# #   kable_styling(latex_options = c("striped", "HOLD_position"), position = "center", full_width = FALSE) |>
# #   row_spec(0, bold = TRUE)
# num_bins_for_nldr_methods_df$tot_bins <- as.character(num_bins_for_nldr_methods_df$tot_bins)
# colnames(num_bins_for_nldr_methods_df) <- c('NLDR technique', 'total number of bins', "AIC")
# num_bins_for_nldr_methods_df <- tibble::remove_rownames(num_bins_for_nldr_methods_df)
# 
# xtable(num_bins_for_nldr_methods_df, caption = "Total number of bins suggested by rule of thumb and AIC values for each NLDR technique applied to S-curve dataset.", label = "tbl-msebinsnldr") |>
#   xtable2kable() |> 
#   kable_styling(latex_options = c("striped", "HOLD_position"), position = "center", full_width = FALSE) |>
#   row_spec(0, bold = TRUE) |>
#   row_spec(4, bold=T, color = "red")


```




<!--Adjusting the parameter $b_1$ provides control over the total number of bins $b$, allowing us to fine-tune the hexagonal grid.-->

<!--first value-->
        
        
<!--                  
```{r}
#| echo: false
#| message: false
#| warning: false
#| eval: false
hex_full_count_df_loop1 <- read_rds("data/s_curve/s_curve_hex_3.rds") 

p1 <-  ggplot(data = hex_full_count_df_loop1, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = polygon_id, fill = std_counts)) +
  geom_point(data = UMAP_data, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_cartesian(xlim =c(-5, 7), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "a", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

```
                
                
```{r}
#| echo: false
#| message: false
#| warning: false
#| eval: false
hex_full_count_df_loop2 <- read_rds("data/s_curve/s_curve_hex_11.rds") 

p2 <-  ggplot(data = hex_full_count_df_loop2, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = polygon_id, fill = std_counts)) +
  geom_point(data = UMAP_data, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_cartesian(xlim =c(-5, 7), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "b", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| eval: false
hex_full_count_df_loop3 <- read_rds("data/s_curve/s_curve_hex_20.rds") 

p3 <-  ggplot(data = hex_full_count_df_loop3, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = polygon_id, fill = std_counts)) +
  geom_point(data = UMAP_data, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_cartesian(xlim =c(-5, 7), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "c", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

```

```{r}
#| eval: false
#| echo: false
#| label: fig-binsize1
#| fig-pos: H
#| fig-cap: "Hexbin plots from different number of bins for the **UMAP** projections of **S-curve** training data: (a) b = 32 (4, 8), s = 1.643542, (b) b = 264 (12, 22), s = 1.643542, and (c) b = 840 (21, 40), s = 1.643542. The hexbins are colored based on the density of points, with darker colors indicating higher point density and yellow color representing lower point density within each bin. What is the number of bins that would be effective in representing low-dimensional data?"

p1 + p2 + p3
```

```{r}
#| warning: false
#| echo: false
#| eval: false

## UMAP
## Prediction

data <- read_rds("data/s_curve/s_curve.rds")

shape_value_curve <- calculate_effective_shape_value(.data = UMAP_data,
                                                   x = UMAP1, y = UMAP2)

num_bins_vec <- 1:13 ## Number of bins along the x-axis

vec <- stats::setNames(rep("", 5), c("number_of_bins", "number_of_observations", "total_error", "total_mse", "num_bins_x"))  ## Define column names

eval_data_training <- dplyr::bind_rows(vec)[0, ]
eval_data_training <- eval_data_training |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(num_bins_vec)) {
  
  model_object <- fit_high_d_model(training_data = training_data, nldr_df_with_id = UMAP_data, x = "UMAP1", y = "UMAP2", num_bins_x = num_bins_vec[i], shape_val = shape_value_curve,
                             is_bin_centroid = TRUE,
                             is_rm_lwd_hex = FALSE,
                             benchmark_to_rm_lwd_hex = NA,
                             is_avg_high_d = TRUE, column_start_text = "x")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_df_training <- predict_2d_embeddings(test_data = training_data, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, type_NLDR = "UMAP")
  
  # pred_df_training <- predict_hex_id(df_bin_centroids = centroid_df_training, nldr_df_test = UMAP_data, x = "UMAP1", y = "UMAP2")

  
  eval_df_training <- generate_eval_df(data = data, prediction_df = pred_df_training, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, col_start = "x")
  
  eval_df_training <- eval_df_training |>
    mutate(num_bins_x = num_bins_vec[i])
  
  eval_data_training <- dplyr::bind_rows(eval_data_training, eval_df_training)
  
  
}


## Add new column with data types

MSE_df_umap_s_curve <- eval_data_training |>
  mutate(data_type = "training",
         method = "UMAP")
```

```{r}
#| warning: false
#| echo: false
#| eval: false

## To draw with AIC
aic_plot <- ggplot(MSE_df_umap_s_curve |> dplyr::filter(data_type == "training") |> dplyr::filter(method == "UMAP"), aes(x = number_of_bins,
                                                                                 y = total_error,
                                                                                 color = method
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 144, linetype="dashed", 
                color = "red", size=0.5) +
  #geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  #annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=-5000, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  scale_colour_manual(values = c("#377eb8")) +
  ylab("AIC") +
  xlab("total number of bins")
## Effective number of bins along x-axis

mse_plot <- ggplot(MSE_df_umap_s_curve |> dplyr::filter(method == "UMAP"), aes(x = number_of_bins,
                                       y = total_mse,
                                       color = method
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 144, linetype="dashed", 
                color = "red", size=0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  # geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  # annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=0.25, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

-->

#### Benchmark value to remove low-density hexagons

After setting up the hexagonal grid with an appropriate number of bins, it is possible that some hexagonal bins may have very few or no data points within them. To ensure comprehensive coverage of the NLDR data, it is necessary to select hexagonal bins that have a considerable number of data points within their hexagons. To achieve this, the standard number of points within each hexagon is first calculated. This standard count is obtained by dividing the number of points within each hexagon by the maximum number of points in the grid (see @eq-equationp2). Next, the bins that have a standard number of points less than a certain benchmark value are removed. After removing the hexagons that have insufficient data density, the hexagons with more substantial data representation are used to construct the 2D model.

$$
\text{standard count} = \frac{\text{count}}{\text{max count}} 
$${#eq-equationp2}

Furthermore, it is crucial to choose the benchmark value to remove low-density hexagons carefully. If we remove unnecessary bins, then it may result in long edges and an uneven 2D model. Therefore, instead of removing hexagons only identified by the benchmark value, we examine the standard number of points in the neighboring hexagons of the identified low-density hexagons. If the neighboring bins also have low counts, then only those bins will be removed. The other identified bins will be kept and used for constructing the 2D model along with the high-density bins (see Appendix for more details).

The benchmark value for removing low-density hexagons has a range of $0$ and $1$. When analyzing how these benchmark values affect model performance, it's important to observe the change in Mean Squared Error (MSE) as the benchmark value increases. The MSE exhibits a gradual increase as the benchmark value progresses from $0$ to $1$. Assessing this rate of increase is crucial. If the increment is not substantial, the decision might lean towards retaining low-density hexagons. According to @fig-diagnosticpltScurvelwd, the change in MSE for NLDR techniques is relatively small across different benchmark values, except for the PHATE method.

Consequently, it is not necessary to remove low-density hexagons when constructing the 2D model for the S-curve dataset in NLDR techniques, except for PHATE. While there may be some fluctuations in MSE between benchmark values of 0 to 1, the absence of significant changes suggests that maintaining low-density hexagons is preferable. However, to choose the best selection, it's recommended to examine the benchmark values around the first local minimum in the MSE curve. However, the MSE for PHATE fluctuates when benchmark values range between 0 and 1. Therefore, it is necessary to explore the benchmark values surrounding the first local minimum to determine an effective benchmark value. There is no universal rule for selecting a process. As shown in @fig-diagnosticpltScurvelwd, the MSE values for PHATE fluctuate, and the first local minimum is at $0$. Therefore, nearby benchmark values such as $0.01$, $0.04$, and $0.06$ were explored to identify the best value for preserving the data structure. In this case, a benchmark value of $0.06$ was chosen. The resulting 2D model is shown in @fig-modelScurve (c), while the video link provides a visual representation of how the model appears in high-D.

The following steps will help to find a suitable value to remove low density hexagons:

1. Plot the distribution of the standardized counts

2. See the distribution of counts

3. Take the first quartile 

<!--
```{r}
#| echo: false
#| message: false
#| warning: false
#| eval: false

hex_full_count_df_loop2 <- read_rds("data/s_curve/s_curve_hex_8.rds") 

hex_full_count_df_loop2 <- hex_full_count_df_loop2 |>
  dplyr::mutate(type = if_else(std_counts <= 0.20, "low", "high"))

hex_full_count_df_filtered <- hex_full_count_df_loop2 |>
  dplyr::filter(type == "low")


p2_n <-  ggplot(data = hex_full_count_df_loop2, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = polygon_id, fill = std_counts)) +
  #geom_point(data = UMAP_data, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  #coord_cartesian(xlim =c(-5, 7), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) #+
  #annotate(geom = 'text', label = "b", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 


p2_n_rm <-  ggplot(data = hex_full_count_df_loop2, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = polygon_id, fill = std_counts)) +
  geom_text(data = hex_full_count_df_filtered, color = "red", aes(x = c_x, y = c_y, group = polygon_id, label = "X", size = 0.5)) +
  #geom_point(data = UMAP_data, aes(x = UMAP1, y = UMAP2), alpha = 0.5) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  #coord_cartesian(xlim =c(-5, 7), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) #+
  #annotate(geom = 'text', label = "b", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

## Import data

UMAP_s_curve <- read_rds("data/s_curve/s_curve_umap.rds")

## UMAP

num_bins_umap_s_curve <- 8
shape_val_umap_s_curve <- calculate_effective_shape_value(.data = UMAP_s_curve,
                                                          x = UMAP1, y = UMAP2) ## 1.259938
## To extract bin centroids
hexbin_data_object_umap_s_curve <- extract_hexbin_centroids(nldr_df = UMAP_s_curve, num_bins = num_bins_umap_s_curve, shape_val = shape_val_umap_s_curve, x = UMAP1, y = UMAP2)

df_bin_centroids_umap_s_curve <- hexbin_data_object_umap_s_curve$hexdf_data

cell_count_plot_s_curve <- ggplot(df_bin_centroids_umap_s_curve, aes(x = reorder(as.factor(hexID), -std_counts), y = std_counts)) +
  geom_quasirandom() + xlab("hexagonal id") + ylab("Standardized cell count") +
  geom_hline(yintercept = 0.20, colour = "#de2d26") +
  theme(axis.text = element_text(size = 5),
        axis.title = element_text(size = 7),
        axis.text.x = element_text(angle = 90))

df_bin_centroids_umap_s_curve <- df_bin_centroids_umap_s_curve |>
  dplyr::filter(std_counts > 0.20)

## Triangulate bin centroids
tr1_object_umap_s_curve <- triangulate_bin_centroids(df_bin_centroids_umap_s_curve, x, y)
tr_from_to_df_umap_s_curve <- generate_edge_info(triangular_object = tr1_object_umap_s_curve)

## Compute 2D distances
distance_umap_s_curve <- cal_2d_dist(.data = tr_from_to_df_umap_s_curve)

## To find the benchmark value
benchmark_umap_s_curve <- find_benchmark_value(.data = distance_umap_s_curve, distance_col = distance)



trimesh_umap_s_curve_rm_low <- ggplot(df_bin_centroids_umap_s_curve, aes(x = x, y = y)) +
  geom_segment(data = tr_from_to_df_umap_s_curve, aes(x = x_from, y = y_from, xend = x_to, yend = y_to)) +
  geom_point(size = 2, colour = "#33a02c") +
  coord_equal()

trimesh_umap_s_curve_rm_low <- trimesh_umap_s_curve_rm_low +
  coord_cartesian(xlim =c(-5, 7.5), ylim = c(-10, 10)) +
  #ggtitle("(a)") +
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) #+
  #annotate(geom = 'text', label = 'c', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) 

```

```{r}
#| eval: false
#| echo: false
#| warning: false
#| fig-cap: Goodness of f
#| label: fig-rmlowdenshex
#| fig-pos: H
##| out-width: 100%

p2_n + p2_n_rm + trimesh_umap_s_curve_rm_low +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides='collect', ncol = 3) &
  theme(legend.position='bottom', plot.tag = element_text(size = 8))
```

-->

<!--Addressing low-density hexagons is a systematic process to handle sparsely represented data in certain regions. For each hex bin, we identify the six nearest hex bins using an equal 2D distance metric. Then, we calculate the mean density, as outlined in the equations:

$$
\text{standard count} = \frac{\text{count}}{\text{max count}} 
$${#eq-equationp2}

$$
\text{mean density} = \frac{\text{standard count}}{6} 
$${#eq-equationp3}

The standard count is derived from the number of observations in the hex bins. By examining the distribution of mean densities and designating the first quartile as the benchmark value, hex bins with mean densities below this benchmark are removed. This process ensures the elimination of regions with insufficient data density, focusing on areas with more significant data representation and preserving the overall structure in the low-dimensional space.-->

<!--lwd smoothing criteria 1 with s-curve-->
<!--
```{r}
#| warning: false
#| echo: false
#| eval: false

MSE_df_1_lwd <- read_rds("data/s_curve/s_curve_summary_lwd_tsne.rds")
MSE_df_2_lwd <- read_rds("data/s_curve/s_curve_summary_lwd_umap.rds")
MSE_df_3_lwd <- read_rds("data/s_curve/s_curve_summary_lwd_phate.rds")
MSE_df_4_lwd <- read_rds("data/s_curve/s_curve_summary_lwd_trimap.rds")
MSE_df_5_lwd <- read_rds("data/s_curve/s_curve_summary_lwd_pacmap.rds")

MSE_df_lwd <- dplyr::bind_rows(MSE_df_1_lwd, MSE_df_2_lwd, MSE_df_3_lwd, MSE_df_4_lwd, MSE_df_5_lwd)

MSE_df_lwd$method <- factor(MSE_df_lwd$method, levels = c("tSNE", "UMAP", "PHATE", "TriMAP", "PaCMAP"))

## To draw with AIC
aic_plot_lwd <- ggplot(MSE_df_lwd |> dplyr::filter(data_type == "training") |> dplyr::filter(method == "UMAP"), aes(x = benchmark_rm_hex,
                                                                                 y = total_error,
                                                                                 color = method
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 0.2, linetype="dashed", 
                color = "red", size=0.5) +
  #geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  #annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=-5000, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  scale_colour_manual(values = c("#377eb8", "#e41a1c", "#4daf4a", "#984ea3", "#ff7f00")) +
  ylab("AIC") +
  xlab("benchmark value")
## Effective number of bins along x-axis

mse_plot_lwd <- ggplot(MSE_df_lwd |> dplyr::filter(method == "UMAP"), aes(x = benchmark_rm_hex,
                                       y = total_mse,
                                       color = method
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 0.2, linetype="dashed", 
                color = "red", size=0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  # geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  # annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=0.25, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  scale_colour_manual(values = c("#377eb8", "#e41a1c", "#4daf4a", "#984ea3", "#ff7f00")) +
  ylab("MSE") +
  xlab("benchmark value")

```

```{r}
#| eval: false
#| echo: false
#| warning: false
#| fig-cap: "Goodness of fit statistics from UMAP applied to training S-curve dataset with different benchmark values to remove the low-density heaxgons. What is the effective benchmark value to remove the low-density heaxgons? The MSE plot have a steep slope at the beginning, indicating that a smaller benchmark causes a small amount of error. Then, the slope gradually increases or level up, indicating that a higher number of benchmark values generates a higher error. Using the reverse elbow method, when the benchmark value is set to 0.2, the slope of the Mean Squared Error (MSE) plot experiences a sudden and noticeable change, resembling an elbow-like shape. This point indicates that higher benchmark values remove the necessary bins as well which lead to distruct the 2D structure."
#| label: fig-diagnosticpltScurvelwd
##| out-width: 100%
#| fig-pos: H

aic_plot_lwd + mse_plot_lwd +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```
-->

```{r}
#| warning: false
#| echo: false
#| message: false

## Decide by looking at MSE plot
num_bins_x_s_curve <- 6
num_bins_y_s_curve <- 14
hex_size_s_curve <- 0.13

hb_obj_s_curve <- hex_binning(data = umap_s_curve_scaled, x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x_s_curve, 
                      num_bins_y = num_bins_y_s_curve, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_s_curve, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_s_curve$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_s_curve$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_s_curve$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
pcentroid_plot_s_curve <- ggplot(data = hex_grid, aes(x = x, y = y)) +
  geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
  geom_point(data = df_bin_centroids, aes(x = c_x, y = c_y), color = "#33a02c") +
  coord_fixed() +
  theme_linedraw() +
  theme(legend.position = "bottom", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) 

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

umap_data_with_hb_id <- as.data.frame(do.call(cbind, hb_obj_s_curve$data_hb_id))
  
model_object <- fit_highd_model( training_data = training_data, 
                                 nldr_df_with_id = umap_s_curve_scaled, 
                                 x = "UMAP1", y = "UMAP2", 
                                 num_bins_x = num_bins_x_s_curve, 
                                 num_bins_y = num_bins_y_s_curve, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_s_curve,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "UMAP", 
                                 col_start_highd = "x")

df_bin_centroids_s_curve <- model_object$df_bin_centroids
df_bin_s_curve <- model_object$df_bin

## Triangulate bin centroids
tr1_object_s_curve <- tri_bin_centroids(df_bin_centroids_s_curve, x = "c_x", y = "c_y")
tr_from_to_df_s_curve <- gen_edges(tri_object = tr1_object_s_curve)

## Compute 2D distances
distance_s_curve <- cal_2d_dist(tr_coord_df = tr_from_to_df_s_curve, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_pbmc) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_s_curve <- find_lg_benchmark(distance_edges = distance_s_curve, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_pbmc, mapping = aes(x = c_x, y = c_y))

trimesh_s_curve_umap <- vis_lg_mesh(distance_edges = distance_s_curve, benchmark_value = benchmark_s_curve, tr_coord_df = tr_from_to_df_s_curve, distance_col = "distance")

trimesh_s_curve_umap <- trimesh_s_curve_umap +
  theme_linedraw() +
  theme(legend.position = "bottom", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) +
  labs(colour = "")

trimesh_removed_s_curve_umap <- vis_rmlg_mesh(distance_edges = distance_s_curve, benchmark_value = benchmark_s_curve, tr_coord_df = tr_from_to_df_s_curve, distance_col = "distance")

trimesh_removed_s_curve_umap <- trimesh_removed_s_curve_umap +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'c', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)
```

```{r}
#| echo: false
#| fig-cap: "(a), (b) 2D model."
#| label: fig-modelScurve

pcentroid_plot_s_curve + trimesh_s_curve_umap + trimesh_removed_s_curve_umap +
  plot_layout(guides='collect', ncol = 3) &
  theme(legend.position='bottom') 
```


#### Benchmark value to remove long edges

Achieving a smooth representation in 2D space is crucial, and one factor influencing this smoothness is the presence of long edges (see @fig-modelScurvermlgimp). These long edges occur when a line connects points that are distant in the triangular mesh, impacting the overall smoothness of the mesh.

To investigate the effect of removing long edges on the MSE, we analyzed the MSE for various benchmark values. Surprisingly, the results indicated that the MSE remained consistent across different benchmark values, as shown in @fig-diagnosticpltScurvelgrm. It's important to note that edges are defined only in the 2D model and do not extend to higher dimensions. Consequently, removing edges does not affect the model in higher dimensions.

There is no definitive rule for determining the benchmark value to remove long edges. However, we have a method to find a default value (see Appendix). Adjusting values around this default can help to find benchmark value to remove long edges, contributing to the construction of a smoother 2D representation (see @fig-diagnosticpltScurvelgrm).

The following steps will help to find a suitable value to remove long edges:

1. Plot the distribution of the 2D distances

2. Find a value which is greater than smallest value


<!--The removal of long edges is a critical step to create a smoother representation  by iteratively eliminating hexagons with excessive distances between centroids. This process eliminates outliers and noise while preserving essential local relationships within the data. To achieve this, distances between vertices are sorted, and unique distance values are extracted. By setting a threshold based on the largest difference between consecutive distance values, long edges are identified and removed. This refinement step contributes to enhancing the quality of the triangular mesh, ensuring a more accurate representation of the data structure.-->
<!--
```{r}
#| warning: false
#| echo: false
#| eval: false

## Import data

UMAP_s_curve <- read_rds("data/s_curve/s_curve_umap.rds")

## UMAP

num_bins_umap_s_curve <- 8
shape_val_umap_s_curve <- calculate_effective_shape_value(.data = UMAP_s_curve,
                                                          x = UMAP1, y = UMAP2) ## 1.259938
## To extract bin centroids
hexbin_data_object_umap_s_curve <- extract_hexbin_centroids(nldr_df = UMAP_s_curve, num_bins = num_bins_umap_s_curve, shape_val = shape_val_umap_s_curve, x = UMAP1, y = UMAP2)

df_bin_centroids_umap_s_curve <- hexbin_data_object_umap_s_curve$hexdf_data

UMAP_data_with_hb_id_s_curve <- UMAP_s_curve |>
  dplyr::mutate(hb_id = hexbin_data_object_umap_s_curve$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all_umap_s_curve <- dplyr::bind_cols(training_data |> dplyr::select(-ID), UMAP_data_with_hb_id_s_curve)

## Averaged on high-D
df_bin_umap_s_curve <- avg_highD_data(.data = df_all_umap_s_curve)

## Triangulate bin centroids
tr1_object_umap_s_curve <- triangulate_bin_centroids(df_bin_centroids_umap_s_curve, x, y)
tr_from_to_df_umap_s_curve <- generate_edge_info(triangular_object = tr1_object_umap_s_curve)

# ggplot(df_bin_centroids_umap_s_curve, aes(x = x, y = y)) +
#   geom_segment(data = tr_from_to_df_umap_s_curve, aes(x = x_from, y = y_from, xend = x_to, yend = y_to)) +
#   geom_point(size = 2, colour = "#33a02c") +
#   coord_equal()


## Compute 2D distances
distance_umap_s_curve <- cal_2d_dist(.data = tr_from_to_df_umap_s_curve)

distance_plot_s_curve <- plot_dist(distance_umap_s_curve) +
  #ggtitle("(b)" ) +
  ylab(expression(d^{(2)})) +
  theme(axis.text = element_text(size = 5),
        axis.title = element_text(size = 12))

## To find the benchmark value
benchmark_umap_s_curve <- find_benchmark_value(.data = distance_umap_s_curve, distance_col = distance)
benchmark_umap_s_curve <- 1.346694


# colour_long_edges(.data = distance_umap_s_curve, benchmark_value = benchmark_umap_s_curve,
#                   triangular_object = tr1_object_umap_s_curve, distance_col = distance)



trimesh_umap_s_curve <- ggplot(df_bin_centroids_umap_s_curve, aes(x = x, y = y)) +
  geom_segment(data = tr_from_to_df_umap_s_curve, aes(x = x_from, y = y_from, xend = x_to, yend = y_to)) +
  geom_point(size = 2, colour = "#33a02c") +
  coord_equal()

trimesh_umap_s_curve <- trimesh_umap_s_curve +
  #ggtitle("(a)") +
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) 
# theme(axis.text = element_text(size = 5),
#       axis.title = element_text(size = 7))

trimesh_gr_umap_s_curve <- colour_long_edges(.data = distance_umap_s_curve, benchmark_value = benchmark_umap_s_curve, triangular_object = tr1_object_umap_s_curve, distance_col = distance)

trimesh_gr_umap_s_curve <- trimesh_gr_umap_s_curve +
  geom_point(size = 2, colour = "#33a02c") +
  #ggtitle("(b)") +
  xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  theme_light() +
  #coord_equal() +
  theme(legend.position = "none", plot.title = element_text(size = 5, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()#change legend key width
  ) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) 


# ### Define type column
# df <- df_all_umap_s_curve |>
#   dplyr::select(tidyselect::starts_with("x")) |>
#   dplyr::mutate(type = "data") ## original dataset
# 
# df_b <- df_bin_umap_s_curve |>
#   dplyr::filter(hb_id %in% df_bin_centroids_umap_s_curve$hexID) |>
#   dplyr::select(-hb_id) |>
#   dplyr::mutate(type = "model") ## Data with summarized mean
# 
# df_exe <- dplyr::bind_rows(df_b, df)
# 
# distance_df_small_edges <- distance_umap_s_curve %>%
#   dplyr::filter(distance < benchmark_umap_s_curve)
# 
# distance_df_long_edges <- distance_umap_s_curve %>%
#   dplyr::filter(distance >= benchmark_umap_s_curve)
# 
# distance_df_edges <- dplyr::bind_rows(distance_df_small_edges, distance_df_long_edges)
# 
# langevitour::langevitour(df_exe[1:(length(df_exe)-1)], lineFrom = distance_df_edges$from , lineTo = distance_df_edges$to, group = df_exe$type, pointSize = 3, levelColors = c("#6a3d9a", "#33a02c"), lineColors = append(rep("black", length(distance_df_small_edges$from)), rep("red", length(distance_df_long_edges$from))))
# 

```

```{r}
#| eval: false
#| warning: false
#| echo: false
#| label: fig-modelScurverdistcount
#| fig-cap: "plots to identify benchmark values"
##| out-width: 100%
#| fig-pos: H

cell_count_plot_s_curve + distance_plot_s_curve +
  #plot_annotation(tag_levels = 'a') +
  plot_layout(ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```



```{r}
#| eval: false
#| warning: false
#| echo: false
#| label: fig-modelScurvermlgimp
#| fig-cap: "What does the 2D model, constructed using UMAP (applied to the S-curve dataset), look like in high dimensions with long edges? (<https://youtu.be/pSL_G_n7-fM>) (a) 2D model without removing the long edges, and (b) 2D model with long edges coloured by red. The default benchmark value is used to identify long edges."
##| out-width: 100%
#| fig-pos: H

trimesh_umap_s_curve + trimesh_gr_umap_s_curve +
  #plot_annotation(tag_levels = 'a') +
  plot_layout(ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```
-->

#### Starting point of the hexagonal grid

According to @Dan2023, the hexagonal binning is done by tessellating the $xy$ plane over the set (range($x$), range($y$)) (see @fig-scurveshifthexgridsexp (b)). In that case, bin centroids are defined as shown in @fig-scurveshifthexgridsexp (a) with gray colour. Rather than sticking to the typical hexagonal grid, introducing a meaningful shift in both the x and y directions presents an opportunity for an improved 2D model. Therefore, investigating this shift in the hexagonal grid is an important parameter to consider.

As shown in @fig-scurveshifthexgrids, the shifting influences the distribution of points and number of non-empty bins, impacting the resulting 2D model. According to @fig-diagnosticpltScurvehexbins, the 2D model with a total of $144$ bins applied to S-curve UMAP data does not require any shifting because the lowest MSE occurs when no shift is introduced.

<!--

```{r}
#| eval: false
#| echo: false
#| warning: false

hex_full_count_df <- read_rds("data/s_curve/s_curve_hex_8.rds")

shifted_hex_coord_df <- read_rds("data/s_curve/s_curve_hex_8_shifted_hex_coord_df.rds")

bin_centroids_shift <- ggplot(data = hex_full_count_df, aes(x = c_x, y = c_y)) +
  geom_point(color = "#bdbdbd") +
  geom_point(data = shifted_hex_coord_df, aes(x = c_x, y = c_y), color = "#feb24c") +
  coord_cartesian(xlim = c(-5, 8), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "a", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

hex_grid_shift <- ggplot(data = shifted_hex_coord_df, aes(x = x, y = y)) +
  geom_polygon(fill = NA, color = "#feb24c", aes(group = polygon_id)) +
  geom_polygon(data = hex_full_count_df, aes(x = x, y = y, group = polygon_id),
               fill = NA, color = "#bdbdbd") +
  coord_cartesian(xlim = c(-5, 8), ylim = c(-10, 10)) +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "b", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

## Before shift
before_shift_plot <- ggplot(data = hex_full_count_df, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = polygon_id, fill = std_counts)) +
  geom_text(aes(x = c_x, y = c_y, label = hexID), size = 2) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_equal() +
  theme_void() +
  theme(legend.position="bottom", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "a", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 


## After shift
after_shift_plot <- ggplot(data = shifted_hex_coord_df, aes(x = x, y = y)) +
  geom_polygon(color = "black", aes(group = polygon_id, fill = std_counts)) +
  geom_text(aes(x = c_x, y = c_y, label = hexID), size = 2) +
  scale_fill_viridis_c(direction = -1, na.value = "#ffffff", option = "C") +
  coord_equal() +
  theme_void() +
  theme(legend.position="none", legend.direction="horizontal", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=8), #change legend title font size
        legend.text = element_text(size=6)) +
  guides(fill = guide_colourbar(title = "Standardized count")) +
  annotate(geom = 'text', label = "b", x = -Inf, y = Inf, hjust = -0.3, vjust = 1, size = 3) 

```

```{r}
#| eval: false
#| echo: false
#| fig-cap: "(a) Visualization of bin centroids and (b) hexagonal grid, showcasing the configuration before (colored in gray) and after (colored in light orange) shifting the starting point by an identical amount applied in both x and y directions, with a shift value of $0.537285$."
#| label: fig-scurveshifthexgridsexp
##| out-width: 100%
#| fig-pos: H

bin_centroids_shift + hex_grid_shift +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```

```{r}
#| eval: false
#| echo: false
#| fig-cap: "Hexbin plots shows the distribution of points before and after shifting the starting point of the hexagonal grid generated for UMAP applied to the training S-curve dataset. (a) Hexbin plot before shifting, and (b) Hexbin plot after shifting (identical shift applied in both x and y directions, with a shift value of $0.537285$)."
#| label: fig-scurveshifthexgrids
##| out-width: 100%
#| fig-pos: H

before_shift_plot + after_shift_plot +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```

```{r}
#| eval: false
#| warning: false
#| echo: false

#MSE_df <- dplyr::bind_rows(MSE_df_1, MSE_df_2, MSE_df_3, MSE_df_4, MSE_df_5)

#MSE_df$method <- factor(MSE_df$method, levels = c("tSNE", "UMAP", "PHATE", "TriMAP", "PaCMAP"))

MSE_df <- read_rds("data/s_curve/s_curve_umap_shift_summary.rds") 
MSE_df$method <- factor(MSE_df$method, levels = c("UMAP"))

## To draw with AIC
aic_plot <- ggplot(MSE_df |> dplyr::filter(data_type == "training") |> dplyr::filter(method == "UMAP"), aes(x = shift,
                                                                                 y = total_error,
                                                                                 color = method
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = MSE_df |> dplyr::filter(total_mse == min(total_mse)) |> dplyr::pull(shift), linetype="dashed",
                color = "red", size=0.5) +
  #geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  #annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=-5000, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  scale_colour_manual(values = c("#377eb8", "#e41a1c", "#4daf4a", "#984ea3", "#ff7f00")) +
  ylab("AIC") +
  xlab("shift value")
## Effective number of bins along x-axis

mse_plot <- ggplot(MSE_df |> dplyr::filter(method == "UMAP"), aes(x = shift,
                                       y = total_mse,
                                       color = method
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = MSE_df |> dplyr::filter(total_mse == min(total_mse)) |> dplyr::pull(shift), linetype="dashed",
                color = "red", size=0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  # geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  # annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=0.25, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  scale_colour_manual(values = c("#377eb8", "#e41a1c", "#4daf4a", "#984ea3", "#ff7f00")) +
  ylab("MSE") +
  xlab("shift value")

```

```{r}
#| eval: false
#| echo: false
#| fig-cap: "Goodness of fit statistics from UMAP applied to training S-curve dataset with different shift values. In this illustration, an identical shift is applied in both the x and y directions. The Mean Squared Error (MSE) plot exhibits a global minimum at $0$, indicating that no additional shifting is necessary for the current hexagonal grid to yield a well-fitted model."
#| label: fig-diagnosticpltScurvehexbins
##| out-width: 100%
#| fig-pos: H

aic_plot + mse_plot +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```
-->

### Model summaries {#sec-summary}

#### Predicted values and residuals

The prediction approach involves performing the K-nearest neighbors (KNN) algorithm for an unsupervised classification problem. First, the nearest high-D model point is identified for a given new high-D point. Then, the corresponding 2D centroid mapping for the identified high-D model point is determined. Finally, the coordinates of this 2D centroid are used as the predicted 2D embedding for the new high-D data point. This step is particularly valuable due to the limitations of some NLDR techniques, like tSNE, which don't provide a straightforward method for prediction. As a result, our approach offers a solution that capable of generating predicted 2D embedding regardless of the NLDR technique employed, effectively addressing this functional gap.

Residuals are essential for evaluating the accuracy of representing high-D points by the high-D mapping of 2D bin centroids. To measure this accuracy, an error metric is introduced, quantifying the sum of squared differences between the high-D data ($x_{ij}$) and the high-D mapping of the 2D bin centroid data ($C_{x_ij}$) across all observations and dimensions (see @eq-equation11).

$$
\text{Error} = \sum_{j = 1}^{n}\sum_{i = 1}^{p} (x_{ij} - C_{x_ij})^2
$$ {#eq-equation11}

Here, $n$ represents the number of observations, $p$ represents the dimensions of high-D data, $x_{ij}$ is the high-D data, and $C_{x_ij}$ is the high-D mapping of the 2D bin centroid.

<!--
The concept of "residuals" is pivotal in evaluating the accuracy of representing bin centroids in high-D. To quantify this accuracy, we introduce an error metric, which measures the sum of squared differences between the high-D data ($x_{ij}$) and the predicted bin centroid data in high-D space ($C_{x_ij}$) across all bins and dimensions. Mathematically, this error is expressed as:

$$
\text{Error} = \sum_{j = 1}^{n}\sum_{i = 1}^{p} (x_{ij} - C_{x_ij})^2
$$ {#eq-equation11}


Here, $n$ represents the number of observations, $p$ represents the dimensions, $x_{ij}$ is the high-D data, and $C_{x_ij}$ is the predicted bin centroid data in high-D.

The error metric outlined above provides valuable insights into the overall accuracy of our predictive model. By quantifying the squared deviations between the actual and predicted values across all bins and dimensions, we gain a comprehensive understanding of how well our method captures and represents the underlying structure of the data in the reduced 2D space. This assessment is crucial for evaluating the efficacy of our NLDR technique in preserving the essential information present in the original high-dimensional data.
-->

#### Goodness of fit statistics {#sec-goodfit}

To assess how well our method captures and represents the underlying structure of the high-D data, Mean Squared Error (MSE) and Akaike Information Criterion (AIC) are used. When computing MSE, total model error (see @sec-summary) is divided by the number of observations to make it as a mean value (see @eq-equation9).  

$$
\text{MSE} = \sum_{j = 1}^{n} \frac{\sum_{i = 1}^{p} (x_{ij} - C_{x_ij})^2}{n}
$$ {#eq-equation9}

Furthermore, to incorporate with the parameters in our model, which is the non-empty bins, and as a statistical measure used for model selection and comparison, AIC is used (see @eq-equation10).

$$
\text{AIC} = 2b'p + np * log(\text{MSE})
$$ {#eq-equation10}

Here, $b'$ signifies the number of bins non-empty bins, $p$ denotes the number of dimensions in the high-D data, and $n$ represents the number of observations.

### Simulated data example {#sec-simpleex}

In this section, we showcase the effectiveness of our methodology using simulated data. The dataset comprises five spherical Gaussian clusters in 4-$d$, with each cluster containing an equal number of points and consistent within variation.  

In the 2D representations created by all NLDR techniques, as shown in @fig-nldervis5Gau, except for PHATE, there are five distinct clusters. In tSNE, these five clusters are closely located to each other (see @fig-nldervis5Gau (a)). However, in PHATE, two clusters are closely positioned, while the other three are more distant (see @fig-nldervis5Gau (c)). In PaCMAP, one cluster is at the center, and the remaining four are positioned in four different directions (see @fig-nldervis5Gau (e)). In TriMAP, two clusters are close, although not as close as in PHATE, and the other three are well-separated (see @fig-nldervis5Gau (d)). In UMAP, all clusters are arranged in a parallel manner, with three in one line and the other two in a separate line (see @fig-nldervis5Gau (b)).

Visualizing the models alongside the original high-D data provides insights into how different techniques capture the underlying clustering structure. The tSNE model exhibits five well-separated clusters, effectively preserving both local and global structures (see video link of @fig-modelfiveGau (a)). UMAP, on the other hand, also presents five distinct clusters but with a more flattened surface appearance (see video link of @fig-modelfiveGau (b)). The PHATE model shows five separated clusters resembling triangles or partial triangles but struggles to capture local structures (see video link of @fig-modelfiveGau (c)). TriMAP and PaCMAP both display five well-separated clusters with flat surfaces, each capturing within-cluster variation to varying extents. Despite the various 2D representations, all NLDR techniques preserve the global structure (see video link of @fig-modelfiveGau (d), (e) respectively). However, tSNE, effectively capture both local and global structures, as indicated by lower AIC values in @fig-diagnosticpltGau (a).

<!-- five Gaussian clusters with different NLDR techniques-->
```{r}
#| warning: false
#| echo: false

## Import data
df_2 <- read_rds("data/five_gau_clusters/data_five_gau.rds")
training_data_gau <- read_rds("data/five_gau_clusters/data_five_gau_training.rds")
test_data_gau <- read_rds("data/five_gau_clusters/data_five_gau_test.rds")

tSNE_data_gau <- read_rds("data/five_gau_clusters/tsne_data_five_gau_61.rds")
UMAP_data_gau <- read_rds("data/five_gau_clusters/umap_data_five_gau.rds")
PHATE_data_gau <- read_rds("data/five_gau_clusters/phate_data_five_gau.rds")
TriMAP_data_gau <- read_rds("data/five_gau_clusters/trimap_data_five_gau.rds")
PaCMAP_data_gau <- read_rds("data/five_gau_clusters/pacmap_data_five_gau.rds")

## Visualise embeddings

plot_list1_gau <- plot_tSNE_2D(tSNE_data_gau) + 
  geom_point(size = 0.00001, colour = "#e41a1c") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)


plot_list2_gau <- plot_UMAP_2D(UMAP_data_gau) + 
  geom_point(size = 0.00001, colour = "#377eb8") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)


plot_list3_gau <- plot_PHATE_2D(PHATE_data_gau) + 
  geom_point(size = 0.00001, colour = "#4daf4a") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'c', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)


plot_list4_gau <- plot_TriMAP_2D(TriMAP_data_gau) + 
  geom_point(size = 0.00001, colour = "#984ea3") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'd', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

plot_list5_gau <- plot_PaCMAP_2D(PaCMAP_data_gau) + 
  geom_point(size = 0.00001, colour = "#ff7f00") +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5), 
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'e', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)
```

```{r}
#| echo: false
#| fig-cap: "2D layouts from different NLDR techniques applied the same data: (a) tSNE (perplexity = 61), (b) UMAP (n_neighbors = 15), (c) PHATE (knn = 5), (d) TriMAP (n_inliers = 5, n_outliers = 4, n_random = 3), and (e) PaCMAP (n_neighbors = 10, init = random, MN_ratio = 0.9, FP_ratio = 2). Is there a best representation of the original data or are they all providing  equivalent information?"
#| label: fig-nldervis5Gau
#| out-width: 100%

plot_list1_gau + plot_list2_gau + plot_list3_gau + plot_list4_gau + plot_list5_gau +
  plot_layout(ncol=5)
```

<!-- To find the number of bins should assign for the model in tSNE-->
```{r}
#| warning: false
#| echo: false
#| message: false

tsne_gau_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = tSNE_data_gau, 
                                    x = "tSNE1", y = "tSNE2"))) |>
  dplyr::rename(c("tSNE1" = "scaled_tSNE1", 
                  "tSNE2" = "scaled_tSNE2")) |>
  dplyr::mutate(ID = 1:NROW(tSNE_data_gau))    


## tSNE
hex_size_vec <- seq(0.02, 2, by = 0.01)

vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names

mse_df_gau <- dplyr::bind_rows(vec)[0, ]
mse_df_gau <- mse_df_gau |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = tsne_gau_scaled, 
            x = "tSNE1", y = "tSNE2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data_gau, 
                                   nldr_df_with_id = tsne_gau_scaled, 
                                   x = "tSNE1", y = "tSNE2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "tSNE", 
                                   col_start_highd = "x")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data_gau, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "tSNE")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data_gau, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "x")
  
  mse_df_gau <- mse_df_gau |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_gau |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df_gau |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_gau |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_gau <- dplyr::bind_rows(not_dupli_df, duplicate_df)
```

```{r}
#| warning: false
#| echo: false

## To draw with AIC
aic_plot_gau <- ggplot(mse_df_gau, aes(x = num_bins, y = aic
)) +
  geom_point(size = 0.8) +
  geom_line() +
  geom_vline(xintercept = 42, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("AIC") +
  xlab("total number of bins")
## Effective number of bins along x-axis

mse_plot_gau <- ggplot(mse_df_gau, aes(x = num_bins,
                                       y = mse
)) +
  geom_point(size = 0.8) +
  geom_line() +
   geom_vline(xintercept = 42, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from different NLDR techniques applied to training five spherical Gaussian cluster dataset. What is the best NLDR technique to represent the original data in 2D?"
#| label: fig-diagnosticpltGau
#| out-width: 100%

aic_plot_gau + mse_plot_gau +
  plot_layout(nrow = 2) +
  plot_annotation(tag_levels = 'a') +
  #plot_layout(guides='collect', nrow = 2) & legend.position='bottom', 
  theme(plot.tag = element_text(size = 8))
```

```{r}
#| warning: false
#| echo: false
#| message: false

## Decide by looking at MSE plot
num_bins_x_tsne_gau <- 21
num_bins_y_tsne_gau <- 28
hex_size_tsne_gau <- 0.03
## non-empty:198

hb_obj_tsne_gau <- hex_binning(data = tsne_gau_scaled, x = "tSNE1", 
                      y = "tSNE2", num_bins_x = num_bins_x_tsne_gau, 
                      num_bins_y = num_bins_y_tsne_gau, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_tsne_gau, col_start = "tSNE")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

tsne_data_with_hb_id_gau <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$data_hb_id))
  
model_object_tsne_gau <- fit_highd_model( training_data = training_data_gau, 
                                 nldr_df_with_id = tsne_gau_scaled, 
                                 x = "tSNE1", y = "tSNE2", 
                                 num_bins_x = num_bins_x_tsne_gau, 
                                 num_bins_y = num_bins_y_tsne_gau, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_tsne_gau,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "tSNE", 
                                 col_start_highd = "x")

df_bin_centroids_tsne_gau <- model_object_tsne_gau$df_bin_centroids
df_bin_tsne_gau <- model_object_tsne_gau$df_bin

## Triangulate bin centroids
tr1_object_tsne_gau <- tri_bin_centroids(df_bin_centroids_tsne_gau, x = "c_x", y = "c_y")
tr_from_to_df_tsne_gau <- gen_edges(tri_object = tr1_object_tsne_gau)

## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(tr_coord_df = tr_from_to_df_tsne_gau, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_tsne_gau) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_tsne_gau <- find_lg_benchmark(distance_edges = distance_tsne_gau, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_tsne_gau, mapping = aes(x = c_x, y = c_y))

trimesh_removed_tsne_gau <- vis_rmlg_mesh(distance_edges = distance_tsne_gau, benchmark_value = benchmark_tsne_gau, tr_coord_df = tr_from_to_df_tsne_gau, distance_col = "distance")

trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

df_all_tsne_gau <- dplyr::bind_cols(training_data_gau |> dplyr::select(-ID), tsne_data_with_hb_id_gau)

# show_langevitour(df = df_all_tsne_gau, df_b = df_bin_tsne_gau, df_b_with_center_data = df_bin_centroids_tsne_gau, col_start = "x", distance_df = distance_tsne_gau, distance_col = "distance", benchmark_value = benchmark_tsne_gau)
```


```{r}
#| warning: false
#| echo: false
#| message: false

umap_gau_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = UMAP_data_gau, 
                                    x = "UMAP1", y = "UMAP2"))) |>
  dplyr::rename(c("UMAP1" = "scaled_UMAP1", 
                  "UMAP2" = "scaled_UMAP2")) |>
  dplyr::mutate(ID = 1:NROW(UMAP_data_gau))

## Decide by looking at MSE plot
num_bins_x_tsne_gau <- 60
num_bins_y_tsne_gau <- 79
hex_size_tsne_gau <- 0.01
### non-empty 229

hb_obj_tsne_gau <- hex_binning(data = umap_gau_scaled, x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x_tsne_gau, 
                      num_bins_y = num_bins_y_tsne_gau, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_tsne_gau, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

tsne_data_with_hb_id_gau <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$data_hb_id))
  
model_object_tsne_gau <- fit_highd_model( training_data = training_data_gau, 
                                 nldr_df_with_id = umap_gau_scaled, 
                                 x = "UMAP1", y = "UMAP2", 
                                 num_bins_x = num_bins_x_tsne_gau, 
                                 num_bins_y = num_bins_y_tsne_gau, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_tsne_gau,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "UMAP", 
                                 col_start_highd = "x")

df_bin_centroids_tsne_gau <- model_object_tsne_gau$df_bin_centroids
df_bin_tsne_gau <- model_object_tsne_gau$df_bin

## Triangulate bin centroids
tr1_object_tsne_gau <- tri_bin_centroids(df_bin_centroids_tsne_gau, x = "c_x", y = "c_y")
tr_from_to_df_tsne_gau <- gen_edges(tri_object = tr1_object_tsne_gau)

## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(tr_coord_df = tr_from_to_df_tsne_gau, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_tsne_gau) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_tsne_gau <- find_lg_benchmark(distance_edges = distance_tsne_gau, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_tsne_gau, mapping = aes(x = c_x, y = c_y))

trimesh_removed_tsne_gau <- vis_rmlg_mesh(distance_edges = distance_tsne_gau, benchmark_value = benchmark_tsne_gau, tr_coord_df = tr_from_to_df_tsne_gau, distance_col = "distance")

trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

df_all_tsne_gau <- dplyr::bind_cols(training_data_gau |> dplyr::select(-ID), tsne_data_with_hb_id_gau)

# show_langevitour(df = df_all_tsne_gau, df_b = df_bin_tsne_gau, df_b_with_center_data = df_bin_centroids_tsne_gau, col_start = "x", distance_df = distance_tsne_gau, distance_col = "distance", benchmark_value = benchmark_tsne_gau)

  # find_non_empty_bins(data = umap_gau_scaled, x = "UMAP1", y = "UMAP2",
  #                   non_empty_bins = 198, x_start = NA, y_start = NA,
  #                   buffer_x = NA, buffer_y = NA, hex_size = 0.03,
  #                   col_start = "UMAP")


# hex_size_vec <- seq(0.02, 2, by = 0.01)
# 
# for (i in 1:length(hex_size_vec)) {
# 
#   find_non_empty_bins(data = umap_gau_scaled, x = "UMAP1", y = "UMAP2",
#                     non_empty_bins = 198, x_start = NA, y_start = NA,
#                     buffer_x = NA, buffer_y = NA, hex_size = hex_size_vec[i],
#                     col_start = "UMAP")
# 
# 
# }


```

```{r}
#| warning: false
#| echo: false
#| message: false
#| eval: false

phate_gau_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = PHATE_data_gau, x = "PAHTE1", y = "PAHTE2"))) |>
  dplyr::rename(c("PAHTE1" = "scaled_PAHTE1", 
                  "PAHTE2" = "scaled_PAHTE2")) |>
  dplyr::mutate(ID = 1:NROW(PAHTE_data_gau))

## Decide by looking at MSE plot
num_bins_x_tsne_gau <- 46
num_bins_y_tsne_gau <- 61
hex_size_tsne_gau <- 0.013
### non-empty 179

hb_obj_tsne_gau <- hex_binning(data = phate_gau_scaled, x = "PHATE1", 
                      y = "PHATE2", num_bins_x = num_bins_x_tsne_gau, 
                      num_bins_y = num_bins_y_tsne_gau, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_tsne_gau, col_start = "PHATE")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

tsne_data_with_hb_id_gau <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$data_hb_id))
  
model_object_tsne_gau <- fit_highd_model( training_data = training_data_gau, 
                                 nldr_df_with_id = phate_gau_scaled, 
                                 x = "PHATE1", y = "PHATE2", 
                                 num_bins_x = num_bins_x_tsne_gau, 
                                 num_bins_y = num_bins_y_tsne_gau, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_tsne_gau,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "PHATE", 
                                 col_start_highd = "x")

df_bin_centroids_tsne_gau <- model_object_tsne_gau$df_bin_centroids
df_bin_tsne_gau <- model_object_tsne_gau$df_bin

## Triangulate bin centroids
tr1_object_tsne_gau <- tri_bin_centroids(df_bin_centroids_tsne_gau, x = "c_x", y = "c_y")
tr_from_to_df_tsne_gau <- gen_edges(tri_object = tr1_object_tsne_gau)

## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(tr_coord_df = tr_from_to_df_tsne_gau, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_tsne_gau) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_tsne_gau <- find_lg_benchmark(distance_edges = distance_tsne_gau, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_tsne_gau, mapping = aes(x = c_x, y = c_y))

trimesh_removed_tsne_gau <- vis_rmlg_mesh(distance_edges = distance_tsne_gau, benchmark_value = benchmark_tsne_gau, tr_coord_df = tr_from_to_df_tsne_gau, distance_col = "distance")

trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

df_all_tsne_gau <- dplyr::bind_cols(training_data_gau |> dplyr::select(-ID), tsne_data_with_hb_id_gau)

# show_langevitour(df = df_all_tsne_gau, df_b = df_bin_tsne_gau, df_b_with_center_data = df_bin_centroids_tsne_gau, col_start = "x", distance_df = distance_tsne_gau, distance_col = "distance", benchmark_value = benchmark_tsne_gau)

```


```{r}
#| warning: false
#| echo: false
#| message: false

trimap_gau_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = TriMAP_data_gau, 
                                    x = "TriMAP1", y = "TriMAP2"))) |>
  dplyr::rename(c("TriMAP1" = "scaled_TriMAP1", 
                  "TriMAP2" = "scaled_TriMAP2")) |>
  dplyr::mutate(ID = 1:NROW(TriMAP_data_gau))

## Decide by looking at MSE plot
num_bins_x_tsne_gau <- 46
num_bins_y_tsne_gau <- 61
hex_size_tsne_gau <- 0.013
### non-empty 179

hb_obj_tsne_gau <- hex_binning(data = trimap_gau_scaled, x = "TriMAP1", 
                      y = "TriMAP2", num_bins_x = num_bins_x_tsne_gau, 
                      num_bins_y = num_bins_y_tsne_gau, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_tsne_gau, col_start = "TriMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

tsne_data_with_hb_id_gau <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$data_hb_id))
  
model_object_tsne_gau <- fit_highd_model( training_data = training_data_gau, 
                                 nldr_df_with_id = trimap_gau_scaled, 
                                 x = "TriMAP1", y = "TriMAP2", 
                                 num_bins_x = num_bins_x_tsne_gau, 
                                 num_bins_y = num_bins_y_tsne_gau, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_tsne_gau,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "TriMAP", 
                                 col_start_highd = "x")

df_bin_centroids_tsne_gau <- model_object_tsne_gau$df_bin_centroids
df_bin_tsne_gau <- model_object_tsne_gau$df_bin

## Triangulate bin centroids
tr1_object_tsne_gau <- tri_bin_centroids(df_bin_centroids_tsne_gau, x = "c_x", y = "c_y")
tr_from_to_df_tsne_gau <- gen_edges(tri_object = tr1_object_tsne_gau)

## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(tr_coord_df = tr_from_to_df_tsne_gau, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_tsne_gau) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_tsne_gau <- find_lg_benchmark(distance_edges = distance_tsne_gau, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_tsne_gau, mapping = aes(x = c_x, y = c_y))

trimesh_removed_tsne_gau <- vis_rmlg_mesh(distance_edges = distance_tsne_gau, benchmark_value = benchmark_tsne_gau, tr_coord_df = tr_from_to_df_tsne_gau, distance_col = "distance")

trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

df_all_tsne_gau <- dplyr::bind_cols(training_data_gau |> dplyr::select(-ID), tsne_data_with_hb_id_gau)

# show_langevitour(df = df_all_tsne_gau, df_b = df_bin_tsne_gau, df_b_with_center_data = df_bin_centroids_tsne_gau, col_start = "x", distance_df = distance_tsne_gau, distance_col = "distance", benchmark_value = benchmark_tsne_gau)

```



```{r}
#| warning: false
#| echo: false
#| message: false

pacmap_gau_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = PaCMAP_data_gau, 
                                    x = "PaCMAP1", y = "PaCMAP2"))) |>
  dplyr::rename(c("PaCMAP1" = "scaled_PaCMAP1", 
                  "PaCMAP2" = "scaled_PaCMAP2")) |>
  dplyr::mutate(ID = 1:NROW(PaCMAP_data_gau))

## Decide by looking at MSE plot
num_bins_x_tsne_gau <- 31
num_bins_y_tsne_gau <- 40
hex_size_tsne_gau <- 0.02
### non-empty 179

hb_obj_tsne_gau <- hex_binning(data = pacmap_gau_scaled, x = "PaCMAP1", 
                      y = "PaCMAP2", num_bins_x = num_bins_x_tsne_gau, 
                      num_bins_y = num_bins_y_tsne_gau, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_tsne_gau, col_start = "PaCMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

tsne_data_with_hb_id_gau <- as.data.frame(do.call(cbind, hb_obj_tsne_gau$data_hb_id))
  
model_object_tsne_gau <- fit_highd_model( training_data = training_data_gau, 
                                 nldr_df_with_id = pacmap_gau_scaled, 
                                 x = "PaCMAP1", y = "PaCMAP2", 
                                 num_bins_x = num_bins_x_tsne_gau, 
                                 num_bins_y = num_bins_y_tsne_gau, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_tsne_gau,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "PaCMAP", 
                                 col_start_highd = "x")

df_bin_centroids_tsne_gau <- model_object_tsne_gau$df_bin_centroids
df_bin_tsne_gau <- model_object_tsne_gau$df_bin

## Triangulate bin centroids
tr1_object_tsne_gau <- tri_bin_centroids(df_bin_centroids_tsne_gau, x = "c_x", y = "c_y")
tr_from_to_df_tsne_gau <- gen_edges(tri_object = tr1_object_tsne_gau)

## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(tr_coord_df = tr_from_to_df_tsne_gau, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_tsne_gau) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_tsne_gau <- find_lg_benchmark(distance_edges = distance_tsne_gau, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_tsne_gau, mapping = aes(x = c_x, y = c_y))

trimesh_removed_tsne_gau <- vis_rmlg_mesh(distance_edges = distance_tsne_gau, benchmark_value = benchmark_tsne_gau, tr_coord_df = tr_from_to_df_tsne_gau, distance_col = "distance")

trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

df_all_tsne_gau <- dplyr::bind_cols(training_data_gau |> dplyr::select(-ID), tsne_data_with_hb_id_gau)

# show_langevitour(df = df_all_tsne_gau, df_b = df_bin_tsne_gau, df_b_with_center_data = df_bin_centroids_tsne_gau, col_start = "x", distance_df = distance_tsne_gau, distance_col = "distance", benchmark_value = benchmark_tsne_gau)

```


<!---
```{r}
#| warning: false
#| echo: false
#| eval: false

### tSNE

# num_bins_tsne_gau <- calculate_effective_x_bins(.data = tSNE_data_gau, x = tSNE1,
#                                                 cell_area = 1) #56
num_bins_tsne_gau <- 16

shape_val_tsne_gau <- calculate_effective_shape_value(.data = tSNE_data_gau,
                                                      x = tSNE1, y = tSNE2)
## To extract bin centroids
hexbin_data_object_tsne_gau <- extract_hexbin_centroids(nldr_df = tSNE_data_gau, num_bins = num_bins_tsne_gau, shape_val = shape_val_tsne_gau, x = tSNE1, y = tSNE2)

df_bin_centroids_tsne_gau <- hexbin_data_object_tsne_gau$hexdf_data

num_non_empty_bins_gau <- df_bin_centroids_tsne_gau$hexID |> length()

tSNE_data_with_hb_id_gau <- tSNE_data_gau |>
  dplyr::mutate(hb_id = hexbin_data_object_tsne_gau$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all_tsne_gau <- dplyr::bind_cols(training_data_1 |> dplyr::select(-ID), tSNE_data_with_hb_id_gau)

## Averaged on high-D
df_bin_tsne_gau <- avg_highD_data(.data = df_all_tsne_gau)

## Triangulate bin centroids
tr1_object_tsne_gau <- triangulate_bin_centroids(df_bin_centroids_tsne_gau, x, y)
tr_from_to_df_tsne_gau <- generate_edge_info(triangular_object = tr1_object_tsne_gau)

## Compute 2D distances
distance_tsne_gau <- cal_2d_dist(.data = tr_from_to_df_tsne_gau)

## To find the benchmark value
benchmark_tsne_gau <- find_benchmark_value(.data = distance_tsne_gau, distance_col = distance)

trimesh_removed_tsne_gau <- remove_long_edges(.data = distance_tsne_gau, benchmark_value = benchmark_tsne_gau,
                                                  triangular_object = tr1_object_tsne_gau, distance_col = distance)

trimesh_removed_tsne_gau <- trimesh_removed_tsne_gau +
  # xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  # theme(axis.text = element_text(size = 5),
  #       axis.title = element_text(size = 7)) +
  geom_point(colour = "#33a02c", size = 0.05) +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

# tour_tsne_gau <- show_langevitour(df_all_tsne_gau, df_bin_tsne_gau, df_bin_centroids_tsne_gau, benchmark_value = benchmark_tsne_gau, distance = distance_tsne_gau, distance_col = distance)

### UMAP

# num_bins_umap_gau <- calculate_effective_x_bins(.data = UMAP_data_gau, x = UMAP1,
#                                                 cell_area = 1) #41

shape_val_umap_gau <- calculate_effective_shape_value(.data = UMAP_data_gau,
                                                      x = UMAP1, y = UMAP2)
num_bins_umap_gau <- find_non_empty_bins(nldr_df = UMAP_data_gau, x = "UMAP1", y = "UMAP2", shape_val = shape_val_umap_gau, non_empty_bins = num_non_empty_bins_gau)

## To extract bin centroids
hexbin_data_object_umap_gau <- extract_hexbin_centroids(nldr_df = UMAP_data_gau, num_bins = num_bins_umap_gau, shape_val = shape_val_umap_gau, x = UMAP1, y = UMAP2)

df_bin_centroids_umap_gau <- hexbin_data_object_umap_gau$hexdf_data

UMAP_data_with_hb_id_gau <- UMAP_data_gau |>
  dplyr::mutate(hb_id = hexbin_data_object_umap_gau$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all_umap_gau <- dplyr::bind_cols(training_data_1 |> dplyr::select(-ID), UMAP_data_with_hb_id_gau)

## Averaged on high-D
df_bin_umap_gau <- avg_highD_data(.data = df_all_umap_gau)

## Triangulate bin centroids
tr1_object_umap_gau <- triangulate_bin_centroids(df_bin_centroids_umap_gau, x, y)
tr_from_to_df_umap_gau <- generate_edge_info(triangular_object = tr1_object_umap_gau)

## Compute 2D distances
distance_umap_gau <- cal_2d_dist(.data = tr_from_to_df_umap_gau)

## To find the benchmark value
benchmark_umap_gau <- find_benchmark_value(.data = distance_umap_gau, distance_col = distance)

trimesh_removed_umap_gau <- remove_long_edges(.data = distance_umap_gau, benchmark_value = benchmark_umap_gau,
                                              triangular_object = tr1_object_umap_gau, distance_col = distance)

trimesh_removed_umap_gau <- trimesh_removed_umap_gau +
  # xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  # theme(axis.text = element_text(size = 5),
  #       axis.title = element_text(size = 7)) +
  geom_point(colour = "#33a02c", size = 0.05) +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

# tour_umap_gau <- show_langevitour(df_all_umap_gau, df_bin_umap_gau, df_bin_centroids_umap_gau, benchmark_value = benchmark_umap_gau, distance = distance_umap_gau, distance_col = distance)


## PAHTE

# num_bins_phate_gau <- calculate_effective_x_bins(.data = PHATE_data_gau, x = PHATE1,
#                                                  cell_area = 1)

shape_val_phate_gau <- calculate_effective_shape_value(.data = PHATE_data_gau,
                                                       x = PHATE1, y = PHATE2)
num_bins_phate_gau <- find_non_empty_bins(nldr_df = PHATE_data_gau, x = "PHATE1", y = "PHATE2", shape_val = shape_val_phate_gau, non_empty_bins = num_non_empty_bins_gau)


## To extract bin centroids
hexbin_data_object_phate_gau <- extract_hexbin_centroids(nldr_df = PHATE_data_gau, num_bins = num_bins_phate_gau, shape_val = shape_val_phate_gau, x = PHATE1, y = PHATE2)

df_bin_centroids_phate_gau <- hexbin_data_object_phate_gau$hexdf_data

PHATE_data_with_hb_id_gau <- PHATE_data_gau |>
  dplyr::mutate(hb_id = hexbin_data_object_phate_gau$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all_phate_gau <- dplyr::bind_cols(training_data_1 |> dplyr::select(-ID), PHATE_data_with_hb_id_gau)

## Averaged on high-D
df_bin_phate_gau <- avg_highD_data(.data = df_all_phate_gau)

## Triangulate bin centroids
tr1_object_phate_gau <- triangulate_bin_centroids(df_bin_centroids_phate_gau, x, y)
tr_from_to_df_phate_gau <- generate_edge_info(triangular_object = tr1_object_phate_gau)

## Compute 2D distances
distance_phate_gau <- cal_2d_dist(.data = tr_from_to_df_phate_gau)

## To find the benchmark value
benchmark_phate_gau <- find_benchmark_value(.data = distance_phate_gau, distance_col = distance)
benchmark_phate_gau <- 0.00078

trimesh_removed_phate_gau <- remove_long_edges(.data = distance_phate_gau, benchmark_value = benchmark_phate_gau,
                                               triangular_object = tr1_object_phate_gau, distance_col = distance)

trimesh_removed_phate_gau <- trimesh_removed_phate_gau +
  # xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  # theme(axis.text = element_text(size = 5),
  #       axis.title = element_text(size = 7)) +
  geom_point(colour = "#33a02c", size = 0.05) +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'c', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

# tour_phate_gau <- show_langevitour(df_all_phate_gau, df_bin_phate_gau, df_bin_centroids_phate_gau, benchmark_value = benchmark_phate_gau, distance = distance_phate_gau, distance_col = distance)

## TriMAP

# num_bins_trimap_gau <- calculate_effective_x_bins(.data = TriMAP_data_gau, x = TriMAP1,
#                                                   cell_area = 1) #143

shape_val_trimap_gau <- calculate_effective_shape_value(.data = TriMAP_data_gau,
                                                        x = TriMAP1, y = TriMAP2)

num_bins_trimap_gau <- find_non_empty_bins(nldr_df = TriMAP_data_gau, x = "TriMAP1", y = "TriMAP2", shape_val = shape_val_trimap_gau, non_empty_bins = num_non_empty_bins_gau)


## To extract bin centroids
hexbin_data_object_trimap_gau <- extract_hexbin_centroids(nldr_df = TriMAP_data_gau, num_bins = num_bins_trimap_gau, shape_val = shape_val_trimap_gau, x = TriMAP1, y = TriMAP2)

df_bin_centroids_trimap_gau <- hexbin_data_object_trimap_gau$hexdf_data

TriMAP_data_with_hb_id_gau <- TriMAP_data_gau |>
  dplyr::mutate(hb_id = hexbin_data_object_trimap_gau$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all_trimap_gau <- dplyr::bind_cols(training_data_1 |> dplyr::select(-ID), TriMAP_data_with_hb_id_gau)

## Averaged on high-D
df_bin_trimap_gau <- avg_highD_data(.data = df_all_trimap_gau)

## Triangulate bin centroids
tr1_object_trimap_gau <- triangulate_bin_centroids(df_bin_centroids_trimap_gau, x, y)
tr_from_to_df_trimap_gau <- generate_edge_info(triangular_object = tr1_object_trimap_gau)

## Compute 2D distances
distance_trimap_gau <- cal_2d_dist(.data = tr_from_to_df_trimap_gau)

## To find the benchmark value
benchmark_trimap_gau <- find_benchmark_value(.data = distance_trimap_gau, distance_col = distance)

trimesh_removed_trimap_gau <- remove_long_edges(.data = distance_trimap_gau, benchmark_value = benchmark_trimap_gau,
                                                triangular_object = tr1_object_trimap_gau, distance_col = distance)

trimesh_removed_trimap_gau <- trimesh_removed_trimap_gau +
  # xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  # theme(axis.text = element_text(size = 5),
  #       axis.title = element_text(size = 7)) +
  geom_point(colour = "#33a02c", size = 0.05) +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'd', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

# tour_trimap_gau <- show_langevitour(df_all_trimap_gau, df_bin_trimap_gau, df_bin_centroids_trimap_gau, benchmark_value = benchmark_trimap_gau, distance = distance_trimap_gau, distance_col = distance)


## PaCMAP

# num_bins_pacmap_gau <- calculate_effective_x_bins(.data = PaCMAP_data_gau, x = PaCMAP1,
#                                                   cell_area = 1) #30

shape_val_pacmap_gau <- calculate_effective_shape_value(.data = PaCMAP_data_gau,
                                                        x = PaCMAP1, y = PaCMAP2)

num_bins_pacmap_gau <- find_non_empty_bins(nldr_df = PaCMAP_data_gau, x = "PaCMAP1", y = "PaCMAP2", shape_val = shape_val_pacmap_gau, non_empty_bins = num_non_empty_bins_gau)

## To extract bin centroids
hexbin_data_object_pacmap_gau <- extract_hexbin_centroids(nldr_df = PaCMAP_data_gau, num_bins = num_bins_pacmap_gau, shape_val = shape_val_pacmap_gau, x = PaCMAP1, y = PaCMAP2)

df_bin_centroids_pacmap_gau <- hexbin_data_object_pacmap_gau$hexdf_data

PaCMAP_data_with_hb_id_gau <- PaCMAP_data_gau |>
  dplyr::mutate(hb_id = hexbin_data_object_pacmap_gau$hb_data@cID)

## To generate a data set with high-D and 2D training data
df_all_pacmap_gau <- dplyr::bind_cols(training_data_1 |> dplyr::select(-ID), PaCMAP_data_with_hb_id_gau)

## Averaged on high-D
df_bin_pacmap_gau <- avg_highD_data(.data = df_all_pacmap_gau)

## Triangulate bin centroids
tr1_object_pacmap_gau <- triangulate_bin_centroids(df_bin_centroids_pacmap_gau, x, y)
tr_from_to_df_pacmap_gau <- generate_edge_info(triangular_object = tr1_object_pacmap_gau)

## Compute 2D distances
distance_pacmap_gau <- cal_2d_dist(.data = tr_from_to_df_pacmap_gau)

## To find the benchmark value
benchmark_pacmap_gau <- find_benchmark_value(.data = distance_pacmap_gau, distance_col = distance)

trimesh_removed_pacmap_gau <- remove_long_edges(.data = distance_pacmap_gau, benchmark_value = benchmark_pacmap_gau,
                                                triangular_object = tr1_object_pacmap_gau, distance_col = distance)

trimesh_removed_pacmap_gau <- trimesh_removed_pacmap_gau +
  # xlab(expression(C[x]^{(2)})) + ylab(expression(C[y]^{(2)})) +
  # theme(axis.text = element_text(size = 5),
  #       axis.title = element_text(size = 7)) +
  geom_point(colour = "#33a02c", size = 0.05) +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'e', x = -Inf, y = Inf, hjust = -0.5, vjust = 1, size = 3)

# tour_pacmap_gau <- show_langevitour(df_all_pacmap_gau, df_bin_pacmap_gau, df_bin_centroids_pacmap_gau, benchmark_value = benchmark_pacmap_gau, distance = distance_pacmap_gau, distance_col = distance)


```

```{r}
#| eval: false
#| warning: false
#| echo: false
#| label: fig-modelfiveGau
#| fig-cap: "Is there a best model to represent the original data in 2D space or are they all providing equivalent information?, (a) Model in the 2D space with tSNE (<https://youtu.be/x5VPB-wOLm4>), (b) Model in the 2D space with UMAP (<https://youtu.be/Cm1dW6iLyHQ>), (c) Model in the 2D space with PHATE (<https://youtu.be/HB0Y3ilz6sI>), (d) Model in the 2D space with TriMAP (<https://youtu.be/iSVkXIrOrSA>), and (e) Model in the 2D space with PaCMAP (<https://youtu.be/O2QBctsc4uM>)."
#| out-width: 100%

trimesh_removed_tsne_gau + trimesh_removed_umap_gau + trimesh_removed_phate_gau + trimesh_removed_trimap_gau + trimesh_removed_pacmap_gau +
  #plot_annotation(tag_levels = 'a') +
  plot_layout(ncol = 5) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```


```{r}
#| eval: false
#| warning: false
#| echo: false

## tSNE

shape_value_gau <- calculate_effective_shape_value(.data = tSNE_data_gau,
                                                   x = tSNE1, y = tSNE2)

num_bins_vec <- 1:20 ## Number of bins along the x-axis

vec <- stats::setNames(rep("", 4), c("number_of_bins", "number_of_observations", "total_error", "total_mse"))  ## Define column names

eval_data_training <- dplyr::bind_rows(vec)[0, ]
eval_data_training <- eval_data_training |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(num_bins_vec)) {
  model_object <- fit_high_d_model(training_data = training_data_1, nldr_df_with_id = tSNE_data_gau, x = "tSNE1", y = "tSNE2", num_bins_x = num_bins_vec[i], shape_val = shape_value_gau,
                                 is_bin_centroid = TRUE,
                                 is_rm_lwd_hex = FALSE,
                                 benchmark_to_rm_lwd_hex = NA,
                                 is_avg_high_d = TRUE, column_start_text = "x")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_df_training <- predict_2d_embeddings(test_data = training_data_1, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, type_NLDR = "tSNE")
  
  eval_df_training <- generate_eval_df(data = df_2, prediction_df = pred_df_training, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, col_start = "x")
  
  eval_df_training <- eval_df_training |>
    mutate(num_bins_x = num_bins_vec[i])
  
  eval_data_training <- dplyr::bind_rows(eval_data_training, eval_df_training)
}


## Add new column with data types

eval_data_training <- eval_data_training |>
  mutate(data_type = "training")

MSE_df_1_gau <- eval_data_training |>
  dplyr::mutate(method = "tSNE")
```


```{r}
#| eval: false
#| warning: false
#| echo: false

## UMAP
## Prediction

shape_value_gau <- calculate_effective_shape_value(.data = UMAP_data_gau,
                                                   x = UMAP1, y = UMAP2)

num_bins_vec <- 1:20 ## Number of bins along the x-axis

vec <- stats::setNames(rep("", 4), c("number_of_bins", "number_of_observations", "total_error", "total_mse"))  ## Define column names

eval_data_training <- dplyr::bind_rows(vec)[0, ]
eval_data_training <- eval_data_training |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(num_bins_vec)) {
  
  model_object <- fit_high_d_model(training_data = training_data_1, nldr_df_with_id = UMAP_data_gau, x = "UMAP1", y = "UMAP2", num_bins_x = num_bins_vec[i], shape_val = shape_value_gau,
                                 is_bin_centroid = TRUE,
                                 is_rm_lwd_hex = FALSE,
                                 benchmark_to_rm_lwd_hex = NA,
                                 is_avg_high_d = TRUE, column_start_text = "x")

  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_df_training <- predict_2d_embeddings(test_data = training_data_1, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, type_NLDR = "UMAP")
  
  eval_df_training <- generate_eval_df(data = df_2, prediction_df = pred_df_training, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, col_start = "x")
  
  eval_df_training <- eval_df_training |>
    mutate(num_bins_x = num_bins_vec[i])
  
  eval_data_training <- dplyr::bind_rows(eval_data_training, eval_df_training)

  
  
}


## Add new column with data types

eval_data_training <- eval_data_training |>
  mutate(data_type = "training")

MSE_df_2_gau <- eval_data_training |>
  dplyr::mutate(method = "UMAP")
```

```{r}
#| eval: false
#| warning: false
#| echo: false
## PAHTE
## Prediction

shape_value_gau <- calculate_effective_shape_value(.data = PHATE_data_gau,
                                                   x = PHATE1, y = PHATE2)

num_bins_vec <- 1:20 ## Number of bins along the x-axis

vec <- stats::setNames(rep("", 4), c("number_of_bins", "number_of_observations", "total_error", "total_mse"))  ## Define column names

eval_data_training <- dplyr::bind_rows(vec)[0, ]
eval_data_training <- eval_data_training |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(num_bins_vec)) {
  
  model_object <- fit_high_d_model(training_data = training_data_1, nldr_df_with_id = PHATE_data_gau, x = "PHATE1", y = "PHATE2", num_bins_x = num_bins_vec[i], shape_val = shape_value_gau,
                                 is_bin_centroid = TRUE,
                                 is_rm_lwd_hex = FALSE,
                                 benchmark_to_rm_lwd_hex = NA,
                                 is_avg_high_d = TRUE, column_start_text = "x")

  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_df_training <- predict_2d_embeddings(test_data = training_data_1, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, type_NLDR = "PHATE")
  
  eval_df_training <- generate_eval_df(data = df_2, prediction_df = pred_df_training, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, col_start = "x")
  
  eval_df_training <- eval_df_training |>
    mutate(num_bins_x = num_bins_vec[i])
  
  eval_data_training <- dplyr::bind_rows(eval_data_training, eval_df_training)

  
  
}


## Add new column with data types

eval_data_training <- eval_data_training |>
  mutate(data_type = "training")

MSE_df_3_gau <- eval_data_training |>
  dplyr::mutate(method = "PHATE")

```

```{r}
#| eval: false
#| warning: false
#| echo: false

## TriMAP

## Prediction

shape_value_gau <- calculate_effective_shape_value(.data = TriMAP_data_gau,
                                                   x = TriMAP1, y = TriMAP2)

num_bins_vec <- 1:20 ## Number of bins along the x-axis

vec <- stats::setNames(rep("", 4), c("number_of_bins", "number_of_observations", "total_error", "total_mse"))  ## Define column names

eval_data_training <- dplyr::bind_rows(vec)[0, ]
eval_data_training <- eval_data_training |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(num_bins_vec)) {
  
  model_object <- fit_high_d_model(training_data = training_data_1, nldr_df_with_id = TriMAP_data_gau, x = "TriMAP1", y = "TriMAP2", num_bins_x = num_bins_vec[i], shape_val = shape_value_gau,
                                 is_bin_centroid = TRUE,
                                 is_rm_lwd_hex = FALSE,
                                 benchmark_to_rm_lwd_hex = NA,
                                 is_avg_high_d = TRUE, column_start_text = "x")

  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_df_training <- predict_2d_embeddings(test_data = training_data_1, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, type_NLDR = "TriMAP")
  
  eval_df_training <- generate_eval_df(data = df_2, prediction_df = pred_df_training, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, col_start = "x")
  
  eval_df_training <- eval_df_training |>
    mutate(num_bins_x = num_bins_vec[i])
  
  eval_data_training <- dplyr::bind_rows(eval_data_training, eval_df_training)

  
  
}


## Add new column with data types

eval_data_training <- eval_data_training |>
  mutate(data_type = "training")

MSE_df_4_gau <- eval_data_training |>
  dplyr::mutate(method = "TriMAP")

```

```{r}
#| eval: false
#| warning: false
#| echo: false

## PaCMAP

## Prediction

shape_value_gau <- calculate_effective_shape_value(.data = PaCMAP_data_gau,
                                                   x = PaCMAP1, y = PaCMAP2)

num_bins_vec <- 1:20 ## Number of bins along the x-axis

vec <- stats::setNames(rep("", 4), c("number_of_bins", "number_of_observations", "total_error", "total_mse"))  ## Define column names

eval_data_training <- dplyr::bind_rows(vec)[0, ]
eval_data_training <- eval_data_training |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(num_bins_vec)) {
  
  model_object <- fit_high_d_model(training_data = training_data_1, nldr_df_with_id = PaCMAP_data_gau, x = "PaCMAP1", y = "PaCMAP2", num_bins_x = num_bins_vec[i], shape_val = shape_value_gau,
                                 is_bin_centroid = TRUE,
                                 is_rm_lwd_hex = FALSE,
                                 benchmark_to_rm_lwd_hex = NA,
                                 is_avg_high_d = TRUE, column_start_text = "x")

  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_df_training <- predict_2d_embeddings(test_data = training_data_1, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, type_NLDR = "PaCMAP")
  
  eval_df_training <- generate_eval_df(data = df_2, prediction_df = pred_df_training, df_bin_centroids = centroid_df_training, df_bin = avg_df_training, col_start = "x")
  
  eval_df_training <- eval_df_training |>
    mutate(num_bins_x = num_bins_vec[i])
  
  eval_data_training <- dplyr::bind_rows(eval_data_training, eval_df_training)

  
  
}


## Add new column with data types

eval_data_training <- eval_data_training |>
  mutate(data_type = "training")

MSE_df_5_gau <- eval_data_training |>
  dplyr::mutate(method = "PaCMAP")

```

```{r}
#| eval: false
#| warning: false
#| echo: false

MSE_df_gau <- dplyr::bind_rows(MSE_df_1_gau, MSE_df_2_gau, MSE_df_3_gau, MSE_df_4_gau, MSE_df_5_gau)

MSE_df_gau$method <- factor(MSE_df_gau$method, levels = c("tSNE", "UMAP", "PHATE", "TriMAP", "PaCMAP"))


## To draw with AIC
aic_gau_plot <- ggplot(MSE_df_gau |> dplyr::filter(data_type == "training"), aes(x = number_of_bins,
                                                             y = total_error,
                   color = method
)) +
  geom_point() +
  geom_line() +
  #geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  #annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=-5000, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  theme_light() +
  theme(legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  scale_colour_manual(values = c("#e41a1c", "#377eb8", "#4daf4a", "#984ea3", "#ff7f00")) +
  ylab("AIC") +
  xlab("total number of bins") + 
  facet_wrap(vars(method), ncol = 5)
## Effective number of bins along x-axis

mse_gau_plot <- ggplot(MSE_df_gau, aes(x = number_of_bins,
                   y = total_mse,
                   color = method
)) +
  geom_point() +
  geom_line() +
  theme_light() +
  theme(legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  # geom_vline(xintercept = NROW(full_grid_with_hexbin_id)) +
  # annotate("text", x= (NROW(full_grid_with_hexbin_id) - 10), y=0.25, label=paste0("effective number of bins = ", as.character(NROW(full_grid_with_hexbin_id))), angle=90) +
  scale_colour_manual(values = c("#e41a1c", "#377eb8", "#4daf4a", "#984ea3", "#ff7f00")) +
  ylab("MSE") +
  xlab("total number of bins") + 
  facet_wrap(vars(method), ncol = 5)

```


-->




## Applications {#sec-applications}

### Single-cell RNA-seq data of human

In the field of single-cell studies, a common analysis task involves clustering to identify groups of cells with similar expression profiles. Analysts often turn to NLDR techniques to verify and identify these clusters and explore developmental trajectories. In clustering workflows, the main objective is to verify the existence of clusters and subsequently identify them as specific cell types by examining the expression of "known" marker genes. Marker genes are specific genes or transcripts that are uniquely or highly expressed in particular cell types. Marker genes are identified through differential gene expression (DEG) analysis, comparing the expression levels of genes across different cell types. In this context, a "faithful" embedding should ideally preserve the topology of the data, ensuring that cells corresponding to the same cell type are situated close to the high-dimensional space.

### Processing steps

To begin our analysis, we installed the Peripheral Blood Mononuclear Cells (pbmc) data set obtained from 10x Genomics using the `SeuratData` R package [@Rahul2019], which facilitates the distribution of data sets in the form of Seurat objects [@Yuhan2021]. This data set contains 13,714 features (genes) across 2,700 samples (cells) within a single assay. The active assay is RNA, with 13,714 features representing different gene expressions. Then, the cells that have unique feature counts over 2,500 or less than 200 and cells that have > 5\% mitochondrial counts are filtered. After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. 

Next, top 1000 genes are selected by Festem [@Chen2023] DEG method. Then, scale the data. Then, perform PCA on the scaled data. Louvain algorithm is used to cluster the single cells based on the genes selected by Festem. Using the Festem-selected genes and 15 PCs, identified 10 clusters in the PBMC3k data and annotated them based on the expression of canonical markers. The 10 clusters included immune cells such as naive CD4 T cells, memory CD4 T cells, CD8 T cells, CD14 monocytes, FCGR3A monocytes, Natural Killer (NK) cells, B cells and Dendritic Cells (DC). In addition to these common cell types, Festem identified a fine cell type, CD27− CD4+ memory T cells, which were often missed by other methods.


- Human peripheral blood mononclear cells (PBMCs) data

- Intro to the data set

Used Louvain algorithm to cluster the single cells based on the genes selected by Festem method

- Explain what "Evaluate Festem on DEG detection" means, in terms of this data


- How did they "identified 10 clusters"? What were the variables used, PCs or full data or 2D representation, spell this out.

- Used top 1000 genes selected by Festem to run PCA, top 15 PCs (original paper mentioned)

- The "10 clusters included immune cells such as naive CD4 T ..." does this mean that every cluster had all of these, or one cluster was mostly "CD4 T cells", another mostly "memory CD4 T", ...?

- How is your use of this data different from the original application.

- Original paper used this data set to compare different DEG methods, but we need to look how the performance of UMAP with the author's selected parameter choice.

- Why 15 PCs? Is that from the original paper? YES

@Chen2023

- Intro to the data set (This data set contains 13,714 features across 2,700 samples within a single assay. The active assay is RNA, with 13,714 features representing different gene expressions.)

- 2622 cells

- Evaluate Festem on DEG detection (Festem enabled identification of often-missed fine cell types)

- Using the Festem-selected genes, identified 10 clusters in the PBMCsk data and annotated them based on the expression of canonical markers

- The 10 clusters included immune cells such as naive CD4 T cells, memory CD4 T cells, CD8 T cells, CD14 monocytes, FCGR3A monocytes, Natural Killer (NK) cells, B cells and Dendritic Cells (DC).

- In addition to these common cell types, Festem identified a fine cell type, CD27− CD4+ memory T cells, which were often missed by other methods.

- The CD27. CD4+ memory T cells identified by Festem expressed common marker genes (IL7R
and S100A4) of memory T cells, but did not express CD27. These cells also had downregulated
expression of SELL, CCR7, MAL and LEF1, and upregulated expression of CCL5 (Fig. 4B) and
thus were the CD27- CD4+ memory T cells in the literature (36). The CD27- CD4+ memory T
cells were known to be at a more differentiated state and have stronger antigen-recall responses
than their CD27+ counterparts.

- 15 PCs

- Num bins along the x-axis = 23, shape parameter = 0.8772751

- learned from the model: There are 3 well-separated clusters in 2D, but if look at the model in high-D space, the three clusters are much closer. Also, there is some continuity within the clustering structure and it didn't capture well. Therefore UMAP with n:neighbour 30 is not a good representation for this data set. 

- The most important parameter is n_neighbors - the number of approximate nearest neighbors used to construct the initial high-dimensional graph. It effectively controls how UMAP balances local versus global structure - low values will push UMAP to focus more on local structure by constraining the number of neighboring points considered when analyzing the data in high dimensions, while high values will push UMAP towards representing the big-picture structure while losing fine detail.

- The second parameter we’ll investigate is min_dist, or the minimum distance between points in low-dimensional space. This parameter controls how tightly UMAP clumps points together, with low values leading to more tightly packed embeddings. Larger values of min_dist will make UMAP pack points together more loosely, focusing instead on the preservation of the broad topological structure.

- The third parameter is metric. This parameter plays a crucial role in determining how distances are computed within the ambient space of the input data (The term "ambient space" refers to the original or initial space in which the data exists before any transformation or dimensionality reduction).

- If it is completely a mess, then that is also further evidence that the fit is poor in high-dimensions.

<!--https://dicook.github.io/mulgar_book/7-spin-and-brush.html#fig-penguins-bs-detourr-->

### Approach followed

- First, referred to @Chen2023 paper which shows UMAP representation of PBMC3k data with 15 PCs and parameter choice of n:neighbor:30, min_dist:0.1, metric:cosine.

- Observed that there is three well-separated clusters.

- Second, visualise the 15 PCs in high-dimensional space with our model and investigate whether can I see the three well-separated clusters or is it showing something different than what I saw in UMAP view suggested by the author.

- Learned from the model: Yes, it's different. There are three clusters but they are really close to each other. Also, in the largest cluster, observed non-linear continuity structure, which didn't captured by the author's UMAP representation.

- Learned from the data: Visualise with detour and colored the clusters in high-D. Identified more than three clusters which is suprising.

- In that case, need to suggest a better UMAP representation than author's suggestion.

- To find a better UMAP representation, I need to investigate different parameter choices for UMAP (or need to try another NLDR technique, but here my objective is to suggest the best parameter choice with UMAP).

- Therefore, I fitted our model for different UMAP parameter choices, record the error, and selected the parameter choice that gives the lowest error which is n:neighbor:5, min_dist:0.99, metric:cosine.

- Then, construct our model for this UMAP data (n:neighbor:5, min_dist:0.99, metric:cosine).

- In this representation, you can see that the clusters are closer, and the continuity of clusters are there.

- Also, what missed from looking at high-D data with detour, in this UMAP representation I can see more than three clusters.

- Then, need to check how correct am I identify the clusters in 2D and is that matched that I identify in high-D.

- Generate a confusion matrix.

### Story

- UMAP representation of PBMC3k data with 15 PCs and parameter choice of n:neighbor:30, min_dist:0.1, metric:cosine (author's suggestion) shows three well-separated clusters (see @fig-nldervisPBMCUMPview). The question we need to answer is: Does this UMAP representation preserve the actual data structure, or is something missing or misidentified or misleading?

```{r}
#| warning: false
#| echo: false

## Import data
training_data_pbmc <- read_rds("data/pbmc/pbmc_3k_festem/pbmc_pca_50.rds")
training_data_pbmc <- training_data_pbmc[, 1:15] |>
  mutate(ID = 1:NROW(training_data_pbmc))

umap_pbmc <- read_rds("data/pbmc/pbmc_3k_festem/pbmc_umap.rds")
umap_pbmc_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = umap_pbmc, 
                                                                 x = "UMAP1", y = "UMAP2"))) |>
  dplyr::mutate(cell_label = umap_pbmc$cell_label) |>
  dplyr::rename(c("UMAP1" = "scaled_UMAP1", 
                  "UMAP2" = "scaled_UMAP2")) |>
  dplyr::mutate(ID = 1:NROW(umap_pbmc))

plot_list2_pbmc <- umap_pbmc_scaled |>
  ggplot(aes(x = UMAP1,
             y = UMAP2))+
  geom_point(alpha=0.5) +
  coord_equal() +
  theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
  theme(legend.position = "none", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
        legend.key.height = unit(0.25, 'cm'),
        legend.key.width = unit(0.25, 'cm')) #+
  # scale_color_manual(values=c("#b15928", "#1f78b4", "#cab2d6", "#ccebc5", "#fb9a99", "#e31a1c", "#6a3d9a", "#ff7f00", "#ffed6f", "#fdbf6f", "#ffff99", "#a6cee3", "#8dd3c7", "#ffffb3", "#bebada", "#fb8072", "#80b1d3", "#fdb462", "#b3de69", "#fccde5", "#d9d9d9", "#b2df8a", "#bc80bd", "#33a02c", "#ccebc5", "#ffed6f", "#000000", "#bdbdbd")) +
  # geom_text(aes(x=UMAP1,y = UMAP2,label = cell_label), data = class_avg,inherit.aes = F, color = "black",fontface = "bold",size = 2) +
  #annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) 
```

```{r}
#| echo: false
#| fig-cap: "(a) 2D layout from UMAP (n_neighbors = 30, min_dist = 0.3) applied for the PBMC3k dataset. Is this a best representation of the original data?"
#| label: fig-nldervisPBMCUMPview
#| fig-pos: H

plot_list2_pbmc 
```


- To investigate this, we are going to visualise the model in the data space, which means that the model generated from UMAP is visualised in high-D with original data.

- To fit the model, first we need to decide how many number bins should allocate along the x and y axes. To make an initial choice, we use MSE plot (@fig-diagnosticpltPBMC (b)).

```{r}
#| warning: false
#| echo: false
#| message: false

## UMAP
## Prediction

#tot_num_bin_vec <- 2:51
hex_size_vec <- seq(0.02, 2, by = 0.01)

vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names

mse_df_pbmc <- dplyr::bind_rows(vec)[0, ]
mse_df_pbmc <- mse_df_pbmc |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = umap_pbmc_scaled, 
            x = "UMAP1", y = "UMAP2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data_pbmc, 
                                   nldr_df_with_id = umap_pbmc_scaled |> dplyr::select(-cell_label), 
                                   x = "UMAP1", y = "UMAP2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "UMAP", 
                                   col_start_highd = "PC_")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data_pbmc, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "UMAP")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data_pbmc, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "PC_")
  
  mse_df_pbmc <- mse_df_pbmc |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_pbmc |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df_pbmc |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_pbmc |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_pbmc <- dplyr::bind_rows(not_dupli_df, duplicate_df)
```

```{r}
#| warning: false
#| echo: false

## To draw with AIC
aic_plot_pbmc <- ggplot(mse_df_pbmc, aes(x = num_bins, y = aic
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 588, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("AIC") +
  xlab("total number of bins")
## Effective number of bins along x-axis

mse_plot_pbmc <- ggplot(mse_df_pbmc, aes(x = num_bins,
                                       y = mse
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 588, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from UMAP applied to training PBMC3k dataset. What is the effective number of bins in each NLDR technique to create a 2D model? The MSE plot have a steep slope at the beginning, indicating that a smaller number of bins causes a larger amount of error. Then, the slope gradually declines or level off, indicating that a higher number of bins generates a smaller error. Using the elbow method, when the total number of bins is set to 588, the slope of the Mean Squared Error (MSE) plot experiences a sudden and noticeable change, resembling an elbow-like shape. This point indicates that adding less bins does not enough to capture the data structure."
#| label: fig-diagnosticpltPBMC
##| out-width: 100%
#| fig-pos: H

aic_plot_pbmc + mse_plot_pbmc +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```

- Then, the model is constructed by following all the steps in 2D and lifts the model into high-D.

```{r}
#| warning: false
#| echo: false
#| message: false

## Decide by looking at MSE plot
num_bins_x_pbmc <- 21
num_bins_y_pbmc <- 28
hex_size_pbmc <- 0.03

hb_obj_pbmc <- hex_binning(data = umap_pbmc_scaled |> dplyr::select(-cell_label), x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x_pbmc, 
                      num_bins_y = num_bins_y_pbmc, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_pbmc, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_pbmc$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_pbmc$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_pbmc$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

umap_data_with_hb_id_pbmc <- as.data.frame(do.call(cbind, hb_obj_pbmc$data_hb_id))
  
model_object <- fit_highd_model( training_data = training_data_pbmc, 
                                 nldr_df_with_id = umap_pbmc_scaled |> dplyr::select(-cell_label), 
                                 x = "UMAP1", y = "UMAP2", 
                                 num_bins_x = num_bins_x_pbmc, 
                                 num_bins_y = num_bins_y_pbmc, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_pbmc,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "UMAP", 
                                 col_start_highd = "PC_")

df_bin_centroids_pbmc <- model_object$df_bin_centroids
df_bin_pbmc <- model_object$df_bin

## Triangulate bin centroids
tr1_object_pbmc <- tri_bin_centroids(df_bin_centroids_pbmc, x = "c_x", y = "c_y")
tr_from_to_df_pbmc <- gen_edges(tri_object = tr1_object_pbmc)

## Compute 2D distances
distance_pbmc <- cal_2d_dist(tr_coord_df = tr_from_to_df_pbmc, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_pbmc) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_pbmc <- find_lg_benchmark(distance_edges = distance_pbmc, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_pbmc, mapping = aes(x = c_x, y = c_y))

trimesh_removed_pbmc_umap <- vis_rmlg_mesh(distance_edges = distance_pbmc, benchmark_value = benchmark_pbmc, tr_coord_df = tr_from_to_df_pbmc, distance_col = "distance")

trimesh_removed_pbmc_umap <- trimesh_removed_pbmc_umap +
  geom_point(data = umap_pbmc_scaled, aes(x = UMAP1, y = UMAP2), alpha = 0.3) +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

# df_all_mnist <- dplyr::bind_cols(training_data_pbmc |> dplyr::select(-ID), umap_data_with_hb_id_pbmc)
# 
# show_langevitour(df_all_pbmc, df_bin_pbmc, df_bin_centroids_pbmc, benchmark_pbmc, distance_pbmc, "distance", col_start = "PC_")

df_bin_train <- df_bin_pbmc
names(df_bin_train)[-1] <- paste0("avg_", names(df_bin_train)[-1])

df_all_pbmc <- dplyr::bind_cols(training_data_pbmc |> dplyr::select(-ID), umap_data_with_hb_id_pbmc)

error_df <- df_all_pbmc |>
  dplyr::left_join(df_bin_train, by = c("hb_id" = "hb_id")) ## Map high-D averaged/weighted mean coordinates

for (i in 1:(NCOL(df_bin_train) - 1)) {

  error_df[ , paste0("abs_residual_", "PC_", i)] <- abs(error_df[ , paste0("PC_", i)] - error_df[ , paste0("avg_", "PC_", i)])

}

error_df <- error_df |>
  dplyr::mutate(total = rowSums(dplyr::pick(tidyselect::starts_with(paste0("abs_residual_", "PC_")))))


error_df <- error_df |>
  mutate(type = if_else(total == 0, "no error",
                        if_else(total <= 15, "error 1-15",
                                if_else(total <= 20, "error 15-20",
                                        if_else(total <= 25, "error 20-25",
                                                if_else(total <= 30, "error 25-30",
                                                        if_else(total <= 35, "error 30-35",
                                                                if_else(total <= 40, "error 35-40", "error greter than 40"))))))))

plot_list2_pbmc_error <- error_df |>
  mutate(type = factor(type , levels = c("no error", "error 1-15", "error 15-20", "error 20-25", "error 25-30", "error 30-35", "error 35-40", "error greter than 40"))) |>
    ggplot(aes(x = UMAP1,
               y = UMAP2, color = type))+
    geom_point(alpha=0.5, size = 0.1) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) +
  scale_color_manual(values=c("#fee0d2", "#fcbba1",
                                         "#fc9272", "#fb6a4a", "#ef3b2c",
                                         "#cb181d", "#a50f15", "#99000d")) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)
```

```{r}
#| echo: false
#| fig-cap: "(a) Model in the 2D space overlaid on UMAP data, and (b) Error occurred by the high-D model for high-D data and the error mapped into 2D NLDR points."
#| label: fig-nldervisPBMCUMAP
#| fig-pos: H

trimesh_removed_pbmc_umap + plot_list2_pbmc_error +
plot_layout(guides='collect', ncol=2) &
  theme(legend.position='bottom') 
```

- As shown in @fig-nldervisPBMCUMAP, there are three well-separated clusters (according to the model in 2D space).

::: {#fig-pbmc1_sc layout-ncol="3" fig-pos="H"}
![](figures/pbmc3k/sc_1.png){#fig-pbmc1_sc1}

![](figures/pbmc3k/sc_2.png){#fig-pbmc1_sc2}

![](figures/pbmc3k/sc_3.png){#fig-pbmc1_sc3}

Screen shots of the **langevitour** of the PBMC3k data set, shows the model in high-D, a video of the tour animation is available at (<https://youtu.be/Gnhh4hfsbbg>).
:::

- According to @fig-pbmc1_sc (a), the model in high-D space shows two well separated clusters. Also, two clusters are really close to each other (see @fig-pbmc1_sc (b)). Furthermore, there are three clusters shown by the model in 2D actually represented in high-D as well (see @fig-pbmc1_sc (c)). Another important thing to notice from the model in high-D space is that the non-linear continuity structure in two well-separated clusters. 

- @fig-pbmc1_sc (c) gives evidence that UMAP preserves the global structure. Furthermore, the non-linearity within the clusters shown in @fig-pbmc1_sc (a) proves that local structure is also preserved but that's not visually shown by th UMAP layout in 2D.

- Can we find a better parameter choice for UMAP which shows this non-linear continuity of the big clusters in 2D space as well?

- To do that, we are going to fit models for different parameter choice and select the one which have the lowest model error in high-D (see @tbl-errordiffcomb).  

```{r}
#| warning: false
#| echo: false

error_df <- read_csv("data/pbmc/pbmc_3k_festem/error_pbmc_umap.csv", col_names = FALSE)

error_df <- error_df |>
  mutate(X4 = round(X4/100, 2),
         X1 = as.integer(X1)) |>
  arrange(X4)

colnames(error_df) <- c("n_neighbors", "min_dist", "metric", "error (x 100)")


kable(error_df, caption = "errors for different parameter combinations", label = "tbl-errordiffcomb") |>
  #xtable2kable() |>
  kable_styling(latex_options = c("striped", "HOLD_position"), position = "center", full_width = FALSE) |>
  row_spec(0, bold = TRUE) |>
  row_spec(7, bold=T, color = "red")
```

<!--UMAP parm option 1-->

```{r}
#| warning: false
#| echo: false

## Import data
training_data_pbmc <- read_rds("data/pbmc/pbmc_3k_festem/pbmc_pca_50.rds")
training_data_pbmc <- training_data_pbmc[, 1:15] |>
  mutate(ID = 1:NROW(training_data_pbmc))

umap_pbmc <- read_rds("data/pbmc/pbmc_umap_5_min_dist_0.99_metric_cosine.rds")
umap_pbmc_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = umap_pbmc, 
                                    x = "UMAP1", y = "UMAP2"))) |>
  dplyr::mutate(cell_label = umap_pbmc$cell_label) |>
  dplyr::rename(c("UMAP1" = "scaled_UMAP1", 
                  "UMAP2" = "scaled_UMAP2")) |>
  dplyr::mutate(ID = 1:NROW(umap_pbmc))

plot_list2_pbmc <- umap_pbmc_scaled |>
    ggplot(aes(x = UMAP1,
               y = UMAP2))+
    geom_point(alpha=0.5) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(legend.position = "none", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) 
```

```{r}
#| echo: false
#| fig-cap: "(a) 2D layout from UMAP (n_neighbors = 5, min_dist = 0.99, metric = cosine) applied for the PBMC3k dataset. Is this a best representation of the original data?"
#| label: fig-nldervisPBMCUMAPview2
#| fig-pos: H

plot_list2_pbmc

```

- Selected the one with n:neighbor:5, min_dist:0.99, metric:cosine (see @fig-nldervisPBMCUMAPview2). As shown in @fig-nldervisPBMCUMAPview2, the two big clusters have non-linear continuity structures, two big clusters are well-separated but close to each other, and the two cluster which exists in the one big cluster are really close to each other (see @fig-nldervisPBMCUMAPview2). 

- Now, we are going to fit the model for the new parameter choice.

```{r}
#| warning: false
#| echo: false
#| message: false

## UMAP
## Prediction

#tot_num_bin_vec <- 2:51
hex_size_vec <- seq(0.02, 2, by = 0.01)

vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names

mse_df_pbmc <- dplyr::bind_rows(vec)[0, ]
mse_df_pbmc <- mse_df_pbmc |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = umap_pbmc_scaled, 
            x = "UMAP1", y = "UMAP2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data_pbmc, 
                                   nldr_df_with_id = umap_pbmc_scaled |> dplyr::select(-cell_label), 
                                   x = "UMAP1", y = "UMAP2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "UMAP", 
                                   col_start_highd = "PC_")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data_pbmc, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "UMAP")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data_pbmc, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "PC_")
  
  mse_df_pbmc <- mse_df_pbmc |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_pbmc |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df_pbmc |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_pbmc |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_pbmc <- dplyr::bind_rows(not_dupli_df, duplicate_df)
```

```{r}
#| warning: false
#| echo: false

## To draw with AIC
aic_plot_pbmc <- ggplot(mse_df_pbmc, aes(x = num_bins, y = aic
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 588, linetype="solid",
                color = "red", size=1, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("AIC") +
  xlab("total number of bins")
## Effective number of bins along x-axis

mse_plot_pbmc <- ggplot(mse_df_pbmc, aes(x = num_bins,
                                       y = mse
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 588, linetype="solid",
                color = "red", size=1, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from UMAP applied to training S-curve dataset. What is the effective number of bins in each NLDR technique to create a 2D model? The MSE plot have a steep slope at the beginning, indicating that a smaller number of bins causes a larger amount of error. Then, the slope gradually declines or level off, indicating that a higher number of bins generates a smaller error. Using the elbow method, when the total number of bins is set to 588, the slope of the Mean Squared Error (MSE) plot experiences a sudden and noticeable change, resembling an elbow-like shape. This point indicates that adding less bins does not enough to capture the data structure."
#| label: fig-diagnosticpltPBMC3
##| out-width: 100%
#| fig-pos: H

aic_plot_pbmc + mse_plot_pbmc +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```

```{r}
#| warning: false
#| echo: false
#| message: false

## Decide by looking at MSE plot
num_bins_x_pbmc <- 21
num_bins_y_pbmc <- 28
hex_size_pbmc <- 0.03

hb_obj_pbmc <- hex_binning(data = umap_pbmc_scaled |> dplyr::select(-cell_label), x = "UMAP1", 
                      y = "UMAP2", num_bins_x = num_bins_x_pbmc, 
                      num_bins_y = num_bins_y_pbmc, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_pbmc, col_start = "UMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_pbmc$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_pbmc$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_pbmc$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)

# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

umap_data_with_hb_id_pbmc <- as.data.frame(do.call(cbind, hb_obj_pbmc$data_hb_id))
  
model_object <- fit_highd_model( training_data = training_data_pbmc, 
                                 nldr_df_with_id = umap_pbmc_scaled |> dplyr::select(-cell_label), 
                                 x = "UMAP1", y = "UMAP2", 
                                 num_bins_x = num_bins_x_pbmc, 
                                 num_bins_y = num_bins_y_pbmc, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_pbmc,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "UMAP", 
                                 col_start_highd = "PC_")

df_bin_centroids_pbmc <- model_object$df_bin_centroids
df_bin_pbmc <- model_object$df_bin

benchmark_value_rm_lwd <- stats::quantile(df_bin_centroids_pbmc$std_counts, 
                probs = c(0,0.25,0.5,0.75,1), names = FALSE)[2]

df_bin_centroids_low <- df_bin_centroids_pbmc |>
  dplyr::filter(std_counts <= benchmark_value_rm_lwd)

identify_rm_bins <- find_low_dens_hex(df_bin_centroids_all = df_bin_centroids_pbmc, 
                                      num_bins_x = num_bins_x_pbmc, 
                                      df_bin_centroids_low = df_bin_centroids_low)

df_bin_centroids_pbmc <- df_bin_centroids_pbmc |>
  dplyr::filter(!(hexID %in% identify_rm_bins))


## Triangulate bin centroids
tr1_object_pbmc <- tri_bin_centroids(df_bin_centroids_pbmc, x = "c_x", y = "c_y")
tr_from_to_df_pbmc <- gen_edges(tri_object = tr1_object_pbmc)

## Compute 2D distances
distance_pbmc <- cal_2d_dist(tr_coord_df = tr_from_to_df_pbmc, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_pbmc) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_pbmc <- find_lg_benchmark(distance_edges = distance_pbmc, distance_col = "distance")
benchmark_pbmc <- 0.08

# ggplot() +
# geom_trimesh(data = df_bin_centroids_pbmc, mapping = aes(x = c_x, y = c_y))

trimesh_removed_pbmc_umap <- vis_rmlg_mesh(distance_edges = distance_pbmc, benchmark_value = benchmark_pbmc, tr_coord_df = tr_from_to_df_pbmc, distance_col = "distance")

trimesh_removed_pbmc_umap <- trimesh_removed_pbmc_umap +
  geom_point(data = umap_pbmc_scaled, aes(x = UMAP1, y = UMAP2), alpha = 0.3) +
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

df_bin_train <- df_bin_pbmc
names(df_bin_train)[-1] <- paste0("avg_", names(df_bin_train)[-1])

df_all_pbmc <- dplyr::bind_cols(training_data_pbmc |> dplyr::select(-ID), umap_data_with_hb_id_pbmc)

error_df <- df_all_pbmc |>
  dplyr::left_join(df_bin_train, by = c("hb_id" = "hb_id")) ## Map high-D averaged/weighted mean coordinates

# prediction_df_join <- prediction_df_join |>
#   dplyr::left_join(data, by = c("ID" = "ID")) ## Map high-D data

for (i in 1:(NCOL(df_bin_train) - 1)) {
  
  error_df[ , paste0("abs_residual_", "PC_", i)] <- abs(error_df[ , paste0("PC_", i)] - error_df[ , paste0("avg_", "PC_", i)])
  
}

error_df <- error_df |>
  dplyr::mutate(total = rowSums(dplyr::pick(tidyselect::starts_with(paste0("abs_residual_", "PC_")))))

# library(ggbeeswarm)
# error_df$group <- "1"
# ggplot(error_df, aes(x = group, y = total)) +
#   geom_quasirandom()+
#   ylim(0, max(unlist(error_df$total))+ 0.5) + coord_flip()

### The minimum error is 0 and the maximum is 42.17439
### There is lot of points with error 0,

error_df <- error_df |>
  mutate(type = if_else(total == 0, "no error",
                        if_else(total <= 15, "error 1-15",
                                if_else(total <= 20, "error 15-20",
                                        if_else(total <= 25, "error 20-25",
                                                if_else(total <= 30, "error 25-30",
                                                        if_else(total <= 35, "error 30-35",
                                                                if_else(total <= 40, "error 35-40", "error greter than 40"))))))))

plot_list2_pbmc_error <- error_df |>
  mutate(type = factor(type , levels = c("no error", "error 1-15", "error 15-20", "error 20-25", "error 25-30", "error 30-35", "error 35-40", "error greter than 40"))) |>
    ggplot(aes(x = UMAP1,
               y = UMAP2, color = type))+
    geom_point(alpha=0.5, size = 0.1) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) +
  scale_color_manual(values=c("#fee0d2", "#fcbba1",
                                         "#fc9272", "#fb6a4a", "#ef3b2c",
                                         "#cb181d", "#a50f15", "#99000d")) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3)

# show_langevitour(df_all_pbmc, df_bin_pbmc, df_bin_centroids_pbmc, benchmark_pbmc, distance_pbmc, "distance", col_start = "PC_")
```

```{r}
#| echo: false
#| fig-cap: "(a) Model in the 2D space overlaid with UMAP data, and (b) Error occurred by the high-D model for high-D data and the error mapped into 2D NLDR points."
#| label: fig-nldervisPBMCUMAP3
#| out-width: 100%
#| fig-pos: H

trimesh_removed_pbmc_umap + plot_list2_pbmc_error +
plot_layout(guides='collect', ncol=2) &
  theme(legend.position='bottom')

```

- According to @fig-nldervisPBMCUMAP3 (a), the model constructed in 2D space for the new parameter choice of UMAP shows 5 clusters which are really close to each other. The big cluster shows the non-linear continuity structure with two sub clusters. Other three clusters positioned in a structure of non-linearity but really close to each other. 

::: {#fig-pbmc2_sc layout-ncol="3" fig-pos="H"}
![](figures/pbmc3k/sc_4.png){#fig-pbmc2_sc1}

![](figures/pbmc3k/sc_5.png){#fig-pbmc2_sc2}

![](figures/pbmc3k/sc_6.png){#fig-pbmc2_sc3}

Screen shots of the **langevitour** of the PBMC3k data set, shows the model in high-D with new parameter choice for UMAP, a video of the tour animation is available at (<https://youtu.be/lc_6-rIuNHI>).
:::

- As shown in @fig-pbmc2_sc, there are 5 clusters, three of them are well-separated but close to each other as seen in @fig-nldervisPBMCUMAP3 (a). Also, other two clusters are really close to each other but separated from the early mentioned three clusters.

- Next, we are going to investigate whether, the clusters we identified in 2D UMAP layout, can also be identified in high-D as well.

- First, I colored the clusters in 2D layout manually. Then, I used spin-and-brush approach with `detour` to color the clusters in high-D. 

<!--Generate true label for PBMC3k-->

```{r}
#| warning: false
#| echo: false

UMAP_pbmc_with_result1_label <- umap_pbmc |>
  dplyr::mutate(result1_class_label = case_when(
    ((UMAP1 >=-12) & (UMAP1 <= -5) & (UMAP2 >= 6) & (UMAP2 <= 18)) ~ "cluster 1",
    ((UMAP1 >-5) & (UMAP1 <= 7) & (UMAP2 >= 4.8) & (UMAP2 <= max(UMAP2))) ~ "cluster 2", ((UMAP1 >=6) & (UMAP1 <= 15) & (UMAP2 >= -4) & (UMAP2 < 4.8)) ~ "cluster 3",
    ((UMAP1 >=-3) & (UMAP1 <= 6.6) & (UMAP2 >= min(UMAP2)) & (UMAP2 <= 4.8)) ~ "cluster 4",
    ((UMAP1 >=min(UMAP1))& (UMAP1 < -3) & (UMAP2 >= -8) & (UMAP2 <= -1)) ~ "cluster 5",
    ((UMAP1 >=min(UMAP1)) & (UMAP1 <= -7) & (UMAP2 >= -3) & (UMAP2 <= 3)) ~ "cluster 6",
    .default = "no class"
    ))

### Reassign some labels

UMAP_pbmc_with_result1_label <- UMAP_pbmc_with_result1_label |>
  dplyr::mutate(result1_class_label = if_else((ID %in% c(2619, 1158)), "cluster 3", result1_class_label)) |>
  dplyr::mutate(result1_class_label = if_else((ID %in% c(948, 285, 158, 268, 731, 1152, 1372, 1651, 2010, 150, 2304, 2546, 487, 2176, 2157, 2451, 264, 63, 1234, 947, 1126, 1699, 1232, 1492, 1488, 2040, 2550, 1313, 361, 372, 1515, 1264, 1307, 1726, 517, 2568, 2274, 591, 1703, 1097, 430, 1556, 2133, 1232, 1194, 1888, 1796, 494, 1194)), "cluster 6", result1_class_label)) 
```

```{r}
#| warning: false
#| echo: false

## Import detour results
detour_results8 <- read_csv("data/pbmc/pbmc_3k_festem/detourr_export8.csv")

### Rename labels

detour_results8 <- detour_results8 |>
  dplyr::mutate(result2_class_label = case_when(
    colour == "000000" ~ "cluster 4",
    colour == "49df20" ~ "cluster 2",
    colour == "619cff" ~ "cluster 3",
    colour == "d82cd3" ~ "cluster 1",
    colour == "df2020" ~ "cluster 5",
    colour == "ffbd61" ~ "cluster 6",
    .default = "no cluster"
    
  ))

detour_results8 <- detour_results8 |>
  dplyr::mutate(ID = training_data_pbmc$ID)

df_res_1_2_label <- inner_join(UMAP_pbmc_with_result1_label, detour_results8, by = c("ID" = "ID"))

result1_2d_layout <- df_res_1_2_label |>
    ggplot(aes(x = UMAP1,
               y = UMAP2, color = result1_class_label))+
    geom_point(alpha=0.5) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) +
  scale_color_manual(values=c("#d82cd3", "#49df20", "#619cff", "#000000", "#df2020", "#ffbd61", "yellow")) +
  # geom_text(aes(x=UMAP1,y = UMAP2,label = cell_label), data = class_avg,inherit.aes = F, color = "black",fontface = "bold",size = 2) +
  annotate(geom = 'text', label = 'a', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) +
  labs(colour = "cluster labels")

result2_2d_layout <- df_res_1_2_label |>
    ggplot(aes(x = UMAP1,
               y = UMAP2, color = result2_class_label))+
    geom_point(alpha=0.5) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(legend.position = "bottom", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) +
  scale_color_manual(values=c("#d82cd3", "#49df20", "#619cff", "#000000", "#df2020", "#ffbd61", "yellow")) +
  # geom_text(aes(x=UMAP1,y = UMAP2,label = cell_label), data = class_avg,inherit.aes = F, color = "black",fontface = "bold",size = 2) +
  annotate(geom = 'text', label = 'b', x = -Inf, y = Inf, hjust = -0.5, vjust = 1.5, size = 3) +
  labs(colour = "cluster labels")

table(df_res_1_2_label$result1_class_label, df_res_1_2_label$result2_class_label)

```

```{r}
#| echo: false
#| fig-cap: "2D layout from UMAP (n_neighbors = 5, min_dist = 0.99, metric = cosine) applied for PBMC3k dataset (a) colored manually in 2D, (b) colored in high-D."
#| label: fig-nldervisPBMCUMAP3Res
#| out-width: 100%
#| fig-pos: H

result1_2d_layout + result2_2d_layout +
  plot_layout(guides='collect', ncol=2) &
  theme(legend.position='bottom')

```

- @fig-nldervisPBMCUMAP3Res shows the 2D UMAP layout colored with each method. As shown in @fig-nldervisPBMCUMAP3Res (b) and the confusion matrix,there are some miss-classifications. What is the reason for that?

- For example, the point (ID: 1158) classified as **cluster 3** in 2D UMAP layout, classified as **cluster 6** when doing the colouring in high-D (see @fig-nldervisPBMCUMAP3Res). Why?

::: {#fig-pbmc2_appsc layout-ncol="1" fig-pos="H"}
![](figures/pbmc3k/sc_7.png){#fig-pbmc2_sc7}

Screen shots of app which shows 2D UMAP layout and comparison of distances related to the point classified as **cluster 6** in high-D (ID: 1158) and randomly selected point which is in **cluster 6** (ID: 2291).
:::

- If we compute the distance between these two points, you will see that it preserves the pair-wise distance (see @fig-pbmc2_appsc), which give us a evidence that even though the point 1158, classified as **cluster 3** in 2D layout, actually should be in **cluster 6**. This also evident that some misleading can happens with UMAP.

::: {#fig-pbmc2_appsc1 layout-ncol="1" fig-pos="H"}
![](figures/pbmc3k/sc_8.png){#fig-pbmc2_sc8}

Screen shots of app which shows 2D UMAP layout and comparison of distances related to the point classified as **cluster 5** in high-D (ID: 3) and randomly selected point which is in **cluster 5** (ID: 2198).
:::

- For another example, if we compute the distance between these two points, you will see that it preserves the pair-wise distance (see @fig-pbmc2_appsc1), which give us a evidence that even though the point 3, classified as **cluster 4** in 2D layout, actually should be in **cluster 5**. This also evident that some misleading can happens with UMAP.

```{r}
#| warning: false
#| echo: false
#| message: false

df_all_pbmc <- dplyr::bind_cols(training_data_pbmc, umap_data_with_hb_id_pbmc)

df_all_pbmc <- inner_join(df_all_pbmc, detour_results8, by = c("ID" = "ID"))

### Define type column
df <- df_all_pbmc |>
  dplyr::select(tidyselect::starts_with("PC_"), result2_class_label) |>
  dplyr::rename("type" = "result2_class_label") ## original dataset

df_b <- df_bin_pbmc |>
  dplyr::filter(hb_id %in% df_bin_centroids_pbmc$hexID) |>
  dplyr::mutate(type = "model") ## Data with summarized mean

## Reorder the rows of df_b according to the hexID order in df_b_with_center_data
df_b <- df_b[match(df_bin_centroids_pbmc$hexID, df_b$hb_id),] |>
  dplyr::select(-hb_id)

df_exe <- dplyr::bind_rows(df_b, df)

 ## Set the maximum difference as the criteria
distance_df_small_edges <- distance_pbmc |>
  dplyr::filter(distance < benchmark_pbmc)
## Since erase brushing is considerd.

# langevitour::langevitour(df_exe[1:(length(df_exe)-1)],
#                          lineFrom = distance_df_small_edges$from,
#                            lineTo = distance_df_small_edges$to,
#                          group = df_exe$type, pointSize = 3,
#                          levelColors = c("#d82cd3", "#49df20", "#619cff", "#000000", "#df2020", "#ffbd61", "#33a02c"))

```

### Handwritten digits

- Why I choose this data set? Because I need show that whatever NLDR technique that we use, our model can capture the non-linear structure within clusters as well. 

- Digit 1 (7877 images only)

#### Preprocessing

- Scale the pixel values to the range [0,1]

- Reshape to have a 2-dimensional array

-  reshaping pixel data is a fundamental preprocessing step in image analysis tasks, ensuring that the data is in a suitable format for further analysis, modeling, and interpretation. It helps preserve important spatial information, ensures compatibility with machine learning models, and facilitates feature extraction and visualization.

-  Reshaping the pixel data allows us to preserve this spatial information, ensuring that the relationships between neighboring pixels are maintained.

- Many machine learning algorithms, including neural networks, expect input data to be in a specific format. For image data, this typically means a two-dimensional array where each row represents a single sample (image), and each column represents a feature (pixel value). Reshaping ensures that all samples have consistent dimensions, making them suitable for feeding into these algorithms.

- Reshaping the pixel data allows for easier extraction of relevant features from the images. Once reshaped, individual pixels can be treated as features, making it easier to apply techniques like dimensionality reduction (e.g., PCA) or feature engineering to extract meaningful information from the images.

- Selected 10 PCs based on scree plot

- 7877 images of digit 1 

- PaCMAP parameters: n_components=2, n_neighbors=10, init="random", MN_ratio=0.9, FP_ratio=2.0

#### Model

- Total number of bins used: 180 (num_x = 12, num_y = 15, hex_size = 0.06)

- Learned from the model: There is a non-linear shape in 2D, but if look at the model in high-D, the non-linear continuity is there but there is a twist in the structure which didn't capture by PaCMAP in 2D layout.

#### Story

- PaCMAP representation of MNIST digit 1 data with 10PCs and parameter choice of n_components=2, n_neighbors=10, init="random", MN_ratio=0.9, FP_ratio=2.0 shows a non-linear structure (see @fig-nldervisMNISTPACMAP (a)). I selected this parameter choice because this the default parameter setting for PaCMAP and selected PaCMAP because when I observed the 5 NLDR techniques applied for the data PaCMAP showed the non-linear structure effectively in 2D.

- By looking at MSE plot, I selected the 180 bins, which associated with 12 bins along the x-axis, 15 bins along the y-axis, and hex size as 0.06 (@fig-diagnosticpltMNIST (b)). Then, fitted the model in 2D (see @fig-nldervisMNISTPACMAP (b)). As you can see in @fig-nldervisMNISTPACMAP (b), the fitted model capture the non-linear structure of the 2D data. 


```{r}
#| warning: false
#| echo: false

## Import data
training_data_mnist <- read_rds("data/mnist/mnist_10_pcs_of_digit_1.rds")
training_data_mnist <- training_data_mnist |>
  mutate(ID = 1:NROW(training_data_mnist))

pacmap_minst <- read_rds("data/mnist/mnist_pacmap.rds")
pacmap_minst_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = pacmap_minst, 
                                    x = "PaCMAP1", y = "PaCMAP2"))) |>
  dplyr::rename(c("PaCMAP1" = "scaled_PaCMAP1", 
                  "PaCMAP2" = "scaled_PaCMAP2")) |>
  dplyr::mutate(ID = 1:NROW(pacmap_minst))


plot_list2_mnist <- pacmap_minst_scaled |>
    ggplot(aes(x = PaCMAP1,
               y = PaCMAP2))+
    geom_point(alpha=0.5) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(legend.position = "none", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) +
  # geom_text(aes(x=UMAP1,y = UMAP2,label = cell_label), data = class_avg,inherit.aes = F, color = "black",fontface = "bold",size = 2) +
  annotate(geom = 'text', label = 'a', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3) 
```

```{r}
#| warning: false
#| echo: false
#| message: false

## UMAP
## Prediction

#tot_num_bin_vec <- 2:51
hex_size_vec <- seq(0.02, 2, by = 0.01)

vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names

mse_df_mnist <- dplyr::bind_rows(vec)[0, ]
mse_df_mnist <- mse_df_mnist |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = pacmap_minst_scaled, 
            x = "PaCMAP1", y = "PaCMAP2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data_mnist, 
                                   nldr_df_with_id = pacmap_minst_scaled, 
                                   x = "PaCMAP1", y = "PaCMAP2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "PaCMAP", 
                                   col_start_highd = "PC")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data_mnist, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "PaCMAP")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data_mnist, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "PC")
  
  mse_df_mnist <- mse_df_mnist |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_mnist |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df_mnist |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_mnist |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_mnist <- dplyr::bind_rows(not_dupli_df, duplicate_df)
```

```{r}
#| warning: false
#| echo: false

## To draw with AIC
aic_plot_mnist <- ggplot(mse_df_mnist, aes(x = num_bins, y = aic
)) +
  geom_point() +
  geom_line() +
  geom_vline(xintercept = 180, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("AIC") +
  xlab("total number of bins")
## Effective number of bins along x-axis

mse_plot_mnist <- ggplot(mse_df_mnist, aes(x = num_bins,
                                       y = mse
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 180, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from PaCMAP applied to training MNIST dataset. What is the effective number of bins in each NLDR technique to create a 2D model? The MSE plot have a steep slope at the beginning, indicating that a smaller number of bins causes a larger amount of error. Then, the slope gradually declines or level off, indicating that a higher number of bins generates a smaller error. Using the elbow method, when the total number of bins is set to 180, the slope of the Mean Squared Error (MSE) plot experiences a sudden and noticeable change, resembling an elbow-like shape. This point indicates that adding less bins does not enough to capture the data structure."
#| label: fig-diagnosticpltMNIST
##| out-width: 100%
#| fig-pos: H

aic_plot_mnist + mse_plot_mnist +
  plot_annotation(tag_levels = 'a') +
  plot_layout(guides='collect', ncol = 2) &
  theme(legend.position='none', plot.tag = element_text(size = 8))
```

```{r}
#| warning: false
#| echo: false
#| message: false

## Decide by looking at MSE plot
num_bins_x_mnist <- 12
num_bins_y_mnist <- 15
hex_size_mnist <- 0.06

hb_obj_mnist <- hex_binning(data = pacmap_minst_scaled, x = "PaCMAP1", 
                      y = "PaCMAP2", num_bins_x = num_bins_x_mnist, 
                      num_bins_y = num_bins_y_mnist, x_start = NA, y_start = NA, 
                      buffer_x = NA, buffer_y = NA, hex_size = hex_size_mnist, col_start = "PaCMAP")

## Data set with all possible centroids in the hexagonal grid
all_centroids_df <- as.data.frame(do.call(cbind, hb_obj_mnist$centroids))

## Generate all coordinates of hexagons
hex_grid <- as.data.frame(do.call(cbind, hb_obj_mnist$hex_poly))

## To obtain the standardise counts within hexbins
counts_df <- as.data.frame(do.call(cbind, hb_obj_mnist$std_cts))
df_bin_centroids <- extract_hexbin_centroids(centroids_df = all_centroids_df, 
                                             counts_df = counts_df)
# ggplot(data = hex_grid, aes(x = x, y = y)) +
#   geom_polygon(fill = "white", color = "black", aes(group = hex_poly_id)) +
#   geom_point(data = all_centroids_df, aes(x = c_x, y = c_y), color = "red") +
#   coord_fixed()

hex_grid_with_counts <- dplyr::left_join(hex_grid, counts_df, by = c("hex_poly_id" = "hb_id"))

# ggplot(data = hex_grid_with_counts, aes(x = x, y = y)) +
#   geom_polygon(color = "black", aes(group = hex_poly_id, fill = std_counts)) +
#   geom_text(data = all_centroids_df, aes(x = c_x, y = c_y, label = hexID)) +
#   scale_fill_viridis_c(direction = -1, na.value = "#ffffff") +
#   coord_fixed()

pacmap_data_with_hb_id_mnist <- as.data.frame(do.call(cbind, hb_obj_mnist$data_hb_id))
  
model_object <- fit_highd_model( training_data = training_data_mnist, 
                                 nldr_df_with_id = pacmap_minst_scaled, 
                                 x = "PaCMAP1", y = "PaCMAP2", 
                                 num_bins_x = num_bins_x_mnist, 
                                 num_bins_y = num_bins_y_mnist, 
                                 x_start = NA, y_start = NA, 
                                 buffer_x = NA, buffer_y = NA, 
                                 hex_size = hex_size_mnist,
                                 is_rm_lwd_hex = FALSE, 
                                 benchmark_to_rm_lwd_hex = NA, 
                                 col_start_2d = "PaCMAP", 
                                 col_start_highd = "PC")

df_bin_centroids_mnist <- model_object$df_bin_centroids
df_bin_mnist <- model_object$df_bin

## Triangulate bin centroids
tr1_object_mnist <- tri_bin_centroids(df_bin_centroids_mnist, x = "c_x", y = "c_y")
tr_from_to_df_mnist <- gen_edges(tri_object = tr1_object_mnist)

## Compute 2D distances
distance_mnist <- cal_2d_dist(tr_coord_df = tr_from_to_df_mnist, 
                             start_x = "x_from", start_y = "y_from", 
                             end_x = "x_to", end_y = "y_to", 
                             select_vars = c("from", "to", "distance"))


# distance_plot <- plot_dist(distance_mnist) +
#   ylab(expression(d^{(2)})) +
#   theme(axis.text = element_text(size = 5),
#         axis.title = element_text(size = 12))
# 
# distance_plot

## To find the benchmark value
benchmark_mnist <- find_lg_benchmark(distance_edges = distance_mnist, distance_col = "distance")

# ggplot() +
# geom_trimesh(data = df_bin_centroids_mnist, mapping = aes(x = c_x, y = c_y))

trimesh_removed_mnist_pacmap <- vis_rmlg_mesh(distance_edges = distance_mnist, benchmark_value = benchmark_mnist, tr_coord_df = tr_from_to_df_mnist, distance_col = "distance")

trimesh_removed_mnist_pacmap <- trimesh_removed_mnist_pacmap +
  geom_point(data = pacmap_minst_scaled, aes(x = PaCMAP1, y = PaCMAP2), alpha = 0.06) + 
  theme_linedraw() +
  theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title.x = element_blank(), axis.title.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  annotate(geom = 'text', label = 'b', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

df_bin_train <- df_bin_mnist
names(df_bin_train)[-1] <- paste0("avg_", names(df_bin_train)[-1])

df_all_mnist <- dplyr::bind_cols(training_data_mnist, pacmap_data_with_hb_id_mnist)

error_df <- df_all_mnist |>
  dplyr::left_join(df_bin_train, by = c("hb_id" = "hb_id")) ## Map high-D averaged/weighted mean coordinates

# prediction_df_join <- prediction_df_join |>
#   dplyr::left_join(data, by = c("ID" = "ID")) ## Map high-D data

for (i in 1:(NCOL(df_bin_train) - 1)) {
  
  error_df[ , paste0("abs_residual_", "PC", i)] <- abs(error_df[ , paste0("PC", i)] - error_df[ , paste0("avg_", "PC", i)])
  
}

error_df <- error_df |>
  dplyr::mutate(total = rowSums(dplyr::pick(tidyselect::starts_with(paste0("abs_residual_", "PC")))))

# library(ggbeeswarm)
# error_df$group <- "1"
# ggplot(error_df, aes(x = group, y = total)) +
#   geom_quasirandom()+
#   ylim(0, max(unlist(error_df$total))+ 0.5) + coord_flip()

### The minimum error is 0 and the maximum is 42.17439
### There is lot of points with error 0,

error_df <- error_df |>
  mutate(type = if_else(total == 0, "no error",
                        if_else(total <= 2, "error 0-2",
                                if_else(total <= 4, "error 2-4",
                                        if_else(total <= 6, "error 4-6",
                                                if_else(total <= 10, "error 6-10",
                                                        if_else(total <= 12, "error 10-12",
                                                                if_else(total <= 14, "error 12-14", "error greter than 14"))))))))

plot_list2_mnist_error <- error_df |>
  mutate(type = factor(type , levels = c("no error", "error 0-2", "error 2-4", "error 4-6", "error 6-10", "error 10-12", "error 12-14", "error greter than 14"))) |>
    ggplot(aes(x = PaCMAP1,
               y = PaCMAP2, color = type))+
    geom_point(alpha=0.5, size = 0.1) +
    coord_equal() +
    theme(plot.title = element_text(hjust = 0.5, size = 18, face = "bold")) + #ggtitle("(a)") +
  theme_linedraw() +
    theme(plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm')) +
  scale_color_manual(values=c("#fee0d2", "#fcbba1",
                                         "#fc9272", "#fb6a4a", "#ef3b2c",
                                         "#cb181d", "#a50f15", "#99000d")) +
  annotate(geom = 'text', label = 'c', x = Inf, y = Inf, hjust = 1.5, vjust = 1.5, size = 3)

show_langevitour(df_all_mnist, df_bin_mnist, df_bin_centroids_mnist, benchmark_mnist, distance_mnist, "distance", col_start = "PC")

# predict_minst_df <- as.data.frame(do.call(cbind, predict_emb(training_data_mnist, df_bin_centroids_mnist, df_bin_mnist, "PaCMAP")))
# gen_summary(training_data_mnist, predict_minst_df, df_bin_mnist, col_start = "PC")
```

```{r}
#| echo: false
#| fig-cap: "(a) 2D layout from PaCMAP (n_components=2, n_neighbors=10, init=random, MN_ratio=0.9, FP_ratio=2.0) applied for the digit 1 of the MNIST dataset, (b) Model in the 2D space overlaid on PaCMAP data, and (c) Error occurred by the high-D model for high-D data and the error mapped into 2D NLDR points."
#| label: fig-nldervisMNISTPACMAP
#| out-width: 100%
#| fig-pos: H

plot_list2_mnist + trimesh_removed_mnist_pacmap + plot_list2_mnist_error +
plot_layout(guides='collect', ncol=3) &
  theme(legend.position='bottom')
```

- Next, the constructed 2D model lifts into high-dimensions (see @fig-mnist1_sc).

::: {#fig-mnist1_sc layout-ncol="3" fig-pos="H"}
![](figures/mnist/sc_1.png){#fig-mnist1_sc1}

![](figures/mnist/sc_2.png){#fig-mnist1_sc2}

![](figures/mnist/sc_3.png){#fig-mnist1_sc3}

Screen shots of the **langevitour** of the MNIST digit 1 data set, shows the model in high-D, a video of the tour animation is available at (<https://youtu.be/zq2GM9qvUNA>).
:::

- As shown in @fig-mnist1_sc (a), the non-linear continuity structure that you have seen in 2D representation of PaCMAP, also can be seen in the model in high-D space as well. This gives us an evidence that our model capture the non-linear structure of the data effectively.

- Furthermore, our model shows some addition pattern of data which couldn't be seen in the 2D layout.

- One is the twisted structure within the non-linear structure (see @fig-mnist1_sc (c)).

- Another thing is the connected corners of the non-linear structure (see @fig-mnist1_sc (b)). The non-linear curve is bended.

- To gives the evidence that PaCMAP preserve the local structure (non-linear pattern), our model helps by computing the model errors (@fig-diagnosticpltMNIST (c)).

<!--images with large error in high-D-->

```{r}
#| warning: false
#| echo: false

img_error <- error_df |> 
  dplyr::filter(total >= 10) |> 
  dplyr::pull(ID)

mnist_data <- read_rds("data/mnist/mnist_digit_1.rds")
pixels_gathered <-  mnist_data |>
  mutate(instance = row_number()) |>
  gather(pixel, value, -Label, -instance) |>
  tidyr::extract(pixel, "pixel", "(\\d+)", convert = TRUE) |>
  mutate(pixel = pixel - 2, x = pixel %% 28, y = 28 - pixel %/% 28) |>
  filter(instance %in% img_error) 

theme_set(theme_light())
imge_error_sample <- pixels_gathered |> 
  ggplot(aes(x, y, fill = value)) +  
  geom_tile() +  
  facet_wrap(~ instance) +
  theme(legend.position = "none", plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
              axis.title.x = element_blank(), axis.title.y = element_blank(),
              axis.text.x = element_blank(), axis.ticks.x = element_blank(),
              axis.text.y = element_blank(), axis.ticks.y = element_blank(),
              panel.grid.major = element_blank(), panel.grid.minor = element_blank(), #change legend key width
        legend.title = element_text(size=5), #change legend title font size
        legend.text = element_text(size=4),
         legend.key.height = unit(0.25, 'cm'),
         legend.key.width = unit(0.25, 'cm'),
        strip.text = element_blank())
```

```{r}
#| echo: false
#| fig-cap: "Images of handwritten digit 1 which occur large model error."
#| label: fig-sampleimg
#| out-width: 100%
#| fig-pos: H

imge_error_sample
```

- As you can see in @fig-diagnosticpltMNIST (c), the largest model error shows in the upper right side of the 2D layout. A sample of the images that shows the largest error can be seen in @fig-sampleimg. The reason for the large model error is that the high-D points related to this largest error located away from the high-D model points.  

## Conclusion {#sec-conclusion}

In conclusion, our proposed model offers a novel approach for visualizing high-dimensional (high-D) data by leveraging non-linear dimension reduction (NLDR) techniques. Through a series of steps including hexagonating NLDR data, triangulating bin centroids, and lifting the 2D triangular mesh into high dimensions, our model effectively transforms complex high-D data into interpretable 2D representations. The model's performance is evaluated using goodness of fit statistics such as Mean Squared Error (MSE) and Akaike Information Criterion (AIC), providing insights into its accuracy and reliability. Overall, our model presents a valuable tool for researchers and practitioners in various fields to gain deeper insights from high-dimensional datasets.

Our algorithm mainly consists... 

These Goodness of fit statistics useful in encountering the prediction accuracy when we predict the 2D embedding for the new high-D data. Because, we try to find the nearest high-D mappings as the first step of prediction which will participate the prediction process. When we need to find which different NLDR technique and which parameter choices is giving the best representation of high-D data, MSE and AIC are also useful.  

We introduce a new tool to help to determine which method, which parameter choice provide the most useful representation of high-D data.

<!--Our research introduces a comprehensive framework that leverages tours for interactive exploration of high-dimensional data coupled with a low-dimensional manifold, facilitated by the `quollr` R package. Regardless of the Non-Linear Dimension Reduction (NLDR) technique in use, our approach demonstrates effectiveness through simulation examples, particularly in the iterative removal of long edges for a smoother representation and capturing cluster variance.

In the example with doublets, our method successfully captures the tweak within each cluster, indicating the variance present within them. However, the model may not appear smooth in high-dimensional space due to considerable noise when the data has a piecewise linear geometry, such as the tree simulation.

The practical application of our framework, as showcased with the UMAP view, enables visual inspection of well-separated clusters. Furthermore, the combined tour and model provide a robust assessment of whether UMAP preserves the data structure and accurately transforms the data.

The advantages of our approach include its versatility across various NLDR techniques and the ability to generate interactive visualizations for detailed exploration. The tour provides an intuitive way to navigate and comprehend high-dimensional data while assessing the accuracy of dimensionality reduction.

However, one limitation is that the approach may be less effective in cases with significant noise, as seen in the tree simulation example. Additionally, while our method aids in visual verification, quantifying the accuracy of embeddings might require further evaluation metrics.

In conclusion, our framework presents a powerful tool for researchers and analysts in single-cell studies to assess their embeddings by visually inspecting them alongside the original data. By leveraging the advantages of tours and low-dimensional manifolds, our approach offers valuable insights into the data transformation process, empowering users to make informed decisions in analyzing high-dimensional data. Future work could enhance the method's robustness in the presence of noise and explore additional evaluation metrics for quantifying embedding accuracy.-->

  
## References {.unnumbered}
  
::: {#refs}
:::
      
{{< pagebreak >}}
    
