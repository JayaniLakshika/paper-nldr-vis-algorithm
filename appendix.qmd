---
title: "Appendix: Visualising How Non-linear Dimension Reduction Warps Your Data"
author:
  - name: Jayani P.G. Lakshika
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-6265-6481
    email: jayani.piyadigamage@monash.edu
    url: https://jayanilakshika.netlify.app/
  - name: Dianne Cook
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-3813-7155
    email: dicook@monash.edu 
    url: http://www.dicook.org/
  - name: Paul Harrison
    affiliations:
      - name: Monash University
        department: MGBP, BDInstitute
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0002-3980-268X
    email: 	paul.harrison@monash.edu
    url: 
  - name: Michael Lydeamore
    affiliations:
      - name: Monash University
        department: Econometrics & Business Statistics
        address: Clayton
        city: VIC 
        country: Austria
        postal-code: 3800
    orcid: 0000-0001-6515-827X
    email: michael.lydeamore@monash.edu
    url: https://www.michaellydeamore.com/
  - name: Thiyanga S. Talagala
    affiliations:
      - name: University of Sri Jayewardenepura
        department: Statistics
        address: Gangodawila
        city: Nugegoda 
        country: Sri Lanka
        postal-code: 10100
    orcid: 0000-0002-0656-9789
    email: ttalagala@sjp.ac.lk 
    url: https://thiyanga.netlify.app/
tbl-cap-location: bottom
---

```{r}
#| warning: false
#| echo: false
library(quollr)
library(dplyr)
library(ggplot2)
library(readr)
library(tidyr)
library(patchwork)
library(langevitour)
library(colorspace)
library(kableExtra)
library(grid)
set.seed(20240110)

#source("nldr_code.R", local = TRUE)
```

<!-- To find the number of bins should assign for the model in tSNE-->
```{r}
#| warning: false
#| echo: false
#| message: false
#| eval: false

training_data_gau <- read_rds("data/five_gau_clusters/data_five_gau_training.rds")
tSNE_data_gau <- read_rds("data/five_gau_clusters/tsne_data_five_gau_61.rds")

tsne_gau_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = tSNE_data_gau, 
                                    x = "tSNE1", y = "tSNE2"))) |>
  dplyr::rename(c("tSNE1" = "scaled_tSNE1", 
                  "tSNE2" = "scaled_tSNE2")) |>
  dplyr::mutate(ID = 1:NROW(tSNE_data_gau))    


## tSNE
hex_size_vec <- seq(0.02, 2, by = 0.01)

vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names

mse_df_gau <- dplyr::bind_rows(vec)[0, ]
mse_df_gau <- mse_df_gau |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = tsne_gau_scaled, 
            x = "tSNE1", y = "tSNE2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data_gau, 
                                   nldr_df_with_id = tsne_gau_scaled, 
                                   x = "tSNE1", y = "tSNE2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "tSNE", 
                                   col_start_highd = "x")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data_gau, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "tSNE")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data_gau, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "x")
  
  mse_df_gau <- mse_df_gau |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_gau |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df_gau |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_gau |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_gau <- dplyr::bind_rows(not_dupli_df, duplicate_df) 
```

```{r}
#| warning: false
#| echo: false
#| eval: false

mse_plot_gau <- ggplot(mse_df_gau, aes(x = num_bins,
                                       y = log(mse)
)) +
  geom_point(size = 0.8) +
  geom_line() +
   geom_vline(xintercept = 588, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from different NLDR techniques applied to training five spherical Gaussian cluster dataset. What is the best NLDR technique to represent the original data in 2D?"
#| label: fig-diagnosticpltGau
#| out-width: 100%
#| fig-pos: H
#| eval: false

mse_plot_gau 
```


<!-- MSE plot to find which is the effective number of bins to use-->
```{r}
#| warning: false
#| echo: false
#| message: false
#| eval: false

## UMAP
## Prediction

## Import data
training_data_pbmc <- read_rds("data/pbmc3k/pbmc_pca_50.rds")
training_data_pbmc <- training_data_pbmc[, 1:9] |>
  mutate(ID = 1:NROW(training_data_pbmc))

umap_pbmc <- read_rds("data/pbmc3k/pbmc_umap_30_min_dist_0.3.rds")
umap_pbmc_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = umap_pbmc, 
                                                                 x = "UMAP1", y = "UMAP2"))) |>
  dplyr::rename(c("UMAP1" = "scaled_UMAP1", 
                  "UMAP2" = "scaled_UMAP2")) |>
  dplyr::mutate(ID = 1:NROW(umap_pbmc))

#tot_num_bin_vec <- 2:51
hex_size_vec <- seq(0.02, 2, by = 0.01)

vec <- stats::setNames(rep("", 7), c("num_bins", "error", "mse", "num_bins_x", "num_bins_y", "hex_size", "num_non_empty_bins"))  ## Define column names

mse_df_pbmc <- dplyr::bind_rows(vec)[0, ]
mse_df_pbmc <- mse_df_pbmc |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = umap_pbmc_scaled, 
            x = "UMAP1", y = "UMAP2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data_pbmc, 
                                   nldr_df_with_id = umap_pbmc_scaled, 
                                   x = "UMAP1", y = "UMAP2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "UMAP", 
                                   col_start_highd = "PC_")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data_pbmc, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "UMAP")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data_pbmc, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "PC_")
  
  mse_df_pbmc <- mse_df_pbmc |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    error = eval_list$error,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i],
                    num_non_empty_bins = NROW(centroid_df_training))
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_pbmc |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df_pbmc |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_pbmc |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_pbmc <- dplyr::bind_rows(not_dupli_df, duplicate_df)
```

```{r}
#| warning: false
#| echo: false
#| eval: false

mse_plot_pbmc <- ggplot(mse_df_pbmc, aes(x = num_bins,
                                       y = mse
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 588, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from UMAP applied to training PBMC3k dataset. What is the effective number of bins in UMAP to create a 2D model? The MSE plot have a steep slope at the beginning, indicating that a smaller number of bins causes a larger amount of error. Then, the slope gradually declines or level off, indicating that a higher number of bins generates a smaller error. Using the elbow method, when the total number of bins is set to 588, the slope of the MSE plot experiences a sudden and noticeable change, resembling an elbow-like shape. This point indicates that adding less bins does not enough to capture the data structure."
#| label: fig-msepltpbmc
#| fig-pos: H
#| eval: false

mse_plot_pbmc
```

<!-- MSE plot to find which is the effective number of bins to use-->

```{r}
#| warning: false
#| echo: false
#| message: false
#| eval: false

## Import data
training_data_mnist <- read_rds("data/mnist/mnist_10_pcs_of_digit_1.rds")
training_data_mnist <- training_data_mnist |>
  mutate(ID = 1:NROW(training_data_mnist))

pacmap_minst <- read_rds("data/mnist/mnist_pacmap.rds")
pacmap_minst_scaled <- as.data.frame(do.call(cbind, gen_scaled_data(data = pacmap_minst, 
                                    x = "PaCMAP1", y = "PaCMAP2"))) |>
  dplyr::rename(c("PaCMAP1" = "scaled_PaCMAP1", 
                  "PaCMAP2" = "scaled_PaCMAP2")) |>
  dplyr::mutate(ID = 1:NROW(pacmap_minst))

## UMAP
## Prediction

#tot_num_bin_vec <- 2:51
hex_size_vec <- seq(0.02, 2, by = 0.01)

vec <- stats::setNames(rep("", 6), c("num_bins", "aic", "mse", "num_bins_x", "num_bins_y", "hex_size"))  ## Define column names

mse_df_mnist <- dplyr::bind_rows(vec)[0, ]
mse_df_mnist <- mse_df_mnist |>
  dplyr::mutate_if(is.character, as.numeric)

for (i in 1:length(hex_size_vec)) {
  
  num_bin_list <- calc_bins(data = pacmap_minst_scaled, 
            x = "PaCMAP1", y = "PaCMAP2", 
            hex_size = hex_size_vec[i], buffer_x = NA, buffer_y = NA)
  
  num_bins_x <- num_bin_list$num_x
  num_bins_y <- num_bin_list$num_y
  
  model_object <- fit_highd_model( training_data = training_data_mnist, 
                                   nldr_df_with_id = pacmap_minst_scaled, 
                                   x = "PaCMAP1", y = "PaCMAP2", 
                                   num_bins_x = num_bins_x, 
                                   num_bins_y = num_bins_y, 
                                   x_start = NA, y_start = NA, 
                                   buffer_x = NA, buffer_y = NA, 
                                   hex_size = hex_size_vec[i],
                                   is_rm_lwd_hex = FALSE, 
                                   benchmark_to_rm_lwd_hex = NA, 
                                   col_start_2d = "PaCMAP", 
                                   col_start_highd = "PC")
  
  centroid_df_training <- model_object$df_bin_centroids
  avg_df_training <- model_object$df_bin
  
  pred_emb_list <- predict_emb(test_data = training_data_mnist, 
                                  df_bin_centroids = centroid_df_training, 
                                  df_bin = avg_df_training, type_NLDR = "PaCMAP")
  
  pred_df_training <- as.data.frame(do.call(cbind, pred_emb_list))
  
  eval_list <- gen_summary(test_data = training_data_mnist, 
                                  prediction_df = pred_df_training, 
                                  df_bin = avg_df_training, col_start = "PC")
  
  mse_df_mnist <- mse_df_mnist |>
    tibble::add_row(num_bins = num_bins_x * num_bins_y,
                    aic = eval_list$aic,
                    mse = eval_list$mse,
                    num_bins_x = num_bins_x,
                    num_bins_y = num_bins_y,
                    hex_size = hex_size_vec[i])
  

}


## If same total number of bins occurred only select ones with minimum error
### Obtain duplicate bins
dupli_bins <- mse_df_mnist |> 
  dplyr::count(num_bins) |> 
  dplyr::filter(n > 1) |> 
  dplyr::pull(num_bins)

### Group split by duplicated bins
duplicate_df_list <- mse_df_mnist |>
  dplyr::filter(num_bins %in% dupli_bins) |>
  dplyr::arrange(num_bins) |>
  dplyr::group_split(num_bins)

### Obtain one row from duplicates which have lowest error and hexsize
duplicate_df <- data.frame(matrix(nrow = 0, ncol = 0))

for (i in 1:length(duplicate_df_list)) {
  
  dd <- duplicate_df_list[[i]] |>
    dplyr::filter(mse == min(duplicate_df_list[[i]]$mse)) |>
    dplyr::filter(hex_size == min(duplicate_df_list[[i]]$hex_size))
  
  duplicate_df <- dplyr::bind_rows(duplicate_df, dd)
  
}

### Obtain the mse_df with not duplicated bins
not_dupli_df <- mse_df_mnist |>
  dplyr::filter(!(num_bins %in% dupli_bins))

### Combine duplicated and not duplicated(corrected) bins dfs
mse_df_mnist <- dplyr::bind_rows(not_dupli_df, duplicate_df)
```

```{r}
#| warning: false
#| echo: false
#| eval: false

mse_plot_mnist <- ggplot(mse_df_mnist, aes(x = num_bins,
                                       y = mse
)) +
  geom_point() +
  geom_line() +
   geom_vline(xintercept = 180, linetype="solid",
                color = "red", size=0.8, alpha = 0.5) +
  theme_light() +
  theme(legend.position = "none", legend.title = element_blank(), plot.title = element_text(size = 7, hjust = 0.5, vjust = -0.5),
        axis.title = element_text(size = 7),
        axis.text = element_text(size = 7)) +
  #scale_colour_manual(values = c("#377eb8")) +
  ylab("MSE") +
  xlab("total number of bins")

```

```{r}
#| echo: false
#| fig-cap: "Goodness of fit statistics from PaCMAP applied to training MNIST dataset. What is the effective number of bins in PaCMAP to create a 2D model? The MSE plot have a steep slope at the beginning, indicating that a smaller number of bins causes a larger amount of error. Then, the slope gradually declines or level off, indicating that a higher number of bins generates a smaller error. Using the elbow method, when the total number of bins is set to 180, the slope of the Mean Squared Error (MSE) plot experiences a sudden and noticeable change, resembling an elbow-like shape. This point indicates that adding less bins does not enough to capture the data structure."
#| label: fig-diagnosticpltMNIST
#| fig-pos: H
#| eval: false

mse_plot_mnist
```
