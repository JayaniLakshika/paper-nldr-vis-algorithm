% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-1in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.7in}%
\addtolength{\topmargin}{-1in}%
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{float}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{bm}
\def\tightlist{}
\usepackage{setspace}
\newcommand\pD{$p\text{-}D$}
\newcommand\kD{$k\text{-}D$}
\newcommand\dD{$d\text{-}D$}
\newcommand\gD{$2\text{-}D$}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{agsm}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Looking at Non-Linear Dimension Reductions as Models in the Data Space},
  pdfauthor={Jayani P.G. Lakshika; Dianne Cook; Paul Harrison; Michael Lydeamore; Thiyanga S. Talagala},
  pdfkeywords={high-dimensional data, dimension reduction, hexagon
binning, low-dimensional manifold, tour, data vizualization, model in
the data space},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}



\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\bf Looking at Non-Linear Dimension Reductions as Models in the
Data Space}
\author{
Jayani P.G. Lakshika\\
Econometrics \& Business Statistics, Monash University\\
and\\Dianne Cook\\
Econometrics \& Business Statistics, Monash University\\
and\\Paul Harrison\\
MGBP, BDInstitute, Monash University\\
and\\Michael Lydeamore\\
Econometrics \& Business Statistics, Monash University\\
and\\Thiyanga S. Talagala\\
Statistics, University of Sri Jayewardenepura\\
}
\maketitle

\bigskip
\bigskip
\begin{abstract}
Nonlinear dimension reduction (NLDR) techniques such as tSNE, and UMAP
provide a low-dimensional representation of high-dimensional (high-D)
data using non-linear transformation. The methods and parameter choices
can create wildly different representations, making it difficult to
decide which is best, or whether any or all are accurate or misleading.
NLDR often exaggerates random patterns, sometimes due to the samples
observed. But NLDR views have an important role in data analysis
because, if done well, they provide a concise visual (and conceptual)
summary of high-D distributions. To help evaluate the NLDR we have
developed an algorithm to show the 2D NLDR model in the high-D space,
viewed with a tour. One can see if the model fits everywhere or better
in some subspaces, or completely mismatches the data. It is used to
evaluate which 2D layout is the best representation of the high-D
distribution and see how different methods may have similar summaries or
quirks.
\end{abstract}

\noindent%
{\it Keywords:} high-dimensional data, dimension reduction, hexagon
binning, low-dimensional manifold, tour, data vizualization, model in
the data space
\vfill

\newpage
\spacingset{1.9} % DON'T change the spacing!


\spacingset{1.0}

\section{Introduction}\label{introduction}

Non-linear dimension reduction (NLDR) is popular for making a convenient
low-dimensional (\kD{}) representation of high-dimensional (\pD{}) data.
Recently developed methods include t-distributed stochastic neighbor
embedding (tSNE) \citep{laurens2008}, uniform manifold approximation and
projection (UMAP) \citep{leland2018}, potential of heat-diffusion for
affinity-based trajectory embedding (PHATE) algorithm \citep{moon2019},
large-scale dimensionality reduction Using triplets (TriMAP)
\citep{amid2022}, and pairwise controlled manifold approximation
(PaCMAP) \citep{yingfan2021}. However, the representation generated can
vary dramatically from method to method, and with different choices of
parameters or random seeds made using the same method
(Figure~\ref{fig-NLDR-variety}). The dilemma for the analyst is then,
\textbf{which representation to use}. The choice might result in
different procedures used in the downstream analysis, or different
inferential conclusions. The research described here provides new visual
tools to aid with this decision.

\begin{figure}

\centering{

\includegraphics[width=1\textwidth,height=\textheight]{paper_files/figure-pdf/fig-NLDR-variety-1.pdf}

}

\caption{\label{fig-NLDR-variety}Six different NLDR representations of
the same data. Different techniques and different parameter choices are
used. Researchers may have seen any of these in their analysis of this
data, depending on their choice of method, or typical parameter choice.
Would they make different decisions downstream in the analysis depending
on which version seen? Which is the most accurate representation of the
structure in high dimensions?}

\end{figure}%

The paper is organised as follows. Section~\ref{sec-background} provides
a summary of the literature on NLDR, and high-dimensional data
visualization methods. Section~\ref{sec-method} contains the details of
the new methodology, including simulated data examples. Two applications
illustrating the use of the new methodology for bioinformatics and image
classification are in Section~\ref{sec-applications}. Limitations and
future directions are provided in Section~\ref{sec-discussion}.

\section{Background}\label{sec-background}

Historically, \kD{} representations of \pD{} data have been computed
using multidimensional scaling (MDS) \citep{borg2005}, which includes
principal components analysis (PCA) \citep{jolliffe2011} as a special
case. The \kD{} representation can be considered to be a layout of
points in \kD{} produced by an embedding procedure that maps the data
from \pD{}. In MDS, the \kD{} layout is constructed by minimizing a
stress function that differences distances between points in \pD{} with
potential distances between points in \kD{}. Various formulations of the
stress function result in non-metric scaling \citep{saeed2018} and
isomap \citep{silva2002}. Challenges in working with high-dimensional
data, including visualization, are outlined in \citet{johnstone2009}.

Many new methods for NLDR have emerged in recent years, all designed to
better capture specific structures potentially existing in \pD{}. Here
we focus on five currently popular techniques, tSNE, UMAP, PHATE, TriMAP
and PaCMAP. tNSE and UMAP can be considered to produce the \kD{}
minimizing the divergence between two distributions, where the
distributions are modeling the inter-point distances. PHATE, TriMAP and
PaCMAP are examples of diffusion processes \citep{coifman2005} spreading
to capture geometric shapes, that include both global and local
structure.

The array of layouts in Figure~\ref{fig-NLDR-variety} illustrate what
can emerge from the choices of method and parameters, and the random
seed that initiates the computation. Key structures interpreted from
these views suggest: (1) highly \textbf{separated clusters} (a, b, e, g,
h) with the number ranging from 3-6; (2) \textbf{stringy branches} (f),
and (3) \textbf{barely separated clusters} (c, d) which would
\textbf{contradict} the other representations.

It happens because these methods and parameter choices provide different
lenses on the interpoint distances in the data.

The alternative approach to visualizing the high-dimensional data is to
use linear projections. PCA is the classical approach, resulting in a
set of new variables which are linear combinations of the original
variables. Tours, defined by \citet{lee2021}, broaden the scope by
providing movies of linear projections, that provide views the data from
all directions. \citet{lee2021} provides an review of the main
developments in tours. There are many tour algorithms implemented, with
many available in the R package \texttt{tourr} \citep{wickham2011}, and
versions enabling better interactivity in \texttt{langevitour}
\citep{harisson2024} and \texttt{detourr} \citep{hart2022}. Linear
projections are a safe way to view high-dimensional data, because they
do not warp the space, so they are more faithful representations of the
structure. However, linear projections can be cluttered, and global
patterns can obscure local structure. The simple activity of projecting
data from \pD{} suffers from piling \citep{laa2022}, where data
concentrates in the center of projections. NLDR is designed to escape
these issues, to exaggerate structure so that it can be observed. But as
a result NLDR can hallucinate wildly, to suggest patterns that are not
actually present in the data.

The solution is to use the tour to examine how the NLDR is warping the
space. This approach follows what \citet{wickham2015} describes as
\emph{model-in-the-data-space}. The fitted model should be overlaid on
the data, to examine the fit relative the spread of the observations.
While this is straightforward, and commonly done when data is \gD{}, it
is also possible in \pD{}, for many models, when a tour is used.

\citet{wickham2015} provides several examples of models overlaid on the
data in \pD{}. In hierarchical clustering, a representation of the
dendrogrom using points and lines can be constructed by augmenting the
data with points marking merging of clusters. Showing the movie of
linear projections reveals shows how the algorithm sequentially fitted
the cluster model to the data. For linear discriminant analysis or
model-based clustering the model can be indicated by \((p-1)\text{-}D\)
ellipses. It is possible to see whether the elliptical shapes
appropriately matches the variance of the relevant clusters, and to
compare and contrast different fits. For PCA, one can display the \kD{}
plane of the reduced dimension using wireframes of transformed cubes.
Using a wireframe is the approach we take here, to represent the NLDR
model in \pD{}.

\section{Method}\label{sec-method}

\subsection{What is the NLDR model?}\label{what-is-the-nldr-model}

At first glance, thinking of NLDR as a modeling technique might seem
strange. It is a simplified representation or abstraction of a system,
process, or phenomenon in the real world. The \pD{} observations are the
realization of the phenomenon, and the \kD{} NLDR layout is the
simplified representation. From a statistical perspective we can
consider the distances between points in the \kD{} layout to be variance
that the model explains, and the (relative) difference with their
distances in \pD{} is the error, or unexplained variance. We can also
imagine that the positioning of points in \gD{} represent the fitted
values, that will have some prescribed position in \pD{} that can be
compared with their observed values. This is the conceptual framework
underlying the more formal versions of factor analysis \citep{cfa69} and
multidimensional scaling (MDS) \citep{borg2005}. (Note that, for this
thinking the full \pD{} data needs to be available, not just the
interpoint distances.)

\begin{table}

\centering{

\centering\begingroup\fontsize{12}{14}\selectfont

\begin{tabular}{>{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{12cm}}
\toprule
\textbf{Notation} & \textbf{Description}\\
\midrule
$n, p, k$ & number of observations, variables, embedding dimension, respectively\\
$\mathbfit{X}, \mathbfit{x}$ & $p$-dimensional data (population, sample)\\
$\mathbfit{y}$ & $k$-dimensional layout\\
$P$ & orthonormal basis, generating a $d\text{-}dimensional$ linear projection of $p$-dimensional data\\
$T$ & true  model\\
\addlinespace
$g$ & functional mapping from \pD{} to \kD{}, especially as prescribed by NLDR\\
$\mathbfit{\theta}$ & (Hyper-) parameters for NLDR method\\
$r$ & ranges of the embedding components\\
$C^{(j)}$ & $j$-dimensional bin centers\\
$(b_1, b_2)$ & number of bins in each direction\\
\addlinespace
$(a_1, a_2)$ & binwidths, distance between centroids in each direction\\
$(s_1, \ s_2)$ & starting coordinates of the hexagonal grid\\
$q$ & buffer to ensure hexgrid covers data, proportion of data range, 0-1\\
$m$ & number of non-empty bins\\
$b$ & number of  hexagons in the grid\\
\addlinespace
$h$ & hexagonal id\\
\bottomrule
\end{tabular}
\endgroup{}

}

\caption{\label{tbl-notation}Summary of notation for describing new
methodology.}

\end{table}%

We define the NLDR as a function
\(g\text{:}~ \mathbb{R}^{n\times p} \rightarrow \mathbb{R}^{n\times k}\),
with (hyper-)parameters \(\mathbfit{\theta}\). The parameters,
\(\mathbfit{\theta}\), depend on the choice of \(g\), and can be
considered part of model fitting in the traditional sense. Common
choices for \(g\) include functions used in tSNE, UMAP, PHATE, TriMAP,
PaCMAP, or MDS, although in theory any function that does this mapping
is suitable.

With our goal being to make a representation of this \gD{} layout that
can be lifted into high-dimensional space, the layout needs to be
augmented to include neighbour information. A simple approach would be
to triangulate the points and add edges. A more stable approach is to
first hexagonly bin the data, reducing it from \(n\) to \(m\leq n\)
observations, and connect the bin centroids. This process serves to
reduce some noisiness in the resulting surface shown in \pD{}. The steps
in this process are shown in Figure~\ref{fig-NLDR-scurve}, and
documented below.

To illustrate the method, we use \(7\text{-}D\) simulated data, which we
call the ``S-curve''. It is constructed by simulating \(n=750\)
observations from \(\theta \sim U(-3\pi/2, 3\pi/2)\),
\(X_1 = \sin(\theta)\), \(X_2 \sim U(0, 2)\) (adding thickness to the
S), \(X_3 = \text{sign}(\theta) \times (\cos(\theta) - 1)\). The
remaining variables \(X_4, X_5, X_6, X_7\) are all uniform error, with
small variance. We would consider \(T=(X_1, X_2, X_3)\) to be the
geometric structure (true model) that we hope to capture.

\begin{figure}[H]

\begin{minipage}{0.33\linewidth}
\begin{center}
\includegraphics[width=1.5625in,height=\textheight]{figures/scurve/sc_true_1.png}
\end{center}
\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\begin{center}
\includegraphics[width=1.5625in,height=\textheight]{figures/scurve/sc_true_2.png}
\end{center}
\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\begin{center}
\includegraphics[width=1.5625in,height=\textheight]{figures/scurve/sc_true_3.png}
\end{center}
\end{minipage}%

\caption{\label{fig-scurve-true-sc}Three views of the true model in
projections from \(7\text{-}D\), for the S-curve data. The model closely
fits the shape. (The \textbf{langevitour} software is used to view the
data with a tour, and the full video is available at
(\url{https://youtu.be/tYATMiSlCXQ}).}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\textwidth,height=\textheight]{paper_files/figure-pdf/fig-NLDR-scurve-1.pdf}

}

\caption{\label{fig-NLDR-scurve}Key steps for constructing the model on
the UMAP layout (\(k=2\)): (a) data, (b) hexagon bins, (c) bin
centroids, and (d) triangulated centroids. The S-curve data is shown.}

\end{figure}%

\subsection{Algorithm to represent the model in
2D}\label{algorithm-to-represent-the-model-in-2d}

\subsubsection{Scale the data}\label{scale-the-data}

Because we are working with distances between points, starting with data
having a standard scale, e.g.~{[}0, 1{]}, is recommended. The default
should take the aspect ratio produced by the NLDR
\((r_1, r_2, ..., r_k)\) into account. When \(k=2\), as in hexagon
binning, the default range is \([0, y_{i,\text{max}}], i=1,2\), where
\(y_{1,\text{max}}=1\) and \(y_{2,\text{max}} = \frac{r_2}{r_1}\)
(Figure~\ref{fig-NLDR-scurve}). If the NLDR aspect ratio is ignored then
set \(y_ {2,\text{max}} = 1\).

\subsubsection{Computing hexagon grid
configuration}\label{computing-hexagon-grid-configuration}

The \gD{} hexagon grid is defined by the number of bins in each
direction \((b_1, b_2)\), giving total number of bins as
\(b = b_1 \times b_2\), and a unique hexagon id, \(h = 1, \dots, b\).
Each hexagon, \(H_h\) is uniquely described by centroid,
\(C_{h}^{(2)} = (c_{h1}, c_{h2})\). (Note that, we explain the algorithm
for constructing the grid and binning the data here because,
surprisingly, there is no readily available implementation that could
produce everything needed for this project.)

To make the grid, a buffer parameter (\(q\)) is set as a proportion of
the plot space. By default this is 0.1. A value should be chosen to
provide at buffer of a full hexagon width (\(a_1\)) and height (\(a_2\))
for the grid to extend beyond the data, in all directions. The lower
left position where the grid starts is defined as \((s_1, s_2)\), and
corresponds to the centroid of the lowest left hexagon. This must be
smaller than the minimum data value. This is computed as
\(s_1 = -q - a_1\), and \(s_2 = -q \times r_2\) to have buffer around
the data space. The user provides the preferred number of bins in the
horizontal direction, \(b_1\), and the algorithm computes the
appropriate number of bins in the vertical direction, \(b_2\).

The value for \(b_2\) is computed by fixing \(b_1\). Considering the
upper bound of the first NLDR component, \(a_1 > \frac{1+q}{b_1 -3}\).
Similarly, for the second NLDR component,
\(a_2 > \frac{r_2(1 + q)}{(b_2 - 2)}\). Since
\(a_2 = \frac{\sqrt(3)}{2}a_1\) for regular hexagons,
\(a_1 > \frac{2r_2(1 + q)}{\sqrt{3}(b_2 - 2)}\). This is a linear
optimization problem. Therefore, the optimal solution must occur on a
vertex. Therefore,
\(b_2 = \Big\lceil2 +\frac{2r_2(b_1 - 3)}{\sqrt{3}}\Big\rceil\).

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=0.3\textheight]{paper_files/figure-pdf/fig-hex-param-1.pdf}

}

\caption{\label{fig-hex-param}The components of the hexagon grid
illustrating notation.}

\end{figure}%

\subsubsection{Binning the data}\label{binning-the-data}

Observations are grouped into bins based on their nearest centroid. This
produces a reduction in size of the data from \(n\) to \(m\), where
\(m\leq b\) (total number of bins). This can be defined using the
function
\(u: \mathbb{R}^{n\times 2} \rightarrow \mathbb{R}^{m\times 2}\), where
\(u(i) = \arg\min_{j = 1, \dots, b} \sqrt{(y_{i1} - C^{(2)}_{j1})^2 + (y_{i2} - C^{(2)}_{j2})^2}\),
mapping observation \(i\) into \(H_h = \{i| u(i) = h\}\).

By default, the bin centroid is used for describing a hexagon (as done
in Figure~\ref{fig-NLDR-scurve} (c)), but any measure of center, such as
a mean or weighted mean of the points within each hexagon, could be
used. The bin centers, and the binned data, are the two important
components needed to render the model representation in high dimensions.

\subsubsection{Indicating neighborhood}\label{indicating-neighborhood}

Delaunay triangulation \citep{lee1980} is used to connect neighboring
centroids, which is needed to preserve neighborhood information when the
model is lifted into \pD{}.

It can also happen that distant centroids can be connected, which can
result in long line segments. In order to generate a smooth surface in
\gD{}, these long line segments must be removed
(Figure~\ref{fig-NLDR-scurve} (d)).

\subsection{\texorpdfstring{Rendering the model in
\pD{}}{Rendering the model in }}\label{rendering-the-model-in}

The last step is to lift the \kD{} model into \pD{} by computing \pD{}
vectors that represent bin centroids. We use the \pD{} mean of the
points in \(H_h\) to map the centroid \(C_{h}^{(2)} = (c_{h1}, c_{h2})\)
to a point in \pD{}. Let the \pD{} mean be

\[C_{h}^{(p)} = \frac{1}{n_h}\sum_{i =1}^{n_h} x_i, h = {1, \dots, b; n_h > 0}.\]
Furthermore, line segments that exist in the \kD{} model generate line
segments in \pD{} by connecting the \pD{} means of the corresponding
\kD{} bin centroids.

\begin{figure}[H]

\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_best_trimesh.png}\end{minipage}%
%
\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_1.png}\end{minipage}%
%
\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_2.png}\end{minipage}%
%
\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_3.png}\end{minipage}%

\caption{\label{fig-scurve-sc}XXX Model in \gD{}, on the UMAP layout,
and three views of the fit in projections from \(7\text{-}D\), for the
S-curve data. The model closely fits the shape, but it has breaks which
means that it does not adequately capture the surface. (The
\textbf{langevitour} software is used to view the data with a tour, and
the full video is available at (\url{https://youtu.be/N6iWEj3aVps}).}

\end{figure}%

\subsection{Measuring the fit}\label{sec-summary}

The model here is similar to a confirmatory factor analysis model (REF),
\(\widehat{T}(X_1, X_2, X_3) + \Epsilon\). The difference between the
fitted model and observed values would be considered to be residuals,
and for this problem are \(7\text{-}D\).

Observations are associated with their bin center, \(C_{h}^{(p)}\),
which are also considered to be the \emph{fitted values}. These can also
be denoted as \(\widehat{X}\).

The error is computed by taking the squared \pD{} Euclidean distance,
corresponding to computing the mean squared error (MSE) as:

\begin{equation}\phantomsection\label{eq-equation1}{\frac{1}{n}\sum_{h = 1}^{b}\sum_{i = 1}^{n_h}\sum_{j = 1}^{p} (\mathbfit{x}_{hij} - C^{(p)}_{hj})^2}\end{equation}

where \(n\) is the number of observations, \(b\) is the number of bins,
\(n_h\) is the number of observations in \(h^{th}\) bin, \(p\) is the
number of variables, \(\mathbfit{x}_{hij}\) is the \(j^{th}\)
dimensional data of \(i^{th}\) observation in \(h^{th}\) hexagon.

\subsection{\texorpdfstring{Prediction into
\gD{}}{Prediction into }}\label{prediction-into}

A new benefit of this fitted model is that it allows us to now predict a
new observation's value in the NLDR, for any method. The steps are to
determine the closest bin center in \pD{}, \(C^{(p)}_{h}\) and predict
it to be the centroid of this bin in \gD{}, \(C^{(2)}_{h}\). This can be
written as, let
\(z(i) = \arg\min_{j = 1, \dots, b} \sqrt{\sum_{v=1}^{p}(x_{iv} - C^{(p)}_{jv})^2}\),
then the new observation \(i\) falls in the hexagon,
\(H_h = \{i| z(i) = h\}\) and the corresponding \kD{} bin centroids,
\(C_{h}^{(2)} = (c_{h1}, c_{h2})\).

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}
\begin{center}
\includegraphics[width=1.5625in,height=\textheight]{figures/scurve/sc_true_only.png}
\end{center}
\end{minipage}%
%
\begin{minipage}{0.50\linewidth}
\begin{center}
\includegraphics[width=1.5625in,height=\textheight]{figures/scurve/pred_true_view.png}
\end{center}
\end{minipage}%

\caption{\label{fig-scurve-pred-sc}A view of the true model in
projections from \(7\text{-}D\), and predictions of the true model in
\gD{}, for the S-curve data. The predictions fits the UMAP layout which
means that it capture the geometry of S-curve with UMAP.}

\end{figure}%

\subsection{Tuning}\label{tuning}

The performance and robustness of our model depend on three key
parameters: (i) the total number of bins (\(b\)), (ii) a benchmark value
used to remove low-density hexagons, and (iii) a benchmark value used to
remove long edges. However, there is no analytical formula to calculate
an appropriate value for these parameters. The selection of these
parameter values depends on the model performance computed by MSE (see
Section~\ref{sec-summary}).

\subsubsection{Choice of bins}\label{choice-of-bins}

The number of hexagon bins in the hexagon grid has a considerable impact
on the construction of the \gD{} model, serving as the initial step. The
chosen total number of bins must effectively capture the structure of
the NLDR data. If the number of bins is too low, the model may not be
able to capture the structure of the NLDR data effectively (see
Figure~\ref{fig-bins-scurve} (a)), while if there are too many bins, it
may result in over-fitting the individual points of the NLDR data (see
Figure~\ref{fig-bins-scurve} (c)). Therefore, it is important to
determine an effective number of bins to construct a reasonable model
(see Figure~\ref{fig-bins-scurve} (b)).

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=\textheight]{paper_files/figure-pdf/fig-bins-scurve-1.pdf}

}

\caption{\label{fig-bins-scurve}Hexbin density plots of UMAP layout of
the S-curve data, using three different bin inputs: (a) \(b = 70\) (7,
10), (b) \(b = 240\) (12, 20), and (c) \(b = 322\) (14, 23). Color
indicates standardized counts, dark indicating high count and light
indicates low count. At the smallest bin size the data segregates into
two separate groups, suggesting this is too many bins. Using the MSE of
the model fit in \(p-D\) helps decide on a useful choice of number of
bins.}

\end{figure}%

To determine the effective \(b\), candidate values are selected based on
the range between the minimum and approximate maximum \(b_1\), because
\(b_2\) is computed from \(b_1\). The minimum \(b_1\) is set to \(2\),
while the maximum number is estimated by taking the square root of
\(\frac{n}{2}\). The analysis evaluates the MSE across varying \(b\)
within this range, covering the minimum to maximum values along both
axes (see \textbf{?@fig-mse-scurve-b}).

\subsubsection{Removal of low density
bins}\label{removal-of-low-density-bins}

Once setting up the hexagon grid with an appropriate number of bins,
some hexagon bins may have few or no data points within them (see
Figure~\ref{fig-bins-scurve} (b)). To ensure comprehensive coverage of
the NLDR data, it is necessary to select hexagon bins with a
considerable number of data points. This involves calculating the number
of points within each hexagon. Then, the standard count is computed by
dividing the number of points within each hexagon by the maximum number
of points in the grid. Next, bins with a standard count less than a
benchmark value are removed (see \textbf{?@fig-lwd-scurve} (a)). There
is no specific rule for selecting a benchmark value. However, the
following steps can help determine a suitable value for removing
low-density hexagons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Plot the distribution of the standardized counts (see
  \textbf{?@fig-stdcts-scurve}).
\item
  Examine the distribution of counts.
\item
  Select the first quantile value if the distribution is skewed.
\end{enumerate}

The benchmark value for removing low-density hexagons ranges between
\(0\) and \(1\). When analyzing how these benchmark values influence
model performance, it's essential to observe the change in MSE as the
benchmark value increases (see \textbf{?@fig-mse-scurve-lwd}). The MSE
shows a gradual increase as the benchmark value progresses from \(0\) to
\(1\). Evaluating this rate of increase is important. If the increment
is not considerable, the decision might lean towards retaining
low-density hexagons.

Furthermore, selecting the benchmark value for removing low-density
hexagons is important. Removing unnecessary bins may lead to the
formation of long edges and an uneven \gD{} model. Hence, rather than
solely relying on the benchmark value to identify hexagons for removal,
it's essential to consider the standard number of points in the
neighboring hexagons of the identified low-density bins (see
\textbf{?@fig-lwd-scurve} (b)). If neighboring bins also show low
counts, only those bins will be removed. The remaining bins are used to
construct the \gD{} model.

\subsubsection{Removing long edges}\label{removing-long-edges}

To create a smooth \gD{} representation (see
Figure~\ref{fig-NLDR-scurve} (d)), it is necessary to remove edges that
connect distant bin centroids in the triangular mesh. These edges only
exist in the \gD{} model and do not extend into \pD{}, so their removal
does not impact the model in \pD{}. Although there are no specific
criteria for determining the benchmark value to remove long edges, the
following steps provide an approach to identifying a suitable threshold:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Plot the distribution of the 2D Euclidean distances (see
  \textbf{?@fig-dist-scurve}).
\item
  Identify the first largest difference between consecutive distance
  values.
\item
  Take the distance value corresponding to this difference as the
  benchmark value.
\end{enumerate}

\begin{figure}[H]

{\centering \includegraphics[width=1\textwidth,height=\textheight]{paper_files/figure-pdf/unnamed-chunk-31-1.pdf}

}

\caption{Various plots to help assess best number of bins, low density
bin and large edge removal. Both (a) and (c) show MSE, against number of
bins and standardised count. A good benchmark value for these parameters
is when the MSE drops and then flattens out. Plot (b) shows the
distribution of stadardised counts of hexagons. Plot (c) shows the
distribution of \(2\text{-}D\) Euclidean distances between bin
centroids, with a good benchmark value for removing large edges would
being the distance that shows the first large increase.}

\end{figure}%

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=\textheight]{paper_files/figure-pdf/fig-lg-scurve-1.pdf}

}

\caption{\label{fig-lg-scurve}\(2\text{-}D\) model generated for
different benchmark values to remove long edges: (a) benchmark =
\(0.201\) (default), (b) benchmark = \(0.35\), and (c) benchmark =
\(1.1\). What is the effective benchmark value to remove long edges?}

\end{figure}%

\section{Best fit}\label{best-fit}

Deciding on the best fit relies on several elements:

\begin{itemize}
\tightlist
\item
  the choice of NLDR method, and the parameters used to create it, and
\item
  model fit parameters: bin size, low density bin removal, long edge
  removal.
\end{itemize}

Comparing the MSE to obtain the best fit is suitable if one starts from
the same NLDR representation. In theory, because the MSE is computed on
\pD{} measuring the fit between model and data it might still be useful
to compare different NLDR representations. A good NLDR representation
should produce a good fit, producing a low MSE if the model fits the
data well. However, it technically might be quite variable.

Figure~\ref{fig-scurve-sc-best} shows one of the best fits for S-curve
data. TriMAP with \(15\) nearest neighbors for forming the nearest
neighbor triplet (\texttt{n\_inliers}), \(3\) outliers for forming the
nearest neighbor triplets (\texttt{n\_outliers}), \(3\) random triplets
per point (\texttt{n\_random}) is used as the NLDR method. The model is
generated with \(103\) bins, which have a width of \(0.154\) and a
height of \(0.133\). Edges with lengths greater than \(0.266\) are
removed.

\begin{figure}[H]

\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_best_trimap_trimesh.png}\end{minipage}%
%
\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_trimap_best_1.png}\end{minipage}%
%
\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_trimap_best_2.png}\end{minipage}%
%
\begin{minipage}{0.25\linewidth}
\includegraphics{figures/scurve/sc_trimap_best_3.png}\end{minipage}%

\caption{\label{fig-scurve-sc-best}Model in \gD{}, on the TriMAP layout,
and three views of the fit in projections from \(7\text{-}D\), for the
S-curve data. The model closely fits the shape, but it has twists. (The
\textbf{langevitour} software is used to view the data with a tour, and
the full video is available at (\url{https://youtu.be/zEz2MUCtADM}).}

\end{figure}%

\section{A curious difference between t-SNE, UMAP and PaCMAP
revealer}\label{a-curious-difference-between-t-sne-umap-and-pacmap-revealer}

In this section, the effectiveness of the algorithm is described using a
simulated dataset. The dataset consists of five spherical Gaussian
clusters in \(4\text{-}D\), with each cluster containing an equal number
of points and the same within-cluster variation.

The \gD{} layouts generated by tSNE, UMAP, and PaCMAP show five
well-separated clusters which evident these methods effectively preserve
the global structure. In tSNE (Figure~\ref{fig-gau-tsne-sc} (a)), these
clusters appear closely. UMAP arranges all clusters in a parallel
manner, with three aligned in one line and the other two in a separate
line (Figure~\ref{fig-gau-umap-sc} (a)). In contrast, PaCMAP shows one
central cluster and the remaining four spread out in different
directions (Figure~\ref{fig-gau-pacmap-sc} (a)).

The tSNE and UMAP shows \emph{filled out} clusters which provide
evidence that these methods preserve the local structure
(Figure~\ref{fig-gau-tsne-sc} (c) and Figure~\ref{fig-gau-umap-sc} (c)).
On the other hand, PaCMAP shows \emph{flat} shapes clusters in the model
and evident that PaCMAP fail to capture the within-cluster variation
(Figure~\ref{fig-gau-pacmap-sc} (c)).

\begin{figure}[H]

\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/tsne_layout.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/2d_model_tsne.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/sc_tsne_3.png}\end{minipage}%

\caption{\label{fig-gau-tsne-sc}The tSNE layout, model in \gD{}, and a
view of the fit in projections from \(4\text{-}D\), for the five
Gaussian cluster data. The model fits the separation and tries to
\emph{filled out} the clusters. (The \textbf{langevitour} software is
used to view the data with a tour, and the full video is available at
(\url{https://youtu.be/RASEE7N5MbM}).}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/umap_layout.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/2d_model_umap.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/sc_umap_3.png}\end{minipage}%

\caption{\label{fig-gau-umap-sc}The UMAP layout, model in \gD{}, and a
view of the fit in projections from \(4\text{-}D\), for the five
Gaussian cluster data. The model fits the separation and tries to
\emph{filled out} the clusters, but not as much as tSNE. (The
\textbf{langevitour} software is used to view the data with a tour, and
the full video is available at (\url{https://youtu.be/iG4bCPkJilw}).}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/pacmap_layout.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/2d_model_pacmap.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/five_gau_clusters/sc_pacmap_2.png}\end{minipage}%

\caption{\label{fig-gau-pacmap-sc}The PaCMAP layout, model in \gD{}, and
a view of the fit in projections from \(4\text{-}D\), for the five
Gaussian cluster data. The model fits the separation and shows
\emph{flat} shaped clusters. (The \textbf{langevitour} software is used
to view the data with a tour, and the full video is available at
(\url{https://youtu.be/z07cKXi8EJQ}).}

\end{figure}%

\section{Applications}\label{sec-applications}

\subsection{Single-cell gene
expression}\label{single-cell-gene-expression}

In the field of single-cell studies, a common analytical task involves
clustering to identify groups of cells with similar expression profiles.
NLDR is commonly used to display clusters, and help to verify the
results. For example, \citet{chen2023} illustrates the use of UMAP to
identify clusters in Human Peripheral Blood Mononuclear Cells (PBMC3k).
Figure~\ref{fig-umap-author} is a reproduction of the published plot. It
shows three well-separated clusters.

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=0.3\textheight]{paper_files/figure-pdf/fig-umap-author-1.pdf}

}

\caption{\label{fig-umap-author}Reproduction of plot published in Chen
et al.~(2023) showing a \(2\text{-}D\) layout from UMAP applied for the
PBMC3k dataset. The parameter settings, beyond the defaults, are
n\_neighbors = 30 and min\_dist = 0.3. The question is whether this is
an accurate representation of structure in the high-dimensional data.}

\end{figure}%

To determine whether the UMAP representation with the parameter choice
suggested by \citet{chen2023} preserves the original data structure, we
visualize the model constructed with UMAP overlaid on the \pD{} data.
The figures in Figure~\ref{fig-pbmc1-sc} show three well-separated
clusters, indicating that the suggested UMAP representation preserves
the global structure (see Figure~\ref{fig-umap-author}). However, as
shown in Figure~\ref{fig-pbmc1-sc}, these clusters are close to each
other in \pD{}. Also, non-linear continuity patterns and high-density
patches within the clusters are observed (see
Figure~\ref{fig-pbmc1-sc}). Therefore, the suggested UMAP representation
(see Figure~\ref{fig-umap-author}) does not accurately preserve the
local structure of the PBMC3k dataset.

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=\textheight]{paper_files/figure-pdf/fig-model-pbmc-author-1.pdf}

}

\caption{\label{fig-model-pbmc-author}(a) Model generated in
\(2\text{-}D\) with UMAP, and (b) \(p\text{-}D\) model error in
\(2\text{-}D\). The \(2\text{-}D\) model shows three well-separated
distant clusters. The \(p\text{-}D\) model errors are distributed along
clusters.}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.33\linewidth}
\includegraphics{figures/pbmc3k/sc_1.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/pbmc3k/sc_2.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/pbmc3k/sc_3.png}\end{minipage}%

\caption{\label{fig-pbmc1-sc}Screen shots of the \textbf{langevitour} of
the PBMC3k data set, shows the model-in-data space, a video of the tour
animation is available at (\url{https://youtu.be/VqqWuE0Jj6A}).}

\end{figure}%

In order to find a reasonable NLDR representation for the PBMC3k
dataset, we calculated the absolute error for different numbers of
non-empty bins using various NLDR techniques and different parameter
settings (see Figure~\ref{fig-pbmc-abserror}). After analyzing the
results, we found that tSNE with a perplexity set to \(30\) had the
lowest error when the number of non-empty bins was \(137\). Therefore,
tSNE with a perplexity of \(30\), which is the default parameter
setting, is considered as a reasonable representation for the PBMC3k
dataset.

\begin{figure}[H]

\centering{

\includegraphics[width=0.5\textwidth,height=\textheight]{paper_files/figure-pdf/fig-pbmc-abserror-1.pdf}

}

\caption{\label{fig-pbmc-abserror}Absolute error from UMAP and tSNE
applied to training PBMC3k dataset with diffferent parameter choices.
What is the best parameter choice to create the model? The residual plot
have a steep slope at the beginning, indicating that a smaller number of
non-empty bins causes a larger amount of error. Then, the slope
gradually declines or level off, indicating that a higher number of
non-empty bins generates a smaller error. Using the elbow method, it was
observed that when the number of non-empty bins is set to \(137\), the
lowest error occurred with the parameters perplexity: \(30\).}

\end{figure}%

As shown in Figure~\ref{fig-tsne-suggest}, there are three
well-separated clusters, although they are located close to each other.
Additionally, non-linear structures can also be observed within the
clusters (see Figure~\ref{fig-model-pbmc} (a)). In this manner, tSNE was
able to capture the data structure for the PBMC3k dataset that UMAP
failed to do.

\begin{figure}[H]

\centering{

\includegraphics[width=0.4\textwidth,height=\textheight]{paper_files/figure-pdf/fig-tsne-suggest-1.pdf}

}

\caption{\label{fig-tsne-suggest}\(2\text{-}D\) layout from tSNE applied
for the PBMC3k dataset. Is this a best representation of the original
data? The parameter setting is perplexity=30.}

\end{figure}%

We then fit the model for tSNE, and visualize the resultant model in the
\pD{} data space. The model shows a quirk, as shown in
Figure~\ref{fig-pbmc2-sc}. All three clusters are connected by an edge
except the small and large clusters. Because the clusters are so close
in \gD{}, they attempt to maintain the structure in \pD{} as well. This
is evident that tSNE with perplexity \(30\) provides a reasonable
representation of PBMC3k data.

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=0.3\textheight]{paper_files/figure-pdf/fig-model-pbmc-1.pdf}

}

\caption{\label{fig-model-pbmc}(a) Model generated in \(2\text{-}D\)
with tSNE, and (b) \(p\text{-}D\) model error in \(2\text{-}D\). The
\(2\text{-}D\) model shows three well-separated distant clusters. The
\(p\text{-}D\) model errors are distributed along clusters, but most low
\(p\text{-}D\) model errors present in the large cluster.}

\end{figure}%

\begin{figure}[H]

\begin{minipage}{0.33\linewidth}
\includegraphics{figures/pbmc3k/sc_4.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/pbmc3k/sc_5.png}\end{minipage}%
%
\begin{minipage}{0.33\linewidth}
\includegraphics{figures/pbmc3k/sc_6.png}\end{minipage}%

\caption{\label{fig-pbmc2-sc}Screen shots of the \textbf{langevitour} of
the PBMC3k data set, shows the model in high-D, a video of the tour
animation is available at (\url{https://youtu.be/5Y1hE4i7N2k}).}

\end{figure}%

\subsection{Hand-written digits}\label{hand-written-digits}

The MNIST dataset consists of grayscale images of handwritten digits
\citep{lecun2010}. \citet{yingfan2021} used this dataset to demonstrate
how PaCMAP preserves local structure. We selected the \gD{} embedding of
PaCMAP for the handwritten digit 1 to assess whether this is a
reasonable representation using our method. As shown in
Figure~\ref{fig-pacmap-author-img}, the angle of the digit 1 images
varies along the \gD{} structure.

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=0.22\textheight]{paper_files/figure-pdf/fig-pacmap-author-1.pdf}

}

\caption{\label{fig-pacmap-author}\(2\text{-}D\) layout from PaCMAP
applied for the digit 1 of the MNIST dataset with a specific parameter
settings. The angle of the digit 1 varies along this structure. Images
at the top-left of the \(2\text{-}D\) layout show the digit 1 angled
more to the left, while images at the bottom-right show the digit 1
angled more to the right. Is this the best representation of the digit
1?}

\end{figure}%

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=0.5\textheight]{paper_files/figure-pdf/fig-pacmap-author-img-1.pdf}

}

\caption{\label{fig-pacmap-author-img}Images of the handwritten digit 1
are ordered from the bottom-right to the top-left of the \(2\text{-}D\)
structure. The angle of the digit varies along this structure. Images at
the bottom-right of the \(2\text{-}D\) layout show the digit 1 angled
more to the right, while images at the top-left show the digit 1 angled
more to the left. This demonstrates how the angle changes from right to
left along the \(2\text{-}D\) structure.}

\end{figure}%

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=\textheight]{paper_files/figure-pdf/fig-model-mnist-1.pdf}

}

\caption{\label{fig-model-mnist}(a) Model generated in \(2\text{-}D\),
and (b) \(p\text{-}D\) model error in \(2\text{-}D\). The \(2\text{-}D\)
model shows a non-linear continuous structure. Most low \(p\text{-}D\)
model errors are distributed along the lower edge of the \(2\text{-}D\)
structure, while most high p-D model errors are concentrated along the
upper edge.}

\end{figure}%

According to Figure~\ref{fig-mnist1-sc1}, the non-linear continuous
structure observed in the \gD{} representation of PaCMAP (see
Figure~\ref{fig-pacmap-author}) is also visible when visualizing the
model overlaid on the data space. This indicates that PaCMAP accurately
captures the structure of the \pD{} data. Additionally, the model shows
a twisted pattern within the non-linear structure in \pD{} space (see
Figure~\ref{fig-mnist1-sc2}), which is an additional pattern not visible
in the \gD{} representation (see Figure~\ref{fig-pacmap-author}).
Furthermore, as shown in Figure~\ref{fig-mnist1-sc3}, some long edges
exist in the \pD{} space that are not recognized as long edges in the
\gD{} representation. However, PaCMAP is a reasonable \gD{}
representation of MNIST digit 1 data. Because PaCMAP preserves the local
structure.

\begin{figure}[H]

\begin{minipage}{0.33\linewidth}

\centering{

\includegraphics{figures/mnist/sc_1.png}

}

\subcaption{\label{fig-mnist1-sc1}}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\centering{

\includegraphics{figures/mnist/sc_2.png}

}

\subcaption{\label{fig-mnist1-sc2}}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\centering{

\includegraphics{figures/mnist/sc_3.png}

}

\subcaption{\label{fig-mnist1-sc3}}

\end{minipage}%

\caption{\label{fig-mnist1-sc}Screen shots of the \textbf{langevitour}
of the MNIST digit 1 data set, shows the model-in-data space, a video of
the tour animation is available at
(\url{https://youtu.be/zcg_GXBmqjA}).}

\end{figure}%

There are certain data points that exhibit high error rates due to their
deviation from the usual \pD{} data structure, which makes them
anomalies (see Figure~\ref{fig-model-mnist} (b)). These anomalies can be
classified into two types: those that are anomalies within the
non-linear structure and those that lie outside of it. The images
associated with high model error points within the non-linear structure
display different patterns of the digit 1, as shown in
Figure~\ref{fig-mnist-anomalies} (a). However, when comparing these
images to the ones found outside of the non-linear structure, it becomes
evident that the latter display different patterns of the digit 1 (see
Figure~\ref{fig-mnist-anomalies} (b)).

\begin{figure}[H]

\centering{

\includegraphics[width=1\textwidth,height=0.35\textheight]{paper_files/figure-pdf/fig-mnist-anomalies-1.pdf}

}

\caption{\label{fig-mnist-anomalies}Some images of handwritten digit 1
which occur high model error (a) within the non-linear strcuture, and
(b) outside the non-linear structure. The images shows different
patterns of digit 1.}

\end{figure}%

\section{Discussion}\label{sec-discussion}

This study makes several important contributions to the field of NLDR.
We have developed an algorithm to evaluate the most useful NLDR method
and (hyper-)parameter choices for creating a reasonable \gD{} layout of
high-dimensional data. Our objective is to fit a model for the \gD{}
layout that preserves the relationships between neighboring points and
turns it into a high-dimensional wireframe, which can be overlaid on the
data and visualized using a tour. This approach is defined as
\emph{model-in-data-space}. Viewing a model in the data space is an
ideal way to examine the fit.

The effectiveness of this approach is illustrated through various
examples. For instance, the S-curve example demonstrates how the model
accurately fits the points, capturing both local and global structures
in high-dimensional space. Our simulation case study further, five
Gaussian cluster example shows that while all observed NLDR methods
preserve the global structure, only tSNE effectively maintains the local
structure, highlighting the specific strengths and quirks of different
methods.

Human behavior often shows a desire for more certainty and a tendency to
prefer well-separated views. This emphasizes the importance of clear and
distinct clusters. For example, in the UMAP layout of the \textbf{pbmc}
dataset suggested by \citet{chen2023}, three distant, well-separated
clusters are shown. However, our model reveals that these clusters are
actually close to each other in \pD{}. Additionally, the model discovers
non-uniform data distribution and non-linear structures within the
clusters that are not visible in the UMAP layout, demonstrating the
ability of our model in uncovering hidden data characteristics.

Evaluating the error or unexplained variance is important for assessing
how well the model fits the data. By examining the error for different
numbers of bins, we found that tSNE with a perplexity of \(30\) provides
a reasonable representation for the \textbf{pbmc} dataset. Connecting
the closest clusters with line segments in the fitted model further
supports the preservation of neighborhood relationships.

The \textbf{digit: 1} example further illustrates the model's ability to
accurately capture non-linear structures and provide additional
information. Key findings include a twisted pattern that compresses the
structure in some projections and long line segments that detect
anomalies.

Predicting new observations in \kD{} is particularly valuable due to the
limitations of some NLDR methods, like tSNE, which don't provide a
straightforward method for prediction. As a result, our approach offers
a solution that capable of generating predicted \kD{} embedding
regardless of the NLDR method employed, effectively addressing this
functional gap.

In conclusion, while our method effectively captures and represents
high-dimensional data structures, further enhancements could involve
introducing approaches to bind the data, indicate line segments beyond
\gD{}, and diagnose the fitted model. These improvements would help in
creating a more accurate representation of the data when \gD{} layout is
inadequate.

\section{Supplementary Materials}\label{supplementary-materials}

Code, and data for reproducing this paper are available at
\url{https://github.com/JayaniLakshika/paper-nldr-vis-algorithm}.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\renewcommand{\bibsection}{}
\bibliography{bibliography.bib}

\newpage{}





\end{document}
